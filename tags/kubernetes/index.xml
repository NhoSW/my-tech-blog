<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Kubernetes on nanta - 데이터 엔지니어링</title><link>https://nanta-data.dev/tags/kubernetes/</link><description>Recent content in Kubernetes on nanta - 데이터 엔지니어링</description><generator>Hugo -- gohugo.io</generator><language>ko</language><copyright>© 2026 nanta</copyright><lastBuildDate>Fri, 27 Feb 2026 00:00:00 +0000</lastBuildDate><atom:link href="https://nanta-data.dev/tags/kubernetes/index.xml" rel="self" type="application/rss+xml"/><item><title>EMR on EKS VPA 검토기: AWS 공식 기능이 동작하지 않을 때</title><link>https://nanta-data.dev/posts/emr-on-eks-vpa-review/</link><pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/emr-on-eks-vpa-review/</guid><description>EMR on EKS 환경에서 Spark executor 리소스를 자동 최적화하려고 AWS 제공 VPA를 검토했다. 약 한 달간 PoC를 진행했지만 오퍼레이터 자체가 정상 동작하지 않았다. AWS 서포트 케이스를 여러 차례 열었고 매니페스트 번들까지 받아서 커스터마이징했지만 결국 포기했다.</description></item><item><title>Kafka Rack Awareness와 Spark: 현재 지원하지 않는다</title><link>https://nanta-data.dev/posts/kafka-rack-awareness-spark/</link><pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/kafka-rack-awareness-spark/</guid><description>Kafka 클러스터의 rack awareness를 Spark에도 적용해서 cross-AZ 네트워크 비용을 줄이려 했다. AZ 정보 추출까지는 해결했지만, Spark 자체가 Kafka 연동 시 rack awareness를 지원하지 않았다. 관련 티켓은 커뮤니티에 열려 있지만 PR은 닫힌 상태다.</description></item><item><title>Trino Alluxio 캐시 PoC: EBS 스루풋이 병목이었다</title><link>https://nanta-data.dev/posts/trino-alluxio-cache-poc/</link><pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/trino-alluxio-cache-poc/</guid><description>Trino의 Alluxio 기반 파일 시스템 캐시를 프로덕션 OLAP 환경에서 PoC했다. 캐시를 붙이기만 하면 빨라질 줄 알았는데 EBS 기본 스루풋 125MiB/s가 병목이었다. 스루풋 상향 후 쿼리 성능이 눈에 띄게 개선됐고 S3 API 비용도 월 440만 원 줄었다.</description></item><item><title>Trino Gateway 도입기: 제로 다운타임 배포와 멀티 클러스터 라우팅</title><link>https://nanta-data.dev/posts/trino-gateway-zero-downtime/</link><pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/trino-gateway-zero-downtime/</guid><description>Trino는 코디네이터 HA를 지원하지 않는다. 코디네이터를 재배포하면 다운타임이 생긴다. Trino Gateway를 도입해서 Blue/Green 배포로 제로 다운타임을 달성하고 BI/OLAP 클러스터를 헤더 기반으로 라우팅한 과정을 정리했다.</description></item><item><title>ALB 로그를 Iceberg 테이블로 만들기까지</title><link>https://nanta-data.dev/posts/alb-log-collection-system/</link><pubDate>Wed, 25 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/alb-log-collection-system/</guid><description>S3에 CSV로 쌓이는 ALB 로그를 Iceberg 테이블로 바꾸는 시스템을 구축했다. Flink filesystem connector의 메모리 한계를 겪고 filebeat + SQS + Kafka 구조로 재설계한 과정, 오토스케일링 적용, 체크포인트 튜닝, 그리고 운영 중 마주친 여러 삽질을 정리했다.</description></item><item><title>Apache APISIX로 프록시 서버 구축하기. 일 13억 건 로그 비식별화 처리</title><link>https://nanta-data.dev/posts/apisix-proxy-server-guide/</link><pubDate>Tue, 24 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/apisix-proxy-server-guide/</guid><description>해외 트래킹 서버로 앱 로그를 전송할 때 개인정보를 비식별화해야 했다. Fluent-bit에서 시작해 Kong을 거쳐 APISIX에 정착한 과정, 커스텀 Lua 플러그인 개발, 5.5만 TPS 부하 테스트, Kubernetes 배포까지 실전 경험을 정리했다.</description></item><item><title>NVIDIA MIG 설정 가이드. A100 GPU 하나를 여러 개로 쪼개 쓰기</title><link>https://nanta-data.dev/posts/nvidia-mig-setup-guide/</link><pubDate>Mon, 23 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/nvidia-mig-setup-guide/</guid><description>A100 GPU 4장으로 최대 28개의 독립 GPU 인스턴스를 만들 수 있다. MIG 개념부터 mig-parted 설치, 슬라이스 구성, Kubernetes 연동까지 실전 경험을 정리했다.</description></item></channel></rss>