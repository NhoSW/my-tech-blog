[{"content":"Joe Reis가 1,101명의 데이터 실무자를 대상으로 진행한 서베이 결과를 기반으로 2026년 데이터 엔지니어링 트렌드를 발표했다. 대규모 플랫폼의 데이터 엔지니어링 팀을 이끌고 있는 입장에서, 이 트렌드를 우리 팀의 현재 아키텍처와 대조하며 이미 잘 하고 있는 것과 앞으로 해야 할 것을 정리해본다.\n우리 아키텍처 한 줄 요약 S3를 중심 데이터 레이크로 두고, Apache Iceberg 테이블 포맷 위에 Trino(배치/애드혹 분석)와 StarRocks(실시간 OLAP)를 얹은 하이브리드 구조다. 데이터 수집은 Kafka + Debezium CDC와 Flink 스트리밍, 오케스트레이션은 Airflow를 깊이 커스터마이징하여 운영하고 있다.\n[Services] → Kafka + Debezium CDC → Flink → S3 (Iceberg) ↓ ┌─────┴─────┐ │ │ Trino StarRocks (배치/애드혹) (실시간 OLAP) │ │ └─────┬─────┘ ↓ Dashboard 1. AI 활용 — 이미 하고 있는 것과 넘어야 할 벽 트렌드 요약 서베이 응답자의 82%가 AI를 매일 사용하고 있지만, 64%는 아직 실험 단계나 단순 작업에만 활용하고 있다. Joe Reis는 2026년 말이면 \u0026ldquo;AI-assisted\u0026quot;라는 수식어가 직무 기술에서 사라질 것이라 예측한다.\n우리가 하고 있는 것 AI 코딩 도구를 활용한 파이프라인 개발은 이미 일상이 되었다. SQL 최적화, 코드 리뷰, 트러블슈팅 과정에서 LLM을 적극적으로 활용하고 있으며, 데이터 카탈로그와 연계한 자연어 기반 데이터 탐색도 시도하고 있다.\n해야 할 것 개인 단위의 AI 활용을 넘어서 팀 전체의 워크플로우에 AI를 임베드하는 것이 과제다.\n데이터 파이프라인 이상 감지 자동 스키마 진화 대응 데이터 품질 룰 자동 생성 Joe Reis가 말한 \u0026ldquo;10%의 AI-mature 팀\u0026quot;에 속하려면, AI를 단순 보조 도구가 아닌 플랫폼의 핵심 컴포넌트로 통합하는 전략이 필요하다.\n2. 데이터 모델링 위기와 시맨틱 레이어 — 가장 큰 숙제 트렌드 요약 응답자의 89%가 데이터 모델링에서 고통을 호소하고 있고, 시맨틱 모델을 사용하는 팀은 고작 5%다. Joe Reis는 시맨틱 레이어가 먼저 주류가 되고, 이후 LLM이 스키마를 즉석에서 해석하는 방향으로 진화할 것이라 본다.\n우리가 하고 있는 것 데이터 카탈로그를 통해 리니지와 메타데이터를 관리하고 있고, 테이블 레이어 체계(L1/L2/L3)를 정의하여 데이터 품질을 계층적으로 관리하려는 시도를 진행 중이다. Airflow 커스텀 오퍼레이터를 통한 데이터 검증 자동화도 운영하고 있다.\n해야 할 것 dbt 도입을 검토했으나 차세대 데이터 플랫폼 전환 전략과 맞물려 중단된 상태다. 현재 파이프라인을 dbt로 이관하기보다는 새로운 플랫폼으로 직접 이관하는 방향을 검토하고 있지만, 그 사이 데이터 변환의 표준화와 모듈화가 공백으로 남아있다. 이것이 Joe Reis가 말한 \u0026ldquo;89%의 고통\u0026quot;과 정확히 일치하는 부분이다.\n시맨틱 레이어 역시 미답 영역이다. 비즈니스 메트릭의 정의가 팀마다 다르고, 동일한 지표에 대해 서로 다른 SQL을 사용하는 문제가 존재한다. 서베이에서 시맨틱 모델 교육 수요가 19%로 높게 나온 것처럼, 조직 전체의 데이터 리터러시를 끌어올리는 작업이 시급하다.\n특히 AI 에이전트가 데이터를 자율적으로 활용하는 미래를 대비하면, 잘 정의된 시맨틱 레이어는 선택이 아닌 필수다. 플랫폼 전환이 지연되더라도 모델링 표준과 시맨틱 정의는 독립적으로 진행할 수 있고, 진행해야 한다.\n3. 오케스트레이션 통합 — Airflow의 미래 트렌드 요약 Airflow가 여전히 지배적이지만, Dagster가 소규모 기업에서 12%의 점유율을 보이며 바텀업으로 성장하고 있다. 오케스트레이션이 아예 없는 팀이 모든 기업 규모에서 20%라는 점도 놀랍다.\n우리가 하고 있는 것 Airflow를 깊이 커스터마이징하여 운영하고 있다. 자체 Provider 패키지를 개발하고, 데이터 검증 자동화 오퍼레이터, 커스텀 전송 오퍼레이터 등 플랫폼에 특화된 기능을 구현했다. 현재 Airflow 3.x 메이저 버전 업그레이드를 진행 중이며, Python 버전 업그레이드와 Breaking Change 대응을 체계적으로 계획하고 있다.\n해야 할 것 Airflow에 대한 깊은 투자는 강점이지만, 동시에 기술 부채이기도 하다.\n커스텀 Provider의 유지보수 부담 버전 업그레이드 시 호환성 이슈 AI 에이전트 오케스트레이션이라는 새로운 패러다임에 대한 대비 Joe Reis가 예측한 것처럼 오케스트레이션이 플랫폼에 흡수되는 방향도 지켜봐야 한다. 차세대 데이터 플랫폼과의 정합성을 고려하면, 오케스트레이션 전략의 중장기적 로드맵 수립이 시급하다.\n4. Lakehouse vs. Warehouse — 이미 답을 낸 영역 트렌드 요약 서베이에서 44%가 Warehouse, 27%가 Lakehouse, 12%가 Hybrid를 사용하고 있다. Snowflake과 Databricks의 기능이 수렴하면서 이 논쟁 자체가 무의미해지고 있다. Joe Reis는 2026년 말이면 \u0026ldquo;warehouse vs. lakehouse\u0026rdquo; 논쟁이 구식으로 느껴질 것이라 예측한다.\n우리가 하고 있는 것 이 트렌드에서 우리 팀은 이미 정답에 가까운 위치에 있다. S3 위에 Iceberg 오픈 테이블 포맷을 표준으로 채택하고, 용도에 따라 Trino와 StarRocks를 선택적으로 사용하는 구조는 Warehouse도 Lakehouse도 아닌, 양쪽의 장점을 취한 아키텍처다. CDC 파이프라인을 통해 실시간 데이터를 Iceberg 테이블로 적재하고, 배치와 실시간 분석을 동일한 데이터 위에서 수행할 수 있다.\n해야 할 것 Iceberg v3의 Deletion Vector, Row Lineage 등 새로운 기능을 적극 활용하기 위해서는 쿼리 엔진 전반의 호환성 확보가 필요하다. 현재 Trino와 StarRocks의 Iceberg v3 지원이 제한적이므로, 엔진 업그레이드 로드맵과 Iceberg 버전 전략을 연계해야 한다. 또한 오픈 테이블 포맷 기반 아키텍처의 거버넌스 체계 — 카탈로그 통합, 접근 제어, 데이터 품질 보장 — 를 더 강화해야 한다.\n5. 리더십이 병목이 되는 문제 — 가장 어렵고 가장 중요한 과제 트렌드 요약 데이터 엔지니어의 22%가 \u0026ldquo;리더십 방향 부재\u0026quot;를 주요 이슈로 꼽았고, 이는 레거시 기술 부채(26%)에 버금가는 수치다. Joe Reis는 2026년에 더 많은 데이터 팀이 해체되거나 엔지니어링 조직에 합병될 것이라 경고한다.\n우리가 하고 있는 것 데이터 플랫폼 팀이 독립적인 조직으로 존재하며, 인프라부터 수집, 변환, 분석 환경까지 End-to-End로 책임지는 구조를 갖추고 있다. 비즈니스 팀과의 직접적인 소통 채널을 유지하며, 데이터 요건을 직접 수렴하고 있다.\n해야 할 것 기술적 역량만으로는 팀의 존재 가치를 증명할 수 없다. Joe Reis가 강조한 것처럼 \u0026ldquo;비즈니스 가치를 증명한 팀만 살아남는다.\u0026rdquo;\n데이터 플랫폼의 ROI를 정량적으로 측정하고 커뮤니케이션하는 체계 AI 시대에 데이터 플랫폼이 어떤 역할을 해야 하는지에 대한 비전 수립 데이터 옵저버빌리티 도입을 통한 데이터 다운타임 감소 파이프라인 개발 생산성 지표화 등 구체적인 비즈니스 임팩트 제시 정리: 잘 하고 있는 것 vs. 해야 할 것 영역 잘 하고 있는 것 해야 할 것 AI 활용 개인 단위 AI 코딩 도구 적극 활용 팀 워크플로우에 AI 임베드, 운영 자동화 데이터 모델링 카탈로그 기반 메타데이터 관리, 레이어 체계 정의 시맨틱 레이어 도입, 데이터 변환 표준화 오케스트레이션 Airflow 깊은 커스터마이징, 3.x 업그레이드 진행 장기 오케스트레이션 전략, AI 에이전트 대응 Lakehouse/Warehouse Iceberg 기반 하이브리드 아키텍처 구축 완료 Iceberg v3 호환성, 거버넌스 체계 강화 리더십 End-to-End 플랫폼 팀 운영 비즈니스 임팩트 정량화, 데이터 옵저버빌리티 마치며 Joe Reis의 서베이에서 가장 인상적이었던 문장은 이것이다.\n\u0026ldquo;2026년 데이터 엔지니어링은 올바른 도구를 고르는 것보다 그 도구를 잘 활용할 조직적 근육을 키우는 것이 더 중요하다.\u0026rdquo;\n우리 팀은 기술 스택 면에서 트렌드의 앞쪽에 서 있다. Iceberg 기반 오픈 데이터 레이크, 실시간과 배치를 아우르는 하이브리드 아키텍처, 깊이 있는 Airflow 커스터마이징 등은 많은 조직이 아직 도달하지 못한 수준이다.\n하지만 기술적 우위만으로는 충분하지 않다. 데이터 변환 표준화, 시맨틱 레이어, 데이터 옵저버빌리티, AI 네이티브 워크플로우, 그리고 무엇보다 비즈니스 가치를 증명하는 리더십 — 이것이 2026년에 우리가 집중해야 할 방향이다.\n과거의 빚은 이자를 물고 있고, 페이데이가 다가오고 있다. 지금이 기반을 다질 때다.\n원문 참고: Where Data Engineering Is Heading in 2026 — Joe Reis\n","permalink":"https://NhoSW.github.io/my-tech-blog/ko/posts/2026-data-engineering-trends/","summary":"Joe Reis의 1,101명 서베이를 기반으로 한 2026년 데이터 엔지니어링 트렌드를, 대규모 플랫폼 데이터 엔지니어링 팀의 현재 아키텍처와 대조하며 정리했습니다. 이미 잘 하고 있는 것과 앞으로 해야 할 것을 솔직하게 돌아봅니다.","title":"2026 데이터 엔지니어링 트렌드와 대규모 플랫폼의 현주소"},{"content":"도입 배경 데이터 파이프라인을 운영하다 보면 한 가지 고민에 반드시 부딪힌다. 실시간 대시보드를 어떻게 만들 것인가?\n우리 팀도 마찬가지였다. 기존 파이프라인은 다음과 같은 구조였다.\nService → Kafka → Iceberg → S3 → Trino → Airflow(5분) → Dashboard 겉보기엔 잘 동작했지만, 실무에서 체감하는 문제는 분명했다.\n최소 5분 지연: Airflow 스케줄 주기가 병목이었다 파이프라인 복잡도: Kafka → Flink → Redis → API → Dashboard로 이어지는 5개 이상의 컴포넌트 관리 반복되는 I/O: Trino가 매 쿼리마다 S3를 풀스캔하는 구조 높은 개발 비용: 새로운 실시간 대시보드 하나에 약 2주 소요 StarRocks를 도입한 후의 아키텍처는 이렇게 단순해졌다.\nService → Kafka → StarRocks → Dashboard (서브초 레이턴시) 중간 컴포넌트가 사라지면서 파이프라인이 극적으로 단순해졌고, 데이터가 Kafka에서 StarRocks로 직접 수집되면서 실시간성도 확보했다.\n도입 효과 약 3개월간의 PoC와 6개월간의 단계적 도입을 거쳐 다음과 같은 개선을 달성했다.\n항목 Before After 개선폭 대시보드 지연 5분 \u0026lt; 1초 ~300배 대시보드 개발 기간 ~2주 ~1주 50% 단축 파이프라인 컴포넌트 5개 이상 2개 60% 감소 쿼리 응답 시간 30~50초 5~10초 5~10배 하드웨어 비용 128GB × 18노드 64GB × 3노드 ~75% 절감 Trino는 절대적인 쿼리 시간에서는 빠르지만, Airflow 스케줄 지연을 포함한 end-to-end 레이턴시와 하드웨어 비용 효율 면에서 StarRocks가 실시간 워크로드에 더 적합했다.\n테이블 모델 선택 가이드 StarRocks를 처음 도입할 때 가장 중요한 결정이 테이블 모델 선택이다. 잘못 고르면 나중에 테이블을 다시 만들어야 한다.\n의사결정 흐름 ┌─────────────────────────────┐ │ 어떤 데이터를 저장하는가? │ └──────────────┬──────────────┘ │ ┌───────▼────────┐ │ UPDATE 필요? │ └───────┬────────┘ │ ┌────────┴────────┐ │ │ [아니오] [예] │ │ ┌─────▼─────┐ ┌─────▼──────┐ │ 집계 필요? │ │ Primary Key │ └─────┬─────┘ │ (빈번한 │ │ │ UPDATE) │ [아니오] [예] └────────────┘ │ │ ┌─────▼───┐ ┌▼──────────┐ │Duplicate│ │Aggregate │ │(원본 저장)│ │(자동 집계) ★│ └─────────┘ └────────────┘ 모델 비교 모델 중복 허용 UPDATE 자동 집계 적합한 용도 Duplicate Key O X X 로그, 원본 이벤트 Aggregate Key X 자동 O 실시간 통계 ★ Primary Key X O (고속) X 빈번한 UPDATE Duplicate Key: 원본 데이터 저장 클릭 로그, API 이벤트, 센서 데이터처럼 원본을 그대로 보관해야 할 때 사용한다.\nCREATE TABLE order_events ( event_id BIGINT, event_time DATETIME, order_id VARCHAR(50), user_id BIGINT, event_type VARCHAR(20), amount DECIMAL(10, 2) ) DUPLICATE KEY(event_id, event_time) PARTITION BY date_trunc(\u0026#39;day\u0026#39;, event_time) DISTRIBUTED BY HASH(event_id) BUCKETS 10; Aggregate Key: 실시간 통계 ★ 데이터가 수집되는 시점에 자동으로 집계가 일어난다. 이 모델이 StarRocks 도입의 핵심이었다.\nCREATE TABLE order_stats ( stat_time DATETIME NOT NULL COMMENT \u0026#39;5분 간격\u0026#39;, region VARCHAR(20) NOT NULL, delivery_type VARCHAR(20) NOT NULL, -- 집계 컬럼: 수집 시 자동으로 집계 함수 적용 order_count BIGINT SUM DEFAULT \u0026#34;0\u0026#34;, total_amount DECIMAL(15, 2) SUM DEFAULT \u0026#34;0\u0026#34;, user_bitmap BITMAP BITMAP_UNION, max_amount DECIMAL(10, 2) MAX ) AGGREGATE KEY(stat_time, region, delivery_type) PARTITION BY date_trunc(\u0026#39;day\u0026#39;, stat_time) DISTRIBUTED BY HASH(stat_time) BUCKETS 10; 사용 가능한 집계 함수:\n함수 용도 예시 SUM 합계 주문 건수, 매출 합계 MAX / MIN 최대/최소값 최고가, 최저가 REPLACE 최신 값 덮어쓰기 최종 상태 BITMAP_UNION 정확한 유니크 카운트 순 이용자 수 HLL_UNION 근사 유니크 카운트 대규모 카디널리티 BITMAP_UNION은 HyperLogLog와 달리 정확한 유니크 카운트를 제공한다. 비즈니스 KPI 대시보드처럼 정확도가 중요한 경우 반드시 이 방식을 사용하자.\nPrimary Key: 빈번한 UPDATE 주문 상태 추적, 재고 관리처럼 같은 키의 데이터가 자주 갱신되는 경우에 적합하다.\nCREATE TABLE orders ( order_id VARCHAR(50) NOT NULL, status VARCHAR(20), amount DECIMAL(10, 2), updated_at DATETIME ) PRIMARY KEY(order_id) DISTRIBUTED BY HASH(order_id) BUCKETS 10 PROPERTIES ( \u0026#34;enable_persistent_index\u0026#34; = \u0026#34;true\u0026#34; ); enable_persistent_index를 활성화하면 UPDATE 성능이 크게 향상된다.\n데이터 수집 Routine Load: Kafka 실시간 연동 Kafka 토픽에서 데이터를 연속으로 수집하는 방식이다. 대부분의 실시간 파이프라인에서 이 방식을 사용한다.\nCREATE ROUTINE LOAD order_load ON orders COLUMNS( order_id, user_id, timestamp_ms, amount, order_date = FROM_UNIXTIME(timestamp_ms / 1000) ) PROPERTIES ( \u0026#34;format\u0026#34; = \u0026#34;json\u0026#34;, \u0026#34;jsonpaths\u0026#34; = \u0026#34;[\\\u0026#34;$.orderId\\\u0026#34;,\\\u0026#34;$.userId\\\u0026#34;,\\\u0026#34;$.timestamp\\\u0026#34;,\\\u0026#34;$.amount\\\u0026#34;]\u0026#34; ) FROM KAFKA ( \u0026#34;kafka_broker_list\u0026#34; = \u0026#34;kafka-broker:9092\u0026#34;, \u0026#34;kafka_topic\u0026#34; = \u0026#34;orders\u0026#34; ); Aggregate Key 테이블과 결합하면 수집 시점에 변환과 집계를 동시에 처리할 수 있다.\nCREATE ROUTINE LOAD order_stats_load ON order_stats COLUMNS( timestamp_ms, region, amount, user_id, -- 5분 간격으로 라운딩 stat_time = FROM_UNIXTIME(FLOOR(timestamp_ms / 1000 / 300) * 300), order_count = 1, total_amount = amount, user_bitmap = BITMAP_HASH(user_id) ) WHERE amount \u0026gt; 0 PROPERTIES (\u0026#34;format\u0026#34; = \u0026#34;json\u0026#34;) FROM KAFKA ( \u0026#34;kafka_broker_list\u0026#34; = \u0026#34;kafka-broker:9092\u0026#34;, \u0026#34;kafka_topic\u0026#34; = \u0026#34;orders\u0026#34; ); 이 패턴 하나로 기존에 Flink로 처리하던 집계 로직을 SQL만으로 대체할 수 있었다.\nStream Load: 벌크 데이터 로딩 파일이나 API를 통한 일회성 대량 로딩에 적합하다.\n# CSV 파일 로딩 curl --location-trusted \\ -u user:password \\ -H \u0026#34;label:load_$(date +%Y%m%d%H%M%S)\u0026#34; \\ -H \u0026#34;column_separator:,\u0026#34; \\ -T data.csv \\ http://starrocks-fe:8030/api/mydb/mytable/_stream_load 성능 튜닝 실전 팁 Thread Pool 설정 동시 접속이 500 RPS 이상인 고부하 환경에서는 기본 Thread Pool 크기가 부족하다.\n# be.conf pipeline_scan_thread_pool_thread_num = 32 # 기본값: 24 pipeline_exec_thread_pool_thread_num = 32 # 기본값: 24 Bucket Count 가이드라인 데이터 크기 권장 Bucket 수 \u0026lt; 10 GB 10 10~50 GB 20 50~100 GB 30 \u0026gt; 100 GB 50+ 산정 공식: buckets = max(1, 데이터_크기_GB / 10)\n파티셔닝 전략 파티션 컬럼에 함수를 사용하면 파티션 프루닝이 동작하지 않는다. 이것은 생각보다 자주 실수하는 부분이다.\n-- ✅ 올바른 사용: 파티션 프루닝 동작 WHERE event_time \u0026gt;= NOW() - INTERVAL 3 DAY -- ❌ 잘못된 사용: 파티션 프루닝 불가 WHERE DATE(event_time) \u0026gt;= CURRENT_DATE - 3 TTL 설정 오래된 파티션을 자동으로 삭제하려면 TTL을 설정한다.\nPROPERTIES ( \u0026#34;partition_live_number\u0026#34; = \u0026#34;3\u0026#34; -- 최근 3개 파티션만 유지 ) 운영 노하우 Materialized View 관리 ASYNC 리프레시가 예고 없이 멈추는 경우가 있다. 정기적으로 상태를 확인하고, 문제 발생 시 수동으로 복구해야 한다.\n-- 상태 확인 SHOW MATERIALIZED VIEWS; -- 강제 동기 리프레시 REFRESH MATERIALIZED VIEW db.mv_name WITH SYNC MODE; -- 비활성화된 MV 재활성화 ALTER MATERIALIZED VIEW db.mv_name ACTIVE; Routine Load 모니터링 상태가 PAUSED로 전환되는 경우가 잦다. Kafka offset 문제나 비정상 메시지가 원인이다.\n-- 상태 확인 SHOW ROUTINE LOAD FOR db.load_job; -- 재개 RESUME ROUTINE LOAD FOR db.load_job; Scale-in 주의사항 노드를 축소할 때는 반드시 Decommission을 먼저 수행해야 한다. 이 절차 없이 노드를 줄이면 데이터가 유실된다.\n-- 1. 현재 노드 확인 SHOW PROC \u0026#39;/backends\u0026#39;; -- 2. 디커미션 시작 ALTER SYSTEM DECOMMISSION BACKEND \u0026#34;\u0026lt;BE_IP\u0026gt;:\u0026lt;HEARTBEAT_PORT\u0026gt;\u0026#34;; -- 3. TabletNum이 0이 될 때까지 대기 후 제거 ALTER SYSTEM DROP BACKEND \u0026#34;\u0026lt;BE_IP\u0026gt;:\u0026lt;HEARTBEAT_PORT\u0026gt;\u0026#34;; 도입 시 알아두면 좋은 것들 알려진 제약 사항 이슈 설명 대안 Routine Load 비정상 메시지 처리 한계 Kafka 단에서 사전 검증 datetime 파티션 Iceberg datetime 파티션 호환 이슈 대체 파티션 전략 사용 버전 업그레이드 4.x 대에서 버그 경험 스테이징 환경 필수 테스트 버전 업그레이드는 반드시 스테이징 환경에서 충분히 검증한 뒤 프로덕션에 적용하자. 실제로 여러 차례 업그레이드/다운그레이드를 반복한 경험이 있다. 롤백 계획은 항상 준비해두어야 한다.\n도입 체크리스트 배포 전\n유스케이스와 요구사항 정의 데이터 볼륨 및 증가량 추정 테이블 모델 선택 파티션 전략 설계 배포 후\nRoutine Load 작업 생성 및 검증 사용자 권한 설정 데이터 보관 정책(TTL) 설정 Scale-in/out 절차 문서화 모니터링 대시보드 구성 마치며 StarRocks 도입에서 얻은 핵심 교훈을 정리하면 다음과 같다.\nAggregate Key 모델이 핵심이다 — 수집 시점 자동 집계로 스토리지와 쿼리 성능을 동시에 잡을 수 있다 BITMAP_UNION으로 정확한 유니크 카운트를 확보하자 — 비즈니스 KPI에는 근사치가 아닌 정확한 수치가 필요하다 Routine Load + Aggregate Key 조합이 Flink를 대체한다 — SQL만으로 실시간 집계 파이프라인을 구축할 수 있다 운영 자동화에 투자하자 — Materialized View와 Routine Load 모니터링은 필수다 실시간 분석 워크로드에서 StarRocks는 파이프라인 복잡도를 획기적으로 줄여주는 강력한 선택지다. 다만 버전 업그레이드와 운영 안정성 측면에서는 아직 성숙해지는 과정에 있으므로, 충분한 PoC와 스테이징 검증을 거쳐 도입하길 권장한다.\n참고 자료: StarRocks 공식 문서\n","permalink":"https://NhoSW.github.io/my-tech-blog/ko/posts/starrocks-adoption-guide/","summary":"기존 Trino + Airflow 파이프라인의 5분 지연을 서브초 레이턴시로 개선한 StarRocks 도입 과정을 정리했습니다. 테이블 모델 선택, 데이터 수집, 성능 튜닝, 운영 노하우까지 실무에서 얻은 교훈을 공유합니다.","title":"StarRocks 도입기: 실시간 OLAP으로 데이터 파이프라인을 혁신한 이야기"},{"content":"왜 압축 설정이 중요한가 StarRocks를 운영하다 보면 데이터가 수십 TB 규모로 늘어나는 시점이 반드시 온다. 이때 압축 설정 하나로 스토리지 비용이 30~50% 차이 나는 경우를 여러 번 경험했다. 단순히 저장 공간만의 문제가 아니다. 압축률이 높으면 디스크 I/O가 줄어들어 스캔 성능이 좋아지고, 반대로 압축/해제에 CPU를 많이 쓰면 지연 시간이 늘어난다. 결국 워크로드 특성에 맞는 압축 알고리즘을 선택하는 것이 StarRocks 운영의 핵심 튜닝 포인트 중 하나다.\n지원되는 압축 알고리즘 비교 StarRocks는 여러 압축 알고리즘을 지원한다. 실무에서 주로 사용하는 세 가지를 비교해 보겠다.\n알고리즘 압축률 압축 속도 해제 속도 적합한 워크로드 LZ4 보통 (2~3x) 매우 빠름 매우 빠름 실시간 분석, 저지연 쿼리 ZSTD 높음 (4~6x) 보통 빠름 배치 분석, 콜드 데이터 Snappy 낮음 (1.5~2x) 빠름 빠름 범용, 레거시 호환 ZLIB 높음 (4~5x) 느림 보통 아카이빙, 저빈도 접근 데이터 개인적으로 가장 많이 쓰는 조합은 핫 데이터에 LZ4, 콜드 데이터에 ZSTD다. Snappy는 Hadoop 에코시스템에서 넘어온 데이터를 다룰 때 간혹 사용하지만, 신규 테이블에는 권장하지 않는다.\n테이블 생성 시 압축 설정 방법 테이블을 생성할 때 PROPERTIES에서 compression 속성을 지정하면 된다. 별도로 설정하지 않으면 StarRocks 기본값인 LZ4가 적용된다.\n실시간 분석용 테이블 (LZ4) CREATE TABLE analytics.realtime_events ( event_id BIGINT, user_id BIGINT, event_type VARCHAR(64), event_time DATETIME, properties JSON ) ENGINE = OLAP DUPLICATE KEY(event_id) DISTRIBUTED BY HASH(user_id) BUCKETS 32 PROPERTIES ( \u0026#34;replication_num\u0026#34; = \u0026#34;3\u0026#34;, \u0026#34;compression\u0026#34; = \u0026#34;LZ4\u0026#34; ); LZ4는 해제 속도가 압도적으로 빠르기 때문에, 대시보드 쿼리처럼 수백 밀리초 이내 응답이 필요한 테이블에 적합하다.\n배치 분석용 테이블 (ZSTD) CREATE TABLE warehouse.order_history ( order_id BIGINT, customer_id BIGINT, order_date DATE, total_amount DECIMAL(18, 2), status VARCHAR(32), items ARRAY\u0026lt;STRUCT\u0026lt;sku STRING, qty INT, price DECIMAL(10,2)\u0026gt;\u0026gt; ) ENGINE = OLAP DUPLICATE KEY(order_id) PARTITION BY RANGE(order_date) ( PARTITION p2025 VALUES LESS THAN (\u0026#39;2026-01-01\u0026#39;), PARTITION p2026 VALUES LESS THAN (\u0026#39;2027-01-01\u0026#39;) ) DISTRIBUTED BY HASH(customer_id) BUCKETS 16 PROPERTIES ( \u0026#34;replication_num\u0026#34; = \u0026#34;2\u0026#34;, \u0026#34;compression\u0026#34; = \u0026#34;ZSTD\u0026#34; ); ZSTD는 압축률이 LZ4 대비 1.5~2배 높아서, 파티션 단위로 수억 건 이상 적재되는 히스토리 테이블에서 스토리지 절감 효과가 크다.\n기존 테이블 압축 변경 이미 운영 중인 테이블의 압축 알고리즘을 변경하고 싶다면 ALTER TABLE을 사용할 수 있다. 단, 변경 이후 새로 적재되는 데이터부터 적용되며 기존 세그먼트는 Compaction이 수행되어야 반영된다는 점에 유의하자.\nALTER TABLE warehouse.order_history SET (\u0026#34;compression\u0026#34; = \u0026#34;ZSTD\u0026#34;); 워크로드별 권장 압축 설정 실무에서 반복적으로 검증한 결과를 기반으로 정리하면 다음과 같다.\n실시간 대시보드 / Ad-hoc 쿼리: LZ4를 권장한다. CPU 오버헤드가 거의 없어 P99 지연 시간에 미치는 영향이 최소화된다. 야간 배치 리포트 / ETL 결과 테이블: ZSTD를 권장한다. 쿼리 빈도가 낮고 데이터 양이 많은 경우 스토리지 절감 효과가 비용에 직접 반영된다. 로그성 대용량 적재: ZSTD를 사용하되 zstd_compression_level을 3 이하로 낮추면 압축 속도와 압축률 사이의 균형을 잡을 수 있다. 압축률과 성능 트레이드오프 실측 결과 약 50억 건(원본 약 800GB)의 이벤트 로그 테이블을 대상으로 압축 알고리즘별 벤치마크를 수행한 결과다.\n지표 LZ4 ZSTD (level 3) ZSTD (level 9) 압축 후 크기 320 GB 195 GB 170 GB 압축률 2.5x 4.1x 4.7x 단순 스캔 쿼리 (Avg) 1.2초 1.5초 1.8초 집계 쿼리 (Avg) 3.4초 3.8초 4.5초 데이터 적재 속도 120 MB/s 95 MB/s 60 MB/s LZ4 대비 ZSTD level 3은 스토리지를 약 39% 절감하면서도 쿼리 지연은 약 10~15%만 증가했다. 반면 ZSTD level 9는 추가 압축 이득 대비 적재 속도 저하가 커서 대부분의 환경에서는 level 3이 최적의 선택이었다.\n운영 팁과 모니터링 마지막으로 실무에서 압축 관련 운영 시 놓치기 쉬운 포인트를 정리한다.\nCompaction 모니터링을 반드시 하자. 압축 알고리즘을 변경한 뒤 Compaction이 완료되기 전까지 혼합 세그먼트가 존재하면 쿼리 성능이 일시적으로 불안정해질 수 있다. BE의 compaction_score 메트릭을 모니터링하여 Compaction 적체 여부를 확인해야 한다.\n테이블 단위로 압축 전략을 분리하라. 하나의 클러스터에서 모든 테이블에 동일한 압축을 적용하는 것은 비효율적이다. 접근 빈도, 데이터 크기, SLA에 따라 테이블별로 다르게 설정하는 것이 올바른 접근이다.\n디스크 사용량 추이를 추적하라. 압축 변경 후 SHOW DATA 명령으로 테이블별 실제 디스크 사용량을 주기적으로 확인하고, 기대한 압축률이 나오지 않는다면 데이터 특성(카디널리티, NULL 비율 등)을 재점검해야 한다.\nSHOW DATA FROM warehouse.order_history; 압축 설정은 한 번 정하고 끝나는 것이 아니라, 데이터 특성과 워크로드가 변함에 따라 지속적으로 재검토해야 하는 영역이다. 이 글이 StarRocks 운영에서 압축 전략을 수립하는 데 실질적인 참고가 되길 바란다.\n","permalink":"https://NhoSW.github.io/my-tech-blog/ko/posts/starrocks-compression-guide/","summary":"StarRocks에서 압축 설정을 최적화하여 스토리지 비용을 절감하고 쿼리 성능을 향상시키는 방법을 실무 경험을 바탕으로 정리했습니다.","title":"StarRocks 압축 설정 가이드: 성능과 스토리지 최적화"},{"content":"운영자 정보 본 블로그는 노승우가 운영하며, 사이트 주소는 https://nhosw.github.io/my-tech-blog/ 입니다.\n수집하는 정보 Google Analytics 본 사이트는 방문자의 이용 현황을 파악하기 위해 Google Analytics 4(GA4)를 사용합니다. GA4는 다음 정보를 수집합니다:\n방문한 페이지 및 체류 시간 대략적인 위치 정보 (국가/도시 수준) 기기 유형, 브라우저, 운영체제 유입 경로 (사이트를 어떻게 찾았는지) Google Analytics는 쿠키를 사용하여 고유 방문자를 구분합니다. 개인을 식별할 수 있는 정보는 의도적으로 수집하지 않습니다.\n자세한 내용은 Google 개인정보처리방침을 참고하세요.\nGoogle AdSense 본 사이트는 Google AdSense를 통해 광고를 게재할 수 있습니다. AdSense는 쿠키와 웹 비콘을 사용하여 이전 방문 기록을 기반으로 광고를 제공합니다.\nGoogle은 DART 쿠키를 사용하여 브라우징 기록에 기반한 광고를 제공합니다 Google 광고 설정에서 맞춤 광고를 비활성화할 수 있습니다 자세한 내용은 Google AdSense 개인정보처리방침을 참고하세요.\n댓글 본 사이트는 현재 댓글 기능을 제공하지 않습니다. 향후 댓글 기능이 추가되면 본 방침을 업데이트하겠습니다.\n쿠키 쿠키는 사용자의 기기에 저장되는 작은 텍스트 파일입니다. 본 사이트는 다음 목적으로 쿠키를 사용합니다:\n분석: 사이트 트래픽 측정 (Google Analytics) 광고: 관련 광고 제공 (Google AdSense) 환경설정: 테마 설정 기억 (다크/라이트 모드) 브라우저 설정을 통해 쿠키를 제어할 수 있습니다. 쿠키를 비활성화하면 사이트 기능에 영향을 줄 수 있습니다.\n외부 링크 블로그 게시물에는 외부 웹사이트로의 링크가 포함될 수 있습니다. 외부 사이트의 개인정보 보호 관행에 대해서는 책임지지 않습니다.\n이용자의 권리 이용자는 다음 권리를 가집니다:\n수집되는 데이터에 대해 알 권리 추적 비활성화 (브라우저 설정 또는 Google 광고 설정) 본인 데이터에 대한 정보 요청 방침 변경 본 개인정보처리방침은 수시로 업데이트될 수 있습니다. 변경 사항은 이 페이지에 게시됩니다.\n문의 본 개인정보처리방침에 대해 궁금한 점이 있으시면 소개 페이지의 연락처로 문의해 주세요.\n최종 수정일: 2026년 2월 23일\n","permalink":"https://NhoSW.github.io/my-tech-blog/ko/privacy-policy/","summary":"개인정보처리방침","title":"개인정보처리방침"},{"content":"안녕하세요, 노승우입니다 저는 안정적이고 확장 가능한 데이터 인프라와 파이프라인을 구축하는 데이터 엔지니어입니다. 대규모 데이터의 수집, 변환, 서빙 과정에서 발생하는 다양한 문제를 해결하는 일에 보람을 느끼고 있습니다.\n블로그 소개 이 블로그는 실무에서 얻은 데이터 엔지니어링 지식을 공유하는 공간입니다. 실제 프로젝트에서 배운 교훈, 튜토리얼, 아키텍처 관련 의사결정, 그리고 데이터 분야에서 일하는 엔지니어분들께 도움이 될 만한 팁들을 다루고 있습니다.\n기술 스택 현재 주로 사용하고 있는 기술들입니다:\n스트림 처리: Apache Kafka 워크플로 오케스트레이션: Apache Airflow 쿼리 엔진: Trino, StarRocks 컨테이너 오케스트레이션: Kubernetes 언어: Python, SQL 인프라: Docker 연락처 GitHub: github.com/your-username LinkedIn: linkedin.com/in/your-profile 이메일: your-email@example.com 궁금한 점이나 제안 사항이 있으시면 편하게 연락 주세요!\n","permalink":"https://NhoSW.github.io/my-tech-blog/ko/about/","summary":"블로그 소개","title":"소개"}]