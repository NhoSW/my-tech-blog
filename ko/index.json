[{"content":"Joe Reis가 1,101명의 데이터 실무자를 대상으로 진행한 서베이 결과를 기반으로 2026년 데이터 엔지니어링 트렌드를 발표했다. 대규모 플랫폼의 데이터 엔지니어링 팀을 이끌고 있는 입장에서, 이 트렌드를 우리 팀의 현재 아키텍처와 대조하며 이미 잘 하고 있는 것과 앞으로 해야 할 것을 정리해본다.\n우리 아키텍처 한 줄 요약 # S3를 중심 데이터 레이크로 두고, Apache Iceberg 테이블 포맷 위에 Trino(배치/애드혹 분석)와 StarRocks(실시간 OLAP)를 얹은 하이브리드 구조다. 데이터 수집은 Kafka + Debezium CDC와 Flink 스트리밍, 오케스트레이션은 Airflow를 깊이 커스터마이징하여 운영하고 있다.\n[Services] → Kafka + Debezium CDC → Flink → S3 (Iceberg) ↓ ┌─────┴─────┐ │ │ Trino StarRocks (배치/애드혹) (실시간 OLAP) │ │ └─────┬─────┘ ↓ Dashboard 1. AI 활용 — 이미 하고 있는 것과 넘어야 할 벽 # 트렌드 요약 # 서베이 응답자의 82%가 AI를 매일 사용하고 있지만, 64%는 아직 실험 단계나 단순 작업에만 활용하고 있다. Joe Reis는 2026년 말이면 \u0026ldquo;AI-assisted\u0026quot;라는 수식어가 직무 기술에서 사라질 것이라 예측한다.\n우리가 하고 있는 것 # AI 코딩 도구를 활용한 파이프라인 개발은 이미 일상이 되었다. SQL 최적화, 코드 리뷰, 트러블슈팅 과정에서 LLM을 적극적으로 활용하고 있으며, 데이터 카탈로그와 연계한 자연어 기반 데이터 탐색도 시도하고 있다.\n해야 할 것 # 개인 단위의 AI 활용을 넘어서 팀 전체의 워크플로우에 AI를 임베드하는 것이 과제다.\n데이터 파이프라인 이상 감지 자동 스키마 진화 대응 데이터 품질 룰 자동 생성 Joe Reis가 말한 \u0026ldquo;10%의 AI-mature 팀\u0026quot;에 속하려면, AI를 단순 보조 도구가 아닌 플랫폼의 핵심 컴포넌트로 통합하는 전략이 필요하다.\n2. 데이터 모델링 위기와 시맨틱 레이어 — 가장 큰 숙제 # 트렌드 요약 # 응답자의 89%가 데이터 모델링에서 고통을 호소하고 있고, 시맨틱 모델을 사용하는 팀은 고작 5%다. Joe Reis는 시맨틱 레이어가 먼저 주류가 되고, 이후 LLM이 스키마를 즉석에서 해석하는 방향으로 진화할 것이라 본다.\n우리가 하고 있는 것 # 데이터 카탈로그를 통해 리니지와 메타데이터를 관리하고 있고, 테이블 레이어 체계(L1/L2/L3)를 정의하여 데이터 품질을 계층적으로 관리하려는 시도를 진행 중이다. Airflow 커스텀 오퍼레이터를 통한 데이터 검증 자동화도 운영하고 있다.\n해야 할 것 # dbt 도입을 검토했으나 차세대 데이터 플랫폼 전환 전략과 맞물려 중단된 상태다. 현재 파이프라인을 dbt로 이관하기보다는 새로운 플랫폼으로 직접 이관하는 방향을 검토하고 있지만, 그 사이 데이터 변환의 표준화와 모듈화가 공백으로 남아있다. 이것이 Joe Reis가 말한 \u0026ldquo;89%의 고통\u0026quot;과 정확히 일치하는 부분이다.\n시맨틱 레이어 역시 미답 영역이다. 비즈니스 메트릭의 정의가 팀마다 다르고, 동일한 지표에 대해 서로 다른 SQL을 사용하는 문제가 존재한다. 서베이에서 시맨틱 모델 교육 수요가 19%로 높게 나온 것처럼, 조직 전체의 데이터 리터러시를 끌어올리는 작업이 시급하다.\n특히 AI 에이전트가 데이터를 자율적으로 활용하는 미래를 대비하면, 잘 정의된 시맨틱 레이어는 선택이 아닌 필수다. 플랫폼 전환이 지연되더라도 모델링 표준과 시맨틱 정의는 독립적으로 진행할 수 있고, 진행해야 한다.\n3. 오케스트레이션 통합 — Airflow의 미래 # 트렌드 요약 # Airflow가 여전히 지배적이지만, Dagster가 소규모 기업에서 12%의 점유율을 보이며 바텀업으로 성장하고 있다. 오케스트레이션이 아예 없는 팀이 모든 기업 규모에서 20%라는 점도 놀랍다.\n우리가 하고 있는 것 # Airflow를 깊이 커스터마이징하여 운영하고 있다. 자체 Provider 패키지를 개발하고, 데이터 검증 자동화 오퍼레이터, 커스텀 전송 오퍼레이터 등 플랫폼에 특화된 기능을 구현했다. 현재 Airflow 3.x 메이저 버전 업그레이드를 진행 중이며, Python 버전 업그레이드와 Breaking Change 대응을 체계적으로 계획하고 있다.\n해야 할 것 # Airflow에 대한 깊은 투자는 강점이지만, 동시에 기술 부채이기도 하다.\n커스텀 Provider의 유지보수 부담 버전 업그레이드 시 호환성 이슈 AI 에이전트 오케스트레이션이라는 새로운 패러다임에 대한 대비 Joe Reis가 예측한 것처럼 오케스트레이션이 플랫폼에 흡수되는 방향도 지켜봐야 한다. 차세대 데이터 플랫폼과의 정합성을 고려하면, 오케스트레이션 전략의 중장기적 로드맵 수립이 시급하다.\n4. Lakehouse vs. Warehouse — 이미 답을 낸 영역 # 트렌드 요약 # 서베이에서 44%가 Warehouse, 27%가 Lakehouse, 12%가 Hybrid를 사용하고 있다. Snowflake과 Databricks의 기능이 수렴하면서 이 논쟁 자체가 무의미해지고 있다. Joe Reis는 2026년 말이면 \u0026ldquo;warehouse vs. lakehouse\u0026rdquo; 논쟁이 구식으로 느껴질 것이라 예측한다.\n우리가 하고 있는 것 # 이 트렌드에서 우리 팀은 이미 정답에 가까운 위치에 있다. S3 위에 Iceberg 오픈 테이블 포맷을 표준으로 채택하고, 용도에 따라 Trino와 StarRocks를 선택적으로 사용하는 구조는 Warehouse도 Lakehouse도 아닌, 양쪽의 장점을 취한 아키텍처다. CDC 파이프라인을 통해 실시간 데이터를 Iceberg 테이블로 적재하고, 배치와 실시간 분석을 동일한 데이터 위에서 수행할 수 있다.\n해야 할 것 # Iceberg v3의 Deletion Vector, Row Lineage 등 새로운 기능을 적극 활용하기 위해서는 쿼리 엔진 전반의 호환성 확보가 필요하다. 현재 Trino와 StarRocks의 Iceberg v3 지원이 제한적이므로, 엔진 업그레이드 로드맵과 Iceberg 버전 전략을 연계해야 한다. 또한 오픈 테이블 포맷 기반 아키텍처의 거버넌스 체계 — 카탈로그 통합, 접근 제어, 데이터 품질 보장 — 를 더 강화해야 한다.\n5. 리더십이 병목이 되는 문제 — 가장 어렵고 가장 중요한 과제 # 트렌드 요약 # 데이터 엔지니어의 22%가 \u0026ldquo;리더십 방향 부재\u0026quot;를 주요 이슈로 꼽았고, 이는 레거시 기술 부채(26%)에 버금가는 수치다. Joe Reis는 2026년에 더 많은 데이터 팀이 해체되거나 엔지니어링 조직에 합병될 것이라 경고한다.\n우리가 하고 있는 것 # 데이터 플랫폼 팀이 독립적인 조직으로 존재하며, 인프라부터 수집, 변환, 분석 환경까지 End-to-End로 책임지는 구조를 갖추고 있다. 비즈니스 팀과의 직접적인 소통 채널을 유지하며, 데이터 요건을 직접 수렴하고 있다.\n해야 할 것 # 기술적 역량만으로는 팀의 존재 가치를 증명할 수 없다. Joe Reis가 강조한 것처럼 \u0026ldquo;비즈니스 가치를 증명한 팀만 살아남는다.\u0026rdquo;\n데이터 플랫폼의 ROI를 정량적으로 측정하고 커뮤니케이션하는 체계 AI 시대에 데이터 플랫폼이 어떤 역할을 해야 하는지에 대한 비전 수립 데이터 옵저버빌리티 도입을 통한 데이터 다운타임 감소 파이프라인 개발 생산성 지표화 등 구체적인 비즈니스 임팩트 제시 정리: 잘 하고 있는 것 vs. 해야 할 것 # 영역 잘 하고 있는 것 해야 할 것 AI 활용 개인 단위 AI 코딩 도구 적극 활용 팀 워크플로우에 AI 임베드, 운영 자동화 데이터 모델링 카탈로그 기반 메타데이터 관리, 레이어 체계 정의 시맨틱 레이어 도입, 데이터 변환 표준화 오케스트레이션 Airflow 깊은 커스터마이징, 3.x 업그레이드 진행 장기 오케스트레이션 전략, AI 에이전트 대응 Lakehouse/Warehouse Iceberg 기반 하이브리드 아키텍처 구축 완료 Iceberg v3 호환성, 거버넌스 체계 강화 리더십 End-to-End 플랫폼 팀 운영 비즈니스 임팩트 정량화, 데이터 옵저버빌리티 마치며 # Joe Reis의 서베이에서 가장 인상적이었던 문장은 이것이다.\n\u0026ldquo;2026년 데이터 엔지니어링은 올바른 도구를 고르는 것보다 그 도구를 잘 활용할 조직적 근육을 키우는 것이 더 중요하다.\u0026rdquo;\n우리 팀은 기술 스택 면에서 트렌드의 앞쪽에 서 있다. Iceberg 기반 오픈 데이터 레이크, 실시간과 배치를 아우르는 하이브리드 아키텍처, 깊이 있는 Airflow 커스터마이징 등은 많은 조직이 아직 도달하지 못한 수준이다.\n하지만 기술적 우위만으로는 충분하지 않다. 데이터 변환 표준화, 시맨틱 레이어, 데이터 옵저버빌리티, AI 네이티브 워크플로우, 그리고 무엇보다 비즈니스 가치를 증명하는 리더십 — 이것이 2026년에 우리가 집중해야 할 방향이다.\n과거의 빚은 이자를 물고 있고, 페이데이가 다가오고 있다.\n원문 참고: Where Data Engineering Is Heading in 2026 — Joe Reis\n","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/posts/2026-data-engineering-trends/","section":"글 목록","summary":"Joe Reis의 1,101명 서베이를 기반으로 한 2026년 데이터 엔지니어링 트렌드를, 대규모 플랫폼 데이터 엔지니어링 팀의 현재 아키텍처와 대조하며 정리했습니다. 이미 잘 하고 있는 것과 앞으로 해야 할 것을 솔직하게 돌아봅니다.","title":"2026 데이터 엔지니어링 트렌드와 대규모 플랫폼의 현주소","type":"posts"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/ai/","section":"Tags","summary":"","title":"Ai","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/airflow/","section":"Tags","summary":"","title":"Airflow","type":"tags"},{"content":"Airflow 2.x의 End of Life가 2026년 4월 22일로 다가오고 있다. 우리 팀은 수백 개의 DAG을 운영하는 프로덕션 환경에서 Airflow 3.x 마이그레이션을 진행했다. 이 글은 그 과정에서 마주친 Breaking Changes, 단계적 업그레이드 전략, 그리고 대규모 DAG 환경에서의 실전 교훈을 정리한 기록이다.\n왜 지금 마이그레이션해야 하는가 # Airflow 3.x의 핵심 개선사항 # Airflow 3.x는 단순한 메이저 버전 업데이트가 아니다. 아키텍처 수준에서 근본적인 변화가 일어났다.\nDAG 버전 관리: dag_id에 버전 서픽스를 붙이거나, 스케줄 변경 시 스케줄링이 꼬이는 문제에서 해방된다. 네이티브 백필: CLI나 커스텀 플러그인에 의존하던 백필이 웹 UI에서 직접 지원된다. 이벤트/애셋 기반 트리거: 단순 cron 표현식을 넘어 다양한 스케줄링 방식을 제공한다. React 기반 웹 UI: Flask App Builder 기반에서 React로 전면 개편되어 사용성이 크게 향상되었다. 아키텍처 변화: API Server의 등장 # 3.x에서 가장 큰 아키텍처 변화는 API Server가 메타 DB에 접근하는 유일한 관문이 되었다는 점이다.\nAirflow 2.x: Webserver ─── MetaDB Worker ────── MetaDB Scheduler ─── MetaDB DAG Code ──── MetaDB (직접 접근 가능) Airflow 3.x: API Server ── MetaDB (유일한 접근 경로) Webserver ─── API Server Worker ────── API Server Scheduler ─── API Server DAG Code ──── API Server (직접 접근 불가) 이 변화로 인해 DAG 최상위 코드에서 메타 DB에 직접 접근하던 모든 패턴이 깨진다. 이것이 마이그레이션에서 가장 큰 영향을 미치는 변경사항이다.\n단계적 업그레이드 전략 # 한 번에 최신 버전으로 올리는 것은 위험하다. 우리는 4단계 전략을 수립했다.\n1단계: 2.x 최신 버전(2.11)으로 업데이트 (선택) # 3.x로 직접 올리는 과정에서 이슈가 발생할 경우를 대비한 안전장치다. 2.11에서는 3.x에서 제거될 기능들에 대한 deprecation 경고가 표시되므로, 어떤 코드를 수정해야 하는지 사전에 파악할 수 있다.\n2단계: 3.0.x로 업데이트 # Python 3.9 환경에서는 최신 3.1.x가 아닌 3.0.x까지만 지원된다. Python 버전 업그레이드 전에 Airflow 메이저 버전을 먼저 올린다.\n3단계: Python 버전 업그레이드 (3.9 → 3.12+) # Airflow 3.1.x는 Python 3.9를 지원하지 않는다. Python 3.12 이상을 목표로 하되, 의존성 호환 이슈가 있으면 3.10이나 3.11로 타협한다.\n4단계: 3.1.x로 업데이트 # 최종적으로 최신 stable 릴리스로 올린다.\n환경별 순차 적용 # DEV → BETA \u0026amp; 개인환경 → STAGE → PROD 각 환경에서 충분한 검증을 거친 후 다음 환경으로 진행한다. 우리는 DEV 환경에서 약 2주, BETA에서 1주의 검증 기간을 가졌다.\n주요 Breaking Changes와 대응 방법 # 1. schedule_interval → schedule # 가장 흔하게 마주치는 변경사항이다. 기존 schedule_interval에 전달하던 cron 표현식을 그대로 schedule에 전달하면 된다.\n# Before (Airflow 2.x) DAG( dag_id=\u0026#34;my_dag\u0026#34;, schedule_interval=\u0026#34;5 2 * * *\u0026#34;, ) # After (Airflow 3.x) DAG( dag_id=\u0026#34;my_dag\u0026#34;, schedule=\u0026#34;5 2 * * *\u0026#34;, ) 단순 치환이지만, DAG 수가 수백 개라면 누락 없이 전부 바꿔야 한다. CI에서 자동 검증하는 방법은 뒤에서 다룬다.\n2. 존재하지 않는 오퍼레이터 인자 전달 불가 # Airflow 3.x에서는 개별 태스크가 메타 DB상에 시리얼라이즈된 DAG을 받아 실행하도록 변경되었다. 이로 인해 allow_illegal_arguments 설정이 제거되고, 오퍼레이터에 정의되지 않은 인자를 전달하면 DAG 임포트 자체가 실패한다.\n# 이런 코드가 2.x에서는 경고 없이 동작했지만, 3.x에서는 에러가 발생한다 MyOperator( task_id=\u0026#34;my_task\u0026#34;, num_partition=10, # 실제 인자명은 num_partitions (복수형) ) TypeError: Invalid arguments were passed to MyOperator (task_id: my_task). Invalid arguments were: **kwargs: {\u0026#39;num_partition\u0026#39;: 10} 이 변경은 오히려 잠재적 버그를 발견하는 계기가 된다. 오랫동안 오타가 있는 인자가 무시되고 있었다면, 이번 마이그레이션에서 바로잡을 수 있다.\n3. Deprecated 컨텍스트/템플릿 변수 제거 # 2.x에서 deprecated 경고만 뜨던 변수들이 3.x에서는 완전히 제거되었다. 가장 영향이 큰 것은 execution_date다.\nDeprecated 변수 대체 변수 {{ execution_date }} {{ logical_date }} 또는 {{ data_interval_start }} {{ next_execution_date }} {{ data_interval_end }} {{ prev_execution_date_success }} {{ prev_data_interval_start_success }} Jinja 템플릿과 Python 코드 양쪽 모두 수정해야 한다.\n# Jinja 템플릿 # Before \u0026#34;SELECT * FROM table WHERE dt = \u0026#39;{{ execution_date }}\u0026#39;\u0026#34; # After \u0026#34;SELECT * FROM table WHERE dt = \u0026#39;{{ logical_date }}\u0026#39;\u0026#34; # Python context # Before execution_date = context[\u0026#34;execution_date\u0026#34;] # After logical_date = context[\u0026#34;logical_date\u0026#34;] 4. DB별 Operator 통합 → SQLExecuteQueryOperator # MySQL, PostgreSQL, Trino 등 DB별로 개별 존재하던 Operator가 하나의 SQLExecuteQueryOperator로 통합되었다. 내부적으로 커넥션 타입에 따라 적절한 Hook을 자동으로 선택한다.\n# Before (Airflow 2.x) from airflow.providers.mysql.operators.mysql import MySqlOperator MySqlOperator( task_id=\u0026#34;task\u0026#34;, mysql_conn_id=\u0026#34;my_conn\u0026#34;, sql=\u0026#34;SELECT 1\u0026#34; ) # After (Airflow 3.x) from airflow.providers.common.sql.operators.sql import SQLExecuteQueryOperator SQLExecuteQueryOperator( task_id=\u0026#34;task\u0026#34;, conn_id=\u0026#34;my_conn\u0026#34;, # DB별 conn_id → 통합 conn_id sql=\u0026#34;SELECT 1\u0026#34; ) 5. DummyOperator → EmptyOperator # 2.x와 3.x 양쪽에서 모두 동작하는 임포트 경로를 사용해야 한다.\n# v2에서만 동작 (3.x에서 에러) from airflow.operators.dummy import DummyOperator # v3에서만 동작 from airflow.providers.standard.operators.empty import EmptyOperator # v2 \u0026amp; v3 모두 호환 (권장) from airflow.operators.empty import EmptyOperator 6. SimpleHttpOperator → HttpOperator # # Before from airflow.providers.http.operators.http import SimpleHttpOperator # After from airflow.providers.http.operators.http import HttpOperator 7. Connection getter 메서드 → 속성 직접 참조 # Connection 클래스의 인터페이스가 더 Pythonic하게 변경되었다.\n# Before conn = BaseHook.get_connection(\u0026#34;my_conn\u0026#34;) password = conn.get_password() host = conn.get_host() # After conn = BaseHook.get_connection(\u0026#34;my_conn\u0026#34;) password = conn.password host = conn.host 8. 기타 패키지 경로 변경 # # cached_property # Before: from airflow.compat.functools import cached_property # After: from functools import cached_property (Python 내장) # KubernetesPodOperator # Before: from airflow.providers.cncf.kubernetes.operators.kubernetes_pod import ... # After: from airflow.providers.cncf.kubernetes.operators.pod import ... 대규모 DAG 환경에서의 마이그레이션 전략 # CI 파이프라인에 v3 호환성 검증 추가 # 수백 개의 DAG을 수동으로 검증하는 것은 불가능하다. MR(Merge Request) 단계에서 v3 호환성을 자동으로 검증하는 CI 잡을 추가했다.\n# .gitlab-ci.yml 예시 airflow-v3-compat-check: stage: test image: apache/airflow:3.0.6-python3.12 script: - pip install -r requirements.txt - python -m py_compile dags/**/*.py - airflow dags list --output table allow_failure: true # 초기에는 경고만, 이후 필수로 전환 처음에는 allow_failure: true로 시작해서 현황을 파악하고, 마이그레이션 기한이 다가오면 필수 검증으로 전환한다.\n이관 허들을 의도적으로 높여라 # 이것이 우리가 얻은 가장 중요한 교훈이다.\n모든 DAG 코드에 일괄 호환성 패치를 적용할 수도 있었다. 하지만 우리는 의도적으로 이관 난이도를 유지하기로 결정했다. 이유는 명확하다.\n관성적으로 운영되고 있지만 실제로는 사용하지 않는 DAG이 상당수 존재한다.\n마이그레이션을 계기로 DAG 소유자들이 **\u0026ldquo;이 DAG이 정말 필요한가?\u0026rdquo;**를 스스로 검토하도록 유도한 것이다. 결과적으로 상당수의 불필요한 DAG이 정리되었고, 이는 운영 부담 감소로 이어졌다.\n구체적인 프로세스:\n비활성 DAG 목록을 취합하여 공유 시트에 정리 DAG 소유자/소속 부서에 유지 필요 여부를 기한 내 확인하도록 안내 기한 내 응답 없으면 비활성화 v3 호환성 패치는 소유자가 직접 수행 커스텀 Provider 패키지 선제 대응 # 사내 커스텀 오퍼레이터나 유틸리티를 Provider 패키지로 제공하고 있다면, Airflow 코어의 Breaking Changes를 흡수하는 호환 레이어를 먼저 준비하는 것이 핵심이다.\n우리는 커스텀 Provider 패키지를 4차례에 걸쳐 점진적으로 업데이트했다.\nv3.0.0: 기본 호환성 확보 v3.0.1: 오퍼레이터 인자 검증 대응 v3.0.2: deprecated 컨텍스트 변수 호환 레이어 추가 v3.0.3: 문서 및 마이너 버그 수정 사용자 코드의 변경은 최소화하되, Provider 패키지 내부에서 v2/v3 분기 처리를 하는 방식으로 접근했다.\nHelm Chart 업데이트 # Kubernetes 환경에서 Airflow를 운영한다면 Helm Chart도 함께 업데이트해야 한다. 3.x에서 도입된 DAG Processor 컴포넌트와 API Server 분리를 반영해야 하기 때문이다.\n우선 기존 차트 버전에서 호환성을 확인한 후, 안정화되면 최신 stable 버전으로 업데이트하는 2단계 접근이 안전하다.\nFAB Auth Manager 이슈 # 3.x에서 React 기반으로 웹이 전면 개편되면서, 기존 Flask App Builder(FAB) 기반 Auth Manager가 기본 패키지에서 제거되었다. 커스텀 Security Manager를 사용하고 있다면 추가 설치와 코드 수정이 필요하다.\nFailed to import WoowaSecurityManager, using default security manager 이런 에러가 발생하면 FAB Auth Manager 패키지를 명시적으로 설치하고, 임포트 경로를 업데이트해야 한다.\n마치며 # Airflow 3.x 마이그레이션은 단순한 버전 업그레이드가 아니다. 아키텍처 변화(API Server 중심), 코드 호환성 변경, 인프라 업데이트까지 광범위한 작업이 필요하다.\n핵심 교훈을 정리하면 다음과 같다.\n단계적으로 올려라 — 한 번에 최신 버전으로 뛰지 말고, 2.11 → 3.0.x → Python 업그레이드 → 3.1.x 순서로 진행하라. CI에서 자동 검증하라 — 수백 개 DAG의 호환성을 사람이 확인하는 건 불가능하다. 마이그레이션을 정리의 기회로 삼아라 — 이관 허들을 의도적으로 유지해서 불필요한 DAG을 자연스럽게 걸러내라. 커스텀 Provider를 선제 업데이트하라 — 사용자 코드의 변경을 최소화하는 호환 레이어가 핵심이다. Airflow 2.x EOL까지 아직 시간이 있다고 안심하지 말자. 대규모 환경에서의 마이그레이션은 예상보다 오래 걸린다. 지금 시작해도 늦지 않다.\n참고 자료:\nUpgrading to Airflow 3 - Apache Airflow Documentation Apache Airflow 3 is Generally Available! Airflow 3.x Release Notes ","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/posts/airflow-3-migration-guide/","section":"글 목록","summary":"Airflow 2.x EOL을 앞두고 3.x로 마이그레이션한 실전 경험을 공유한다. 주요 Breaking Changes, 단계적 업그레이드 전략, DAG 호환성 확보 방법, 그리고 수백 개의 DAG을 운영하는 환경에서 배운 교훈을 정리했다.","title":"Airflow 3.0 마이그레이션 가이드: 대규모 DAG 환경에서의 실전 경험","type":"posts"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/bali/","section":"Tags","summary":"","title":"Bali","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/compression/","section":"Tags","summary":"","title":"Compression","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/categories/data-engineering/","section":"Categories","summary":"","title":"Data Engineering","type":"categories"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/data-engineering/","section":"Tags","summary":"","title":"Data-Engineering","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/data-pipeline/","section":"Tags","summary":"","title":"Data-Pipeline","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/digital-nomad/","section":"Tags","summary":"","title":"Digital-Nomad","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/family/","section":"Tags","summary":"","title":"Family","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/iceberg/","section":"Tags","summary":"","title":"Iceberg","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/kafka/","section":"Tags","summary":"","title":"Kafka","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/lakehouse/","section":"Tags","summary":"","title":"Lakehouse","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/categories/life/","section":"Categories","summary":"","title":"Life","type":"categories"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/migration/","section":"Tags","summary":"","title":"Migration","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/olap/","section":"Tags","summary":"","title":"Olap","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/open-source/","section":"Tags","summary":"","title":"Open-Source","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/optimization/","section":"Tags","summary":"","title":"Optimization","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/orchestration/","section":"Tags","summary":"","title":"Orchestration","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/","section":"OTL - 데이터 엔지니어링","summary":"","title":"OTL - 데이터 엔지니어링","type":"page"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/performance-tuning/","section":"Tags","summary":"","title":"Performance-Tuning","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/python/","section":"Tags","summary":"","title":"Python","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/real-time/","section":"Tags","summary":"","title":"Real-Time","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/remote-work/","section":"Tags","summary":"","title":"Remote-Work","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/starburst/","section":"Tags","summary":"","title":"Starburst","type":"tags"},{"content":"Trino를 프로덕션 쿼리 엔진으로 운영하는 팀이라면, 2025년 한 해 동안 느꼈을 것이다. 릴리스가 뜸해졌다. 감각의 문제가 아니라 숫자로 드러나는 변화다. 2024년 30개였던 Trino 오픈소스 릴리스가 2025년에는 11개로 줄었다. 63% 감소.\n이 글에서는 Starburst가 왜, 어떻게 AI 중심 플랫폼 기업으로 전환했는지를 분석하고, Trino 오픈소스 사용자 입장에서 이 변화를 어떻게 바라봐야 하는지 정리한다.\nTrino 릴리스, 무슨 일이 일어났나 # 릴리스 빈도의 급격한 변화 # Trino 오픈소스의 릴리스 패턴을 분기별로 보면, 감소 추세가 뚜렷하다.\n기간 릴리스 수 평균 주기 비고 2024 Q4 9개 주 1회 안정적 패턴 2025 Q1 6개 2주 1회 감소 시작 2025 Q2 2개 월 1회 급격한 감소 2025 Q3 1개 분기 1회 최저점 2025 Q4 2개 1.5개월 1회 여전히 저조 2024년 Q4까지만 해도 매주 새 릴리스가 나왔다. 그런데 2025년 Q2부터 월 1회 수준으로 떨어졌고, Q3에는 분기 전체에 릴리스가 단 1개였다. Starburst Enterprise 릴리스도 마찬가지로 극소수에 그쳤다.\n숫자만 놓고 보면 심각해 보이지만, 이것이 Trino의 \u0026ldquo;쇠퇴\u0026quot;를 의미하는 건 아니다. Starburst의 전략적 선택이다.\n왜 줄었는가 # Trino 오픈소스에 대한 Starburst의 기여도를 보면 답이 보인다. 2024년 기준으로 Starburst 팀이 Trino 전체 커밋의 **84%**를 차지했다. 138명의 기여자, 2,822개 커밋, 50개 이상 기업이 참여했지만, 실질적인 개발 동력은 Starburst였다. 그 Starburst가 엔지니어링 리소스를 다른 곳에 집중하기 시작한 것이다.\n그 \u0026ldquo;다른 곳\u0026quot;이 바로 AI다.\nStarburst의 AI 피벗 # 포지셔닝의 변화 # Starburst의 공식 메시징 변화를 추적하면, 전환이 얼마나 의도적이었는지 알 수 있다.\n시기 포지셔닝 핵심 메시지 ~2023 Open Data Lakehouse Company Trino 기반 분산 쿼리 엔진 2024 Data Lake Analytics Platform 페더레이션 쿼리 + Iceberg 2025 Data Platform for Apps and AI AI Agent + Agentic Workforce \u0026ldquo;Open Data Lakehouse\u0026quot;에서 \u0026ldquo;Data Platform for Apps and AI\u0026quot;로. 단순한 마케팅 변화가 아니라, 제품 로드맵 전체가 이 방향으로 정렬되었다.\n2025년 주요 발표 타임라인 # 2025년 5월 — Launch Point\nStarburst는 AI Agent와 AI Workflows를 공식 발표했다.\nAI Agent: 자연어로 데이터를 쿼리하는 인터페이스. \u0026ldquo;What were our sales in Europe last quarter?\u0026ldquo;라는 질문이 자동으로 SQL로 변환된다. Air-gapped 환경(금융, 의료, 정부)을 명시적으로 지원하며, Google의 Agent2Agent 프로토콜과 Anthropic의 Model Context Protocol(MCP)을 지원한다. AI Workflows: Vector embeddings를 Iceberg 테이블에 저장하고, 구조화/반구조화/비구조화 데이터를 AI 학습에 활용할 수 있는 파이프라인. RAG(Retrieval-Augmented Generation)를 네이티브로 지원한다. 기타: Starburst Data Catalog(Hive Metastore 대체), Automated Table Maintenance(파일 정리 및 컴팩션 자동화), Native ODBC Driver, Role-based Query Routing 2025년 10월 — AI \u0026amp; Datanova 2025\n여기서 Starburst는 Agentic Workforce 플랫폼과 Lakeside AI Architecture를 발표하며 한 단계 더 나아갔다.\n핵심 개념은 Model-to-Data 아키텍처다. 기존의 접근 방식이 데이터를 중앙 웨어하우스로 모은 뒤 AI 모델을 돌리는 것이었다면, Starburst는 AI 모델을 데이터가 있는 곳으로 보내는 방식을 제안한다.\n기존 접근: Data → Centralized Warehouse → AI Model Starburst: AI Model → Federated Data (where it lives) 데이터를 이동시키지 않으므로 데이터 주권(GDPR, Schrems II)을 유지하면서도 통합 분석이 가능하다는 논리다. Citi, HSBC 같은 글로벌 금융기관이 165개국에 흩어진 데이터를 이 방식으로 통합하고 있다고 한다.\n기술 스택의 변화 # Starburst의 기술 스택을 레이어로 표현하면, 2025년에 추가된 부분이 명확히 보인다.\n┌─────────────────────────────────────┐ │ AI Agent \u0026amp; Agent2Agent Protocol │ ← 2025 NEW ├─────────────────────────────────────┤ │ AI Workflows (Vector Store) │ ← 2025 NEW ├─────────────────────────────────────┤ │ Starburst Data Catalog │ ← 2025 NEW ├─────────────────────────────────────┤ │ Lakehouse (Trino + Iceberg) │ ├─────────────────────────────────────┤ │ Federated Data Sources (50+) │ └─────────────────────────────────────┘ Trino는 여전히 기반 레이어에 있지만, 혁신은 전부 위에서 일어나고 있다. Trino 오픈소스 릴리스가 줄어든 이유가 여기에 있다. 엔지니어링 리소스가 상위 레이어로 이동한 것이다.\nVector Store on Iceberg: 주목할 만한 기술적 혁신 # 2025년 Starburst 발표 중 기술적으로 가장 흥미로운 것은 Apache Iceberg 테이블에 직접 vector embeddings를 저장하는 접근이다.\n이게 왜 의미 있는가:\n별도의 벡터 DB가 필요 없다. Pinecone, Weaviate, Milvus 같은 전용 벡터 데이터베이스를 운영할 필요가 없어진다. 기존 데이터 엔지니어링 스킬을 그대로 활용한다. Iceberg 테이블을 다루는 방식 그대로 벡터 데이터를 관리할 수 있다. Iceberg의 장점이 벡터 데이터에도 적용된다. Time travel, ACID 트랜잭션, 스키마 진화, 파티셔닝 등을 벡터 데이터에도 활용할 수 있다. 거버넌스 정책이 일관성 있게 적용된다. 구조화 데이터와 벡터 데이터에 동일한 접근 제어, 감사 로그, 데이터 마스킹 정책을 적용할 수 있다. 오픈 포맷이므로 vendor lock-in이 없다. AI 워크로드가 데이터 플랫폼의 핵심 요구사항이 되는 미래를 가정하면, 이 접근은 상당히 실용적이다. 물론 전용 벡터 DB 대비 검색 성능은 트레이드오프가 있을 수 있지만, 운영 복잡도 감소와 거버넌스 통합이라는 장점은 엔터프라이즈 환경에서 매력적이다.\n비즈니스 성과: 전략이 시장에서 통하고 있는가 # AI 피벗이 단순한 마케팅이 아니라는 것은 비즈니스 지표가 증명한다.\nFY25 실적 (2025년 2월 발표):\n지표 성과 신규 고객 전년 대비 20% 증가 Galaxy(SaaS) 고객 전년 대비 76% 증가 Galaxy 사용량 전년 대비 94% 증가 최대 계약 글로벌 금융기관과 8자리(억 단위) 다년 계약 파트너십 Dell Data Lakehouse의 쿼리 엔진으로 선정 특히 Galaxy(SaaS) 고객이 76% 증가했다는 것은 주목할 만하다. 클라우드 매니지드 서비스로의 전환이 가속화되고 있다는 의미이고, 이는 오픈소스 Trino를 직접 운영하는 팀들의 대안이기도 하다.\n주요 고객사도 인상적이다:\nHSBC: 165개국 데이터 통합 Citi: 글로벌 데이터 주권 유지하며 통합 분석 Vectra AI: 120개국 위협 탐지 플랫폼 ZoomInfo: 멀티클라우드 데이터 통합 경쟁 환경에서의 포지셔닝 # 데이터 플랫폼 시장에서 Starburst의 위치를 경쟁사와 비교하면 차별화 포인트가 명확해진다.\n기능 Databricks Snowflake Dremio Starburst AI Agent O O X O Federated Query 제한적 제한적 O 핵심 강점 Data Sovereignty 제한적 제한적 제한적 핵심 강점 오픈소스 기반 Spark X Arrow Trino Vector Store O O X O (Iceberg) On-prem + Cloud O 제한적 O 핵심 강점 Starburst의 핵심 차별화는 세 가지다:\n진정한 페더레이션: 50개 이상 데이터 소스에 대한 실시간 쿼리. 데이터를 이동시키지 않고 제자리에서 분석한다. 데이터 주권: 165개국 규제를 준수하면서 통합 분석을 제공한다. GDPR, Schrems II 환경에서 결정적 장점이다. 하이브리드 배포: On-premise와 멀티 클라우드를 동시에 지원한다. 규제 산업에서 클라우드 전환이 더딘 기업들에게 핵심 가치다. 반면 Databricks는 Spark + Delta Lake 중심의 AI/ML Lakehouse로, Unity Catalog으로 거버넌스를 강화하고 있다. Snowflake는 2024년 Iceberg 지원을 추가하고 Snowpark으로 AI/ML을 밀고 있지만, 여전히 데이터 중앙화가 전제다. Dremio는 Arrow Flight 기반 성능과 시맨틱 레이어를 강조하지만, 엔터프라이즈 기능에서는 아직 격차가 있다.\n흥미로운 것은 Starburst CEO Justin Borgman의 발언이다: \u0026ldquo;What they\u0026rsquo;ve done for Spark is what we aim to do for Presto(Trino).\u0026rdquo; Databricks가 Spark 오픈소스 위에 강력한 상용 플랫폼을 구축한 것처럼, Starburst도 Trino 위에 같은 구조를 만들겠다는 것이다.\nTrino 오픈소스, 괜찮을 것인가 # 오픈소스와 상용 기능의 분리 # 현재 Trino 오픈소스에 남아있는 것과 Starburst 전용으로 넘어간 것을 정리하면 다음과 같다.\nTrino 오픈소스:\n핵심 쿼리 엔진 기본 커넥터들 Fault-tolerant execution SQL MERGE 기본 보안 기능 Starburst 전용:\nWarp Speed (최대 7배 성능 향상) AI Agent \u0026amp; AI Workflows Starburst Data Catalog 고급 거버넌스 (RBAC, 데이터 마스킹, 감사 로그) Automated Table Maintenance Smart Indexing Materialized Views (일부) 가장 눈에 띄는 것은 Warp Speed다. 최대 7배 성능 향상을 제공하는 독점 인덱싱/캐싱 레이어가 상용 전용이라는 것은, 대규모 워크로드에서 오픈소스와 상용 제품의 성능 격차가 점점 벌어질 수 있다는 의미다.\n낙관적으로 볼 수 있는 근거 # Trino 코어 엔진은 성숙 단계에 접어들었다. 분산 SQL 쿼리 엔진으로서 필요한 기능은 대부분 갖추고 있다. 릴리스 빈도가 줄었다고 품질이 떨어지는 것은 아니다. 커뮤니티는 여전히 활발하다. Trino Summit 2024는 Netflix, LinkedIn, Wise 등이 참여하며 성공적으로 개최되었고, Trino Community Broadcast도 지속 운영 중이다. Slack과 GitHub 활동도 유지되고 있다. 50개 이상 기업이 기여하고 있다. Starburst의 기여가 줄더라도 다른 기업들이 메울 여지는 있다. 우려할 점 # 84%의 커밋을 한 회사가 다른 곳에 집중하기 시작했다. 다른 기업들이 이 공백을 메울 인센티브가 충분한지는 미지수다. 성능 최적화의 핵심이 상용 전용이다. Warp Speed 없이 대규모 워크로드를 운영하는 팀은 갈수록 불리해질 수 있다. AI 관련 혁신이 모두 상용 제품에 집중되어 있다. 데이터 플랫폼에 AI가 필수가 되는 미래에서, 오픈소스만으로는 경쟁력 확보가 어려워질 수 있다. Trino 운영 팀이 고려해야 할 것 # Trino를 프로덕션에서 운영하는 팀의 입장에서, 이 상황을 두 가지 시간 축으로 나눠서 생각해 볼 수 있다.\n단기 (1~2년): 큰 문제 없다 # Trino 오픈소스는 여전히 안정적이고 프로덕션에서 검증된 기술이다. 핵심 기능은 충분히 성숙했고, 기본적인 쿼리 성능과 커넥터 생태계는 탄탄하다. 당장 대안으로 갈아타야 할 이유는 없다.\n중장기 (3~5년): 전략적 대비가 필요하다 # 오픈소스와 상용 제품의 기능 격차가 확대될 가능성을 감안해야 한다. 특히 다음 영역에서의 대비가 필요하다:\n성능 최적화: Warp Speed 없이 대규모 워크로드의 성능을 어떻게 확보할 것인가. 자체적인 캐싱 레이어, 인덱싱 전략, 또는 StarRocks 같은 보완 엔진의 역할 확대를 검토해야 한다. AI 통합: 데이터 플랫폼에 AI를 통합하는 것이 조직의 요구사항이 될 때, 오픈소스 Trino만으로 충분한지 평가해야 한다. Vector Store on Iceberg 같은 접근을 자체적으로 구현할 수 있는지, 혹은 다른 도구와의 조합이 필요한지. 거버넌스: 조직이 커지고 규제가 강화될수록, 고급 거버넌스 기능(RBAC, 데이터 마스킹, 감사 로그)의 필요성이 커진다. 오픈소스만으로 이를 충족할 수 있는지. 대안 평가: Starburst Galaxy 도입, 다른 쿼리 엔진으로의 전환, 또는 하이브리드 접근(배치는 Trino, 실시간은 StarRocks)을 주기적으로 평가해야 한다. 마치며 # Starburst의 AI 피벗은 단순한 마케팅 전략이 아니다. 비즈니스 지표(Galaxy 고객 76% 증가, 역대 최대 계약)가 이 전략이 시장에서 통하고 있음을 증명하고 있다. 쿼리 엔진 회사에서 AI 플랫폼 기업으로의 전환은 되돌릴 수 없는 방향이다.\nTrino 오픈소스는 당장 죽지 않는다. 하지만 \u0026ldquo;충분히 성숙한\u0026rdquo; 상태로 유지보수 모드에 가까워지고 있으며, 혁신의 무게 중심은 명확하게 상용 제품으로 이동했다. 이것은 Databricks가 Spark에 대해 했던 것과 같은 패턴이다.\nTrino를 프로덕션에서 운영하는 팀이라면, 지금 당장은 안심해도 되지만, 3년 뒤를 위한 대비는 지금 시작해야 한다. 오픈소스의 안정성에 기대면서도, 성능 격차와 AI 통합이라는 두 가지 축에서 전략적 옵션을 확보해 두는 것이 현명한 접근이다.\n기술 부채는 늘 조용히 쌓인다. 그리고 언제나 우리가 생각했던 것보다 이자가 비싸다.\n참고 자료:\nTrino Release Notes Starburst Enterprise Release Notes TechTarget: Addition of new AI capabilities shows Starburst\u0026rsquo;s growth BigDataWire: Starburst\u0026rsquo;s New Platform Aims to Close AI\u0026rsquo;s Biggest Gap ","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/posts/starburst-trino-ai-pivot/","section":"글 목록","summary":"Starburst가 쿼리 엔진 회사에서 AI 플랫폼 기업으로 전환하면서 Trino 오픈소스 릴리스가 63% 감소했다. Trino를 프로덕션에서 운영하는 팀의 관점에서, 이 변화가 의미하는 것과 앞으로의 전략을 정리한다.","title":"Starburst의 AI 피벗: Trino 오픈소스는 괜찮을까?","type":"posts"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/starrocks/","section":"Tags","summary":"","title":"Starrocks","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/categories/starrocks/","section":"Categories","summary":"","title":"StarRocks","type":"categories"},{"content":" 도입 배경 # 데이터 파이프라인을 운영하다 보면 한 가지 고민에 반드시 부딪힌다. 실시간 대시보드를 어떻게 만들 것인가?\n우리 팀도 마찬가지였다. 기존 파이프라인은 다음과 같은 구조였다.\nService → Kafka → Iceberg → S3 → Trino → Airflow(5분) → Dashboard 겉보기엔 잘 동작했지만, 실무에서 체감하는 문제는 분명했다.\n최소 5분 지연: Airflow 스케줄 주기가 병목이었다 파이프라인 복잡도: Kafka → Flink → Redis → API → Dashboard로 이어지는 5개 이상의 컴포넌트 관리 반복되는 I/O: Trino가 매 쿼리마다 S3를 풀스캔하는 구조 높은 개발 비용: 새로운 실시간 대시보드 하나에 약 2주 소요 StarRocks를 도입한 후의 아키텍처는 이렇게 단순해졌다.\nService → Kafka → StarRocks → Dashboard (서브초 레이턴시) 중간 컴포넌트가 사라지면서 파이프라인이 극적으로 단순해졌고, 데이터가 Kafka에서 StarRocks로 직접 수집되면서 실시간성도 확보했다.\n도입 효과 # 약 3개월간의 PoC와 6개월간의 단계적 도입을 거쳐 다음과 같은 개선을 달성했다.\n항목 Before After 개선폭 대시보드 지연 5분 \u0026lt; 1초 ~300배 대시보드 개발 기간 ~2주 ~1주 50% 단축 파이프라인 컴포넌트 5개 이상 2개 60% 감소 쿼리 응답 시간 30~50초 5~10초 5~10배 하드웨어 비용 128GB × 18노드 64GB × 3노드 ~75% 절감 Trino는 절대적인 쿼리 시간에서는 빠르지만, Airflow 스케줄 지연을 포함한 end-to-end 레이턴시와 하드웨어 비용 효율 면에서 StarRocks가 실시간 워크로드에 더 적합했다.\n테이블 모델 선택 가이드 # StarRocks를 처음 도입할 때 가장 중요한 결정이 테이블 모델 선택이다. 잘못 고르면 나중에 테이블을 다시 만들어야 한다.\n의사결정 흐름 # ┌─────────────────────────────┐ │ 어떤 데이터를 저장하는가? │ └──────────────┬──────────────┘ │ ┌───────▼────────┐ │ UPDATE 필요? │ └───────┬────────┘ │ ┌────────┴────────┐ │ │ [아니오] [예] │ │ ┌─────▼─────┐ ┌─────▼──────┐ │ 집계 필요? │ │ Primary Key │ └─────┬─────┘ │ (빈번한 │ │ │ UPDATE) │ [아니오] [예] └────────────┘ │ │ ┌─────▼───┐ ┌▼──────────┐ │Duplicate│ │Aggregate │ │(원본 저장)│ │(자동 집계) ★│ └─────────┘ └────────────┘ 모델 비교 # 모델 중복 허용 UPDATE 자동 집계 적합한 용도 Duplicate Key O X X 로그, 원본 이벤트 Aggregate Key X 자동 O 실시간 통계 ★ Primary Key X O (고속) X 빈번한 UPDATE Duplicate Key: 원본 데이터 저장 # 클릭 로그, API 이벤트, 센서 데이터처럼 원본을 그대로 보관해야 할 때 사용한다.\nCREATE TABLE order_events ( event_id BIGINT, event_time DATETIME, order_id VARCHAR(50), user_id BIGINT, event_type VARCHAR(20), amount DECIMAL(10, 2) ) DUPLICATE KEY(event_id, event_time) PARTITION BY date_trunc(\u0026#39;day\u0026#39;, event_time) DISTRIBUTED BY HASH(event_id) BUCKETS 10; Aggregate Key: 실시간 통계 ★ # 데이터가 수집되는 시점에 자동으로 집계가 일어난다. 이 모델이 StarRocks 도입의 핵심이었다.\nCREATE TABLE order_stats ( stat_time DATETIME NOT NULL COMMENT \u0026#39;5분 간격\u0026#39;, region VARCHAR(20) NOT NULL, delivery_type VARCHAR(20) NOT NULL, -- 집계 컬럼: 수집 시 자동으로 집계 함수 적용 order_count BIGINT SUM DEFAULT \u0026#34;0\u0026#34;, total_amount DECIMAL(15, 2) SUM DEFAULT \u0026#34;0\u0026#34;, user_bitmap BITMAP BITMAP_UNION, max_amount DECIMAL(10, 2) MAX ) AGGREGATE KEY(stat_time, region, delivery_type) PARTITION BY date_trunc(\u0026#39;day\u0026#39;, stat_time) DISTRIBUTED BY HASH(stat_time) BUCKETS 10; 사용 가능한 집계 함수:\n함수 용도 예시 SUM 합계 주문 건수, 매출 합계 MAX / MIN 최대/최소값 최고가, 최저가 REPLACE 최신 값 덮어쓰기 최종 상태 BITMAP_UNION 정확한 유니크 카운트 순 이용자 수 HLL_UNION 근사 유니크 카운트 대규모 카디널리티 BITMAP_UNION은 HyperLogLog와 달리 정확한 유니크 카운트를 제공한다. 비즈니스 KPI 대시보드처럼 정확도가 중요한 경우 반드시 이 방식을 사용하자.\nPrimary Key: 빈번한 UPDATE # 주문 상태 추적, 재고 관리처럼 같은 키의 데이터가 자주 갱신되는 경우에 적합하다.\nCREATE TABLE orders ( order_id VARCHAR(50) NOT NULL, status VARCHAR(20), amount DECIMAL(10, 2), updated_at DATETIME ) PRIMARY KEY(order_id) DISTRIBUTED BY HASH(order_id) BUCKETS 10 PROPERTIES ( \u0026#34;enable_persistent_index\u0026#34; = \u0026#34;true\u0026#34; ); enable_persistent_index를 활성화하면 UPDATE 성능이 크게 향상된다.\n데이터 수집 # Routine Load: Kafka 실시간 연동 # Kafka 토픽에서 데이터를 연속으로 수집하는 방식이다. 대부분의 실시간 파이프라인에서 이 방식을 사용한다.\nCREATE ROUTINE LOAD order_load ON orders COLUMNS( order_id, user_id, timestamp_ms, amount, order_date = FROM_UNIXTIME(timestamp_ms / 1000) ) PROPERTIES ( \u0026#34;format\u0026#34; = \u0026#34;json\u0026#34;, \u0026#34;jsonpaths\u0026#34; = \u0026#34;[\\\u0026#34;$.orderId\\\u0026#34;,\\\u0026#34;$.userId\\\u0026#34;,\\\u0026#34;$.timestamp\\\u0026#34;,\\\u0026#34;$.amount\\\u0026#34;]\u0026#34; ) FROM KAFKA ( \u0026#34;kafka_broker_list\u0026#34; = \u0026#34;kafka-broker:9092\u0026#34;, \u0026#34;kafka_topic\u0026#34; = \u0026#34;orders\u0026#34; ); Aggregate Key 테이블과 결합하면 수집 시점에 변환과 집계를 동시에 처리할 수 있다.\nCREATE ROUTINE LOAD order_stats_load ON order_stats COLUMNS( timestamp_ms, region, amount, user_id, -- 5분 간격으로 라운딩 stat_time = FROM_UNIXTIME(FLOOR(timestamp_ms / 1000 / 300) * 300), order_count = 1, total_amount = amount, user_bitmap = BITMAP_HASH(user_id) ) WHERE amount \u0026gt; 0 PROPERTIES (\u0026#34;format\u0026#34; = \u0026#34;json\u0026#34;) FROM KAFKA ( \u0026#34;kafka_broker_list\u0026#34; = \u0026#34;kafka-broker:9092\u0026#34;, \u0026#34;kafka_topic\u0026#34; = \u0026#34;orders\u0026#34; ); 이 패턴 하나로 기존에 Flink로 처리하던 집계 로직을 SQL만으로 대체할 수 있었다.\nStream Load: 벌크 데이터 로딩 # 파일이나 API를 통한 일회성 대량 로딩에 적합하다.\n# CSV 파일 로딩 curl --location-trusted \\ -u user:password \\ -H \u0026#34;label:load_$(date +%Y%m%d%H%M%S)\u0026#34; \\ -H \u0026#34;column_separator:,\u0026#34; \\ -T data.csv \\ http://starrocks-fe:8030/api/mydb/mytable/_stream_load 성능 튜닝 실전 팁 # Thread Pool 설정 # 동시 접속이 500 RPS 이상인 고부하 환경에서는 기본 Thread Pool 크기가 부족하다.\n# be.conf pipeline_scan_thread_pool_thread_num = 32 # 기본값: 24 pipeline_exec_thread_pool_thread_num = 32 # 기본값: 24 Bucket Count 가이드라인 # 데이터 크기 권장 Bucket 수 \u0026lt; 10 GB 10 10~50 GB 20 50~100 GB 30 \u0026gt; 100 GB 50+ 산정 공식: buckets = max(1, 데이터_크기_GB / 10)\n파티셔닝 전략 # 파티션 컬럼에 함수를 사용하면 파티션 프루닝이 동작하지 않는다. 이것은 생각보다 자주 실수하는 부분이다.\n-- ✅ 올바른 사용: 파티션 프루닝 동작 WHERE event_time \u0026gt;= NOW() - INTERVAL 3 DAY -- ❌ 잘못된 사용: 파티션 프루닝 불가 WHERE DATE(event_time) \u0026gt;= CURRENT_DATE - 3 TTL 설정 # 오래된 파티션을 자동으로 삭제하려면 TTL을 설정한다.\nPROPERTIES ( \u0026#34;partition_live_number\u0026#34; = \u0026#34;3\u0026#34; -- 최근 3개 파티션만 유지 ) 운영 노하우 # Materialized View 관리 # ASYNC 리프레시가 예고 없이 멈추는 경우가 있다. 정기적으로 상태를 확인하고, 문제 발생 시 수동으로 복구해야 한다.\n-- 상태 확인 SHOW MATERIALIZED VIEWS; -- 강제 동기 리프레시 REFRESH MATERIALIZED VIEW db.mv_name WITH SYNC MODE; -- 비활성화된 MV 재활성화 ALTER MATERIALIZED VIEW db.mv_name ACTIVE; Routine Load 모니터링 # 상태가 PAUSED로 전환되는 경우가 잦다. Kafka offset 문제나 비정상 메시지가 원인이다.\n-- 상태 확인 SHOW ROUTINE LOAD FOR db.load_job; -- 재개 RESUME ROUTINE LOAD FOR db.load_job; Scale-in 주의사항 # 노드를 축소할 때는 반드시 Decommission을 먼저 수행해야 한다. 이 절차 없이 노드를 줄이면 데이터가 유실된다.\n-- 1. 현재 노드 확인 SHOW PROC \u0026#39;/backends\u0026#39;; -- 2. 디커미션 시작 ALTER SYSTEM DECOMMISSION BACKEND \u0026#34;\u0026lt;BE_IP\u0026gt;:\u0026lt;HEARTBEAT_PORT\u0026gt;\u0026#34;; -- 3. TabletNum이 0이 될 때까지 대기 후 제거 ALTER SYSTEM DROP BACKEND \u0026#34;\u0026lt;BE_IP\u0026gt;:\u0026lt;HEARTBEAT_PORT\u0026gt;\u0026#34;; 도입 시 알아두면 좋은 것들 # 알려진 제약 사항 # 이슈 설명 대안 Routine Load 비정상 메시지 처리 한계 Kafka 단에서 사전 검증 datetime 파티션 Iceberg datetime 파티션 호환 이슈 대체 파티션 전략 사용 버전 업그레이드 4.x 대에서 버그 경험 스테이징 환경 필수 테스트 버전 업그레이드는 반드시 스테이징 환경에서 충분히 검증한 뒤 프로덕션에 적용하자. 실제로 여러 차례 업그레이드/다운그레이드를 반복한 경험이 있다. 롤백 계획은 항상 준비해두어야 한다.\n도입 체크리스트 # 배포 전\n유스케이스와 요구사항 정의 데이터 볼륨 및 증가량 추정 테이블 모델 선택 파티션 전략 설계 배포 후\nRoutine Load 작업 생성 및 검증 사용자 권한 설정 데이터 보관 정책(TTL) 설정 Scale-in/out 절차 문서화 모니터링 대시보드 구성 마치며 # StarRocks 도입에서 얻은 핵심 교훈을 정리하면 다음과 같다.\nAggregate Key 모델이 핵심이다 — 수집 시점 자동 집계로 스토리지와 쿼리 성능을 동시에 잡을 수 있다 BITMAP_UNION으로 정확한 유니크 카운트를 확보하자 — 비즈니스 KPI에는 근사치가 아닌 정확한 수치가 필요하다 Routine Load + Aggregate Key 조합이 Flink를 대체한다 — SQL만으로 실시간 집계 파이프라인을 구축할 수 있다 운영 자동화에 투자하자 — Materialized View와 Routine Load 모니터링은 필수다 실시간 분석 워크로드에서 StarRocks는 파이프라인 복잡도를 획기적으로 줄여주는 강력한 선택지다. 다만 버전 업그레이드와 운영 안정성 측면에서는 아직 성숙해지는 과정에 있으므로, 충분한 PoC와 스테이징 검증을 거쳐 도입하길 권장한다.\n참고 자료: StarRocks 공식 문서\n","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/posts/starrocks-adoption-guide/","section":"글 목록","summary":"기존 Trino + Airflow 파이프라인의 5분 지연을 서브초 레이턴시로 개선한 StarRocks 도입 과정을 정리했습니다. 테이블 모델 선택, 데이터 수집, 성능 튜닝, 운영 노하우까지 실무에서 얻은 교훈을 공유합니다.","title":"StarRocks 도입기: 실시간 OLAP으로 데이터 파이프라인을 혁신한 이야기","type":"posts"},{"content":" 왜 압축 설정이 중요한가 # StarRocks를 운영하다 보면 데이터가 수십 TB 규모로 늘어나는 시점이 반드시 온다. 이때 압축 설정 하나로 스토리지 비용이 30~50% 차이 나는 경우를 여러 번 경험했다. 단순히 저장 공간만의 문제가 아니다. 압축률이 높으면 디스크 I/O가 줄어들어 스캔 성능이 좋아지고, 반대로 압축/해제에 CPU를 많이 쓰면 지연 시간이 늘어난다. 결국 워크로드 특성에 맞는 압축 알고리즘을 선택하는 것이 StarRocks 운영의 핵심 튜닝 포인트 중 하나다.\n지원되는 압축 알고리즘 비교 # StarRocks는 여러 압축 알고리즘을 지원한다. 실무에서 주로 사용하는 세 가지를 비교해 보겠다.\n알고리즘 압축률 압축 속도 해제 속도 적합한 워크로드 LZ4 보통 (2~3x) 매우 빠름 매우 빠름 실시간 분석, 저지연 쿼리 ZSTD 높음 (4~6x) 보통 빠름 배치 분석, 콜드 데이터 Snappy 낮음 (1.5~2x) 빠름 빠름 범용, 레거시 호환 ZLIB 높음 (4~5x) 느림 보통 아카이빙, 저빈도 접근 데이터 개인적으로 가장 많이 쓰는 조합은 핫 데이터에 LZ4, 콜드 데이터에 ZSTD다. Snappy는 Hadoop 에코시스템에서 넘어온 데이터를 다룰 때 간혹 사용하지만, 신규 테이블에는 권장하지 않는다.\n테이블 생성 시 압축 설정 방법 # 테이블을 생성할 때 PROPERTIES에서 compression 속성을 지정하면 된다. 별도로 설정하지 않으면 StarRocks 기본값인 LZ4가 적용된다.\n실시간 분석용 테이블 (LZ4) # CREATE TABLE analytics.realtime_events ( event_id BIGINT, user_id BIGINT, event_type VARCHAR(64), event_time DATETIME, properties JSON ) ENGINE = OLAP DUPLICATE KEY(event_id) DISTRIBUTED BY HASH(user_id) BUCKETS 32 PROPERTIES ( \u0026#34;replication_num\u0026#34; = \u0026#34;3\u0026#34;, \u0026#34;compression\u0026#34; = \u0026#34;LZ4\u0026#34; ); LZ4는 해제 속도가 압도적으로 빠르기 때문에, 대시보드 쿼리처럼 수백 밀리초 이내 응답이 필요한 테이블에 적합하다.\n배치 분석용 테이블 (ZSTD) # CREATE TABLE warehouse.order_history ( order_id BIGINT, customer_id BIGINT, order_date DATE, total_amount DECIMAL(18, 2), status VARCHAR(32), items ARRAY\u0026lt;STRUCT\u0026lt;sku STRING, qty INT, price DECIMAL(10,2)\u0026gt;\u0026gt; ) ENGINE = OLAP DUPLICATE KEY(order_id) PARTITION BY RANGE(order_date) ( PARTITION p2025 VALUES LESS THAN (\u0026#39;2026-01-01\u0026#39;), PARTITION p2026 VALUES LESS THAN (\u0026#39;2027-01-01\u0026#39;) ) DISTRIBUTED BY HASH(customer_id) BUCKETS 16 PROPERTIES ( \u0026#34;replication_num\u0026#34; = \u0026#34;2\u0026#34;, \u0026#34;compression\u0026#34; = \u0026#34;ZSTD\u0026#34; ); ZSTD는 압축률이 LZ4 대비 1.5~2배 높아서, 파티션 단위로 수억 건 이상 적재되는 히스토리 테이블에서 스토리지 절감 효과가 크다.\n기존 테이블 압축 변경 # 이미 운영 중인 테이블의 압축 알고리즘을 변경하고 싶다면 ALTER TABLE을 사용할 수 있다. 단, 변경 이후 새로 적재되는 데이터부터 적용되며 기존 세그먼트는 Compaction이 수행되어야 반영된다는 점에 유의하자.\nALTER TABLE warehouse.order_history SET (\u0026#34;compression\u0026#34; = \u0026#34;ZSTD\u0026#34;); 워크로드별 권장 압축 설정 # 실무에서 반복적으로 검증한 결과를 기반으로 정리하면 다음과 같다.\n실시간 대시보드 / Ad-hoc 쿼리: LZ4를 권장한다. CPU 오버헤드가 거의 없어 P99 지연 시간에 미치는 영향이 최소화된다. 야간 배치 리포트 / ETL 결과 테이블: ZSTD를 권장한다. 쿼리 빈도가 낮고 데이터 양이 많은 경우 스토리지 절감 효과가 비용에 직접 반영된다. 로그성 대용량 적재: ZSTD를 사용하되 zstd_compression_level을 3 이하로 낮추면 압축 속도와 압축률 사이의 균형을 잡을 수 있다. 압축률과 성능 트레이드오프 실측 결과 # 약 50억 건(원본 약 800GB)의 이벤트 로그 테이블을 대상으로 압축 알고리즘별 벤치마크를 수행한 결과다.\n지표 LZ4 ZSTD (level 3) ZSTD (level 9) 압축 후 크기 320 GB 195 GB 170 GB 압축률 2.5x 4.1x 4.7x 단순 스캔 쿼리 (Avg) 1.2초 1.5초 1.8초 집계 쿼리 (Avg) 3.4초 3.8초 4.5초 데이터 적재 속도 120 MB/s 95 MB/s 60 MB/s LZ4 대비 ZSTD level 3은 스토리지를 약 39% 절감하면서도 쿼리 지연은 약 10~15%만 증가했다. 반면 ZSTD level 9는 추가 압축 이득 대비 적재 속도 저하가 커서 대부분의 환경에서는 level 3이 최적의 선택이었다.\n운영 팁과 모니터링 # 마지막으로 실무에서 압축 관련 운영 시 놓치기 쉬운 포인트를 정리한다.\nCompaction 모니터링을 반드시 하자. 압축 알고리즘을 변경한 뒤 Compaction이 완료되기 전까지 혼합 세그먼트가 존재하면 쿼리 성능이 일시적으로 불안정해질 수 있다. BE의 compaction_score 메트릭을 모니터링하여 Compaction 적체 여부를 확인해야 한다.\n테이블 단위로 압축 전략을 분리하라. 하나의 클러스터에서 모든 테이블에 동일한 압축을 적용하는 것은 비효율적이다. 접근 빈도, 데이터 크기, SLA에 따라 테이블별로 다르게 설정하는 것이 올바른 접근이다.\n디스크 사용량 추이를 추적하라. 압축 변경 후 SHOW DATA 명령으로 테이블별 실제 디스크 사용량을 주기적으로 확인하고, 기대한 압축률이 나오지 않는다면 데이터 특성(카디널리티, NULL 비율 등)을 재점검해야 한다.\nSHOW DATA FROM warehouse.order_history; 압축 설정은 한 번 정하고 끝나는 것이 아니라, 데이터 특성과 워크로드가 변함에 따라 지속적으로 재검토해야 하는 영역이다. 이 글이 StarRocks 운영에서 압축 전략을 수립하는 데 실질적인 참고가 되길 바란다.\n","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/posts/starrocks-compression-guide/","section":"글 목록","summary":"StarRocks에서 압축 설정을 최적화하여 스토리지 비용을 절감하고 쿼리 성능을 향상시키는 방법을 실무 경험을 바탕으로 정리했습니다.","title":"StarRocks 압축 설정 가이드: 성능과 스토리지 최적화","type":"posts"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/trends/","section":"Tags","summary":"","title":"Trends","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/trino/","section":"Tags","summary":"","title":"Trino","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/vector-store/","section":"Tags","summary":"","title":"Vector-Store","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/workation/","section":"Tags","summary":"","title":"Workation","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/posts/","section":"글 목록","summary":"","title":"글 목록","type":"posts"},{"content":"발리하면 떠오르는 이미지가 있다. 서핑, 열대 자연, 코워킹 스페이스에서 노트북을 펼친 디지털 노마드. 워케이션(workation)의 성지라는 수식어가 붙는 곳이다.\n나도 그 이미지에 이끌렸다. 아이에게는 해외 유치원이라는 새로운 경험을, 가족에게는 일상에서의 해방감을 줄 수 있을 거라 기대했다. 2023년 초, 회사의 해외 리모트 근무 제도를 활용해 발리에서 약 한 달간 일하고 생활했다.\n결론부터 말하면, 아이가 있는 가정에게 발리 리모트 근무는 생각보다 별로였다. 이 글은 그 솔직한 기록이다. 발리 리모트 근무를 고민하는 분들, 특히 어린 아이가 있는 가정이라면 이 글이 판단에 도움이 되었으면 한다.\n출발 전: 준비해야 할 것들 # 승인과 세무 이슈 # 해외 리모트 근무는 비행기표를 사기 전에 회사 승인부터 받아야 한다. 승인 과정에서 일정 변경이 생길 수 있기 때문이다.\n나의 경우, 처음에 3개월 체류를 신청했으나 세무 검토 과정에서 세법상 2개월 이하만 가능하다는 회신을 받았다. 해외 체류 기간에 따라 세금 처리가 달라지기 때문이다. 비행기표를 이미 끊어놨다면 변경 수수료를 물어야 할 뻔했다. 반드시 승인 확정 후에 항공권을 구매하자.\n항공권은 대한항공 마일리지를 사용했는데, 비용 대비 차감되는 마일리지가 적어서 가성비가 좋았다.\n숙소: 빌라의 함정 # 발리 숙소는 크게 두 가지 선택지가 있다. 호텔/리조트를 전전하거나, 월 단위로 빌라를 빌리거나.\n나는 호텔에서 3일 정도 지내본 뒤, 수영장이 딸린 발리스러운 빌라를 월 단위로 계약했다. 사진으로 보면 정말 근사하다. 야자수 아래 프라이빗 풀, 넓은 거실, 열대 정원. 문제는 실제로 살아보면 다르다는 것이다. 결국 빌라를 취소하고 다시 호텔로 돌아왔다.\n빌라의 현실:\n벌레가 많다. 개미, 모기는 기본이고 이름 모를 벌레들이 출몰한다. 호텔/리조트는 방역을 하지만 빌라는 그렇지 않다. 침구류와 청소 상태가 불안정하다. 관리 수준이 숙소마다 천차만별이다. 상수도 문제. 후술하겠지만, 이것이 가장 큰 문제다. 교통이 불편하다. 빌라가 저렴한 이유가 있다. 대부분 도심에서 떨어져 있고, 발리에서 걸어 다니는 건 사실상 불가능하다. 한 달 이상 체류할 거라면 빌라가 합리적으로 보이지만, 특히 아이가 있다면 호텔이나 서비스드 레지던스가 낫다. 관리, 위생, 편의성 모든 면에서 그렇다.\n위생: 발리의 가장 큰 리스크 # 인도네시아 여행 커뮤니티에서 가장 많이 나오는 토픽이 있다. \u0026ldquo;병원 어디 가야 해요?\u0026rdquo;, \u0026ldquo;약 좀 주세요\u0026rdquo;, \u0026ldquo;샤워기 필터 구합니다.\u0026rdquo;\n과장이 아니다.\n물 문제 # 발리는 지하수를 끌어다 쓰는 곳이 많다. 오염된 경우가 적지 않아서, 비누로 빡빡 씻어도 몸이 계속 미끈미끈한 느낌이 가시지 않는다. 유럽의 석회수와는 또 다른 종류의 불쾌함이다.\n수영장은 발리 곳곳에 널려 있지만, 소독약 냄새가 안 나는 곳이 많다. 소독약 냄새가 안 난다는 건, 소독을 안 한다는 뜻이다. 세균과 박테리아가 번식하기 좋은 열대 기후에서.\n비치도 안심할 수 없다. 서핑 중 육지에서 흘러들어온 오염된 바닷물을 삼키고 아픈 사람이 많다. 카페에서 나오는 차가운 음료의 얼음이 정수된 물로 만든 것인지도 확신할 수 없다.\n아이의 입원 # 출국 전 나름 준비를 했다. 장티푸스 예방접종을 맞고, 출국 전날 종합병원에서 피검사로 염증 수치와 백혈구 수치를 확인했다. 유산균도 2주 전부터 복용시켰다.\n도착 3일 만에 아이에게 고열이 찾아왔다.\n평소 38도 위로 올라간 적이 없던 아이가 39.5도까지 치솟았다. 응급실을 세 번 갔다. 세 번째 응급실에서는 귀가하겠다고 하니 \u0026ldquo;책임지지 않겠다\u0026quot;는 서명을 하고 가라고 했다. 결국 병동에 입원. 4일간 입원했다.\n이때의 경험은 지금 돌이켜 봐도 힘들다.\n기본적으로 낙후된 인도네시아 의료 시설에 대한 불신. 의사소통도 어렵다. 아이가 응급실에 있는데 비가 쏟아지면서 천장이 무너져 내렸다. 굉음과 함께 천장 조명이 떨어지고, 놀라서 아이를 안고 뛰쳐나온 직후 천장이 내려앉았다. 그 지역에서 제일 좋다는 병원에서 벌어진 일이다. 응급실 한 번 방문에 검사비 포함 약 50만 원. 총 의료비 300만 원 이상. 여행자 보험 가입은 필수다. 반드시 보장 내용을 꼼꼼히 확인하고, 의료비 보장 한도가 충분한 상품으로 들어야 한다. 그리고 솔직히 말하면, 이 경험 이후 **\u0026ldquo;뭘 위해 여기 있어야 하나\u0026rdquo;**라는 생각이 머리에서 떠나지 않았다.\n아이와의 일상: 기대와 현실 # 할 것이 없다 # 한국에서 아이와 하는 일상을 떠올려 보자. 책 읽어주기, 산책, 놀이터, 키즈카페, 장난감 놀이, 주말 캠핑. 발리에서는 이것 중 거의 아무것도 할 수 없다.\n책이 없다. 한글 동화책을 한 보따리 가져가지 않는 한, 읽어줄 책이 없다. 산책이 불가능하다. 발리에는 인도(보도)가 거의 없다. \u0026ldquo;3발자국 이상 걸으려면 오토바이를 불러야 한다\u0026quot;는 말이 과장이 아니다. 강렬한 햇빛 아래 매연을 맞으며 걷다 보면 오토바이에 발이 깔릴 것 같은 공포를 느낀다. 아이와 산책은 상상도 못 한다. 놀이터가 거의 없다. 한국처럼 아파트 단지마다 놀이터가 있는 환경이 아니다. 법적으로도 의무 시설이 아닌 듯하다. 아주 가끔 하나씩 보이는데, 시설 수준이 한국에 비해 현저히 떨어진다. 실내 놀이 환경이 없다. 집에는 익숙한 장난감이 있지만 여기에는 없다. 결국 한국에서는 안 보여줬던 유튜브를 보여주게 된다. 이것이 현실이다.\n기대했던 유치원 # 발리에 호주 교민이 많다 보니 영어 기반 유치원이 잘 되어 있다. 아이에게 영어 환경을 경험시켜 줄 수 있을 거라는 기대가 컸다.\n하지만 아이의 성향을 간과했다. 우리 아이는 소극적이고, 먼저 다가가는 성격이 아니다. 원생 대부분이 영어를 쓰는 환경에서 2주 동안 혼자 노는 아이를 지켜봐야 했다. 결국 유치원을 그만 보내기로 했다. 기대가 컸던 만큼 실망도 컸다.\n아이의 성향에 따라 경험이 완전히 달라진다. 사교적이고 적응이 빠른 아이라면 좋은 경험이 될 수도 있겠지만, 모든 아이가 그런 것은 아니다. 아이의 성격을 냉정하게 고려해야 한다.\n나의 일상: Vacation이 아니라 Workation이다 # 없던 시간이 생겨나지 않는다 # 한국에서의 일상을 돌아보자. 부지런한 성격은 아니다. 아침에 일어나서 아이 밥 먹이고 유치원 보내고, 일하다가, 퇴근하면 아이와 놀아주고, 아이가 잠들면 짧으면 한 시간, 길면 두 시간의 자유 시간. 유튜브 보거나 밀린 일 하거나 운동하거나.\n발리라고 해서 없던 시간이 생겨나지 않는다. 하루에 내 시간이 한 시간인 사람이 장소를 옮겼다고 갑자기 세 시간이 되지 않는다. 오히려 출퇴근 시간이 늘어났다.\n인터넷: VPN의 벽 # 집에서 일하는 것은 사실상 불가능했다. 인터넷 속도가 느리고, 정전이 잦고, 인터넷이 수시로 끊긴다.\n코워킹 스페이스는 다르다. 좋은 코워킹 스페이스는 UPS와 자체 발전기를 갖추고 있고, 여러 ISP와 계약해서 한쪽이 끊겨도 다른 회선으로 유지된다. 회사에서 제시한 최저 인터넷 속도를 대부분 만족한다.\n문제는 VPN이다. 회사 보안 정책상 VPN을 켜고 일해야 하는데, VPN을 켜는 순간 인터넷 속도가 원래의 10~20% 수준으로 떨어진다. VPN을 켜도 원활하게 일할 수 있는 코워킹 스페이스는 발리 전체에 몇 개 안 된다. 그런 곳은 하루 이용료가 2만 원 정도로 비싸고, 숙소에서 가깝지도 않다.\n저녁 시간의 현실 # 퇴근 후 밤 시간. 서핑이나 야외 액티비티는 불가능한 시간이다. 유럽처럼 거리에서 뮤지션이 공연하는 문화도 아니다. 현실적으로 할 수 있는 것은 괜찮은 음식점이나 바에서 맛있는 것을 먹고 술 한 잔 하는 정도다.\n그런데 이것도 녹록지 않다.\n술 문화가 발달하지 않았다. 이슬람 국가라는 배경 때문인지, 크래프트 비어는 로컬 브루어리 2~3곳이 전부이고, 해외 크래프트 비어는 아예 없다. 증류주는 비싸고, 와인은 수입산이라 종류가 한정적이고 가격이 높다. 괜찮은 곳은 한국만큼 비싸다. 음료를 따로 시키고, 세금이 15~20% 붙는다. 매일 괜찮은 곳에서 먹기에는 통장 잔고가 부담스럽다. 저렴한 곳에서 먹다 보면, 남의 나라까지 와서 왜 이 고생을 하고 있나 하는 생각이 든다. 도착한 지 2주 만에 통장 잔고가 급격히 줄어드는 것을 목격했다.\n그래도 좋았던 것 # 부정적인 이야기만 한 것 같아서, 좋았던 것도 솔직하게 적는다.\n코워킹 스페이스 # 발리의 코워킹 스페이스 문화는 확실히 인상적이다. PC방 같기도 하고, 도서관 같기도 하고, 카페 같기도 한 공간. 여기는 이런 분위기구나, 저기는 이런 메뉴가 맛있네, 하면서 코워킹 스페이스를 구경하는 것 자체가 재미있는 경험이었다. 전 세계에서 온 디지털 노마드들과 같은 공간에서 일하는 느낌도 나쁘지 않았다.\n비치클럽 # 뒤에는 수영장, 앞에는 바다. 음악과 맛있는 음식. 발리의 비치클럽은 확실히 특별한 경험이다. 젊은이들이 즐기는 모습을 구경하는 것만으로도 활력이 되었다.\n주말 # 주말에는 비로소 내가 발리에 놀러 온 것 같았다. 투어도 하고, 비치클럽도 가고, 서핑도 한다. 평일에는 느낄 수 없었던 발리의 매력이 주말에 몰아서 찾아온다. 역설적이지만 이것이 \u0026ldquo;워케이션\u0026quot;이라는 단어의 정확한 의미였다. work과 vacation이 동시에 오는 게 아니라, 번갈아 오는 것이다.\n정리: 발리 리모트 근무, 누구에게 맞는가 # 한 달간의 경험을 정리하면, 발리 리모트 근무의 만족도는 라이프 스타일에 따라 극명하게 갈린다.\n조건 만족도 이유 미혼 or 커플 (아이 없음) 높음 액티비티, 자유 시간, 유연한 일정 아이가 있는 가정 낮음 위생 리스크, 할 것 없음, 시간 부족 VPN 불필요한 업무 높음 코워킹 스페이스 활용 자유로움 VPN 필수 업무 보통 코워킹 스페이스 선택지 제한 넉넉한 예산 높음 좋은 숙소 + 좋은 음식 = 좋은 경험 빠듯한 예산 낮음 저렴한 곳 전전하다 지침 가기 전에 체크할 것 # 아이가 있는 가정이 그래도 가겠다면:\n여행자 보험: 의료비 보장 한도를 반드시 확인. 응급실 한 번에 50만 원이 나올 수 있다. 장티푸스 예방접종: 출국 최소 2주 전에 접종. 숙소: 빌라보다 호텔이나 서비스드 레지던스. 위생과 관리가 다르다. VPN 테스트: 회사 VPN을 켠 상태에서 일할 수 있는 코워킹 스페이스를 사전에 조사. 아이 준비물: 한글 책, 장난감, 태블릿에 오프라인 콘텐츠 다운로드. 유치원: 아이 성향을 냉정하게 판단. 소극적인 아이에게 영어 유치원은 스트레스가 될 수 있다. 예산: 한국에서의 생활비 + 30~50% 여유를 잡아야 한다. 발리가 저렴하다는 것은 로컬 음식과 로컬 숙소 기준이다. 한국인이 만족할 수준의 생활을 하려면 한국과 비슷하거나 더 들 수 있다. 마치며 # 돌아와서 생각해 보면, 발리 리모트 근무에서 가장 크게 느낀 것은 이것이다.\n장소를 바꾼다고 삶이 바뀌지 않는다. 하루에 자유 시간이 한 시간인 사람은 발리에서도 한 시간이다. 아이를 돌봐야 하는 부모는 발리에서도 아이를 돌봐야 한다. 거기에 위생 리스크, 의료 불안, 인프라 불편까지 더해진다.\n그럼에도 불구하고 이 경험을 후회하지는 않는다. 해보지 않았으면 계속 궁금했을 것이고, 발리에 대한 막연한 환상을 품고 살았을 것이다. 환상을 현실로 확인한 것 자체가 가치 있었다.\n다만, 같은 조건(어린 아이 동반)으로 다시 해외 리모트 근무를 한다면 발리는 아닐 것이다. 의료 인프라가 탄탄하고, 아이와 산책할 수 있는 도시. 보도가 있고, 놀이터가 있고, 수돗물을 믿을 수 있는 곳. 일상의 기본이 갖춰진 도시에서의 워케이션이 진짜 워케이션이다.\n","date":"2026년 2월 23일","externalUrl":null,"permalink":"/my-tech-blog/ko/posts/bali-remote-work-with-family/","section":"글 목록","summary":"서핑, 자연, 디지털 노마드의 성지 발리. 아이를 데리고 한 달간 리모트 근무를 했다. 기대했던 것과 실제 경험 사이의 간극을 솔직하게 기록한다.","title":"발리 리모트 근무 후기: 아이와 함께한 한 달, 솔직한 기록","type":"posts"},{"content":" 운영자 정보 # 본 블로그는 OTL이 운영하며, 사이트 주소는 https://nhosw.github.io/my-tech-blog/ 입니다.\n수집하는 정보 # Google Analytics # 본 사이트는 방문자의 이용 현황을 파악하기 위해 Google Analytics 4(GA4)를 사용합니다. GA4는 다음 정보를 수집합니다:\n방문한 페이지 및 체류 시간 대략적인 위치 정보 (국가/도시 수준) 기기 유형, 브라우저, 운영체제 유입 경로 (사이트를 어떻게 찾았는지) Google Analytics는 쿠키를 사용하여 고유 방문자를 구분합니다. 개인을 식별할 수 있는 정보는 의도적으로 수집하지 않습니다.\n자세한 내용은 Google 개인정보처리방침을 참고하세요.\nGoogle AdSense # 본 사이트는 Google AdSense를 통해 광고를 게재할 수 있습니다. AdSense는 쿠키와 웹 비콘을 사용하여 이전 방문 기록을 기반으로 광고를 제공합니다.\nGoogle은 DART 쿠키를 사용하여 브라우징 기록에 기반한 광고를 제공합니다 Google 광고 설정에서 맞춤 광고를 비활성화할 수 있습니다 자세한 내용은 Google AdSense 개인정보처리방침을 참고하세요.\n댓글 # 본 사이트는 현재 댓글 기능을 제공하지 않습니다. 향후 댓글 기능이 추가되면 본 방침을 업데이트하겠습니다.\n쿠키 # 쿠키는 사용자의 기기에 저장되는 작은 텍스트 파일입니다. 본 사이트는 다음 목적으로 쿠키를 사용합니다:\n분석: 사이트 트래픽 측정 (Google Analytics) 광고: 관련 광고 제공 (Google AdSense) 환경설정: 테마 설정 기억 (다크/라이트 모드) 브라우저 설정을 통해 쿠키를 제어할 수 있습니다. 쿠키를 비활성화하면 사이트 기능에 영향을 줄 수 있습니다.\n외부 링크 # 블로그 게시물에는 외부 웹사이트로의 링크가 포함될 수 있습니다. 외부 사이트의 개인정보 보호 관행에 대해서는 책임지지 않습니다.\n이용자의 권리 # 이용자는 다음 권리를 가집니다:\n수집되는 데이터에 대해 알 권리 추적 비활성화 (브라우저 설정 또는 Google 광고 설정) 본인 데이터에 대한 정보 요청 방침 변경 # 본 개인정보처리방침은 수시로 업데이트될 수 있습니다. 변경 사항은 이 페이지에 게시됩니다.\n문의 # 본 개인정보처리방침에 대해 궁금한 점이 있으시면 소개 페이지의 연락처로 문의해 주세요.\n최종 수정일: 2026년 2월 23일\n","externalUrl":null,"permalink":"/my-tech-blog/ko/privacy-policy/","section":"OTL - 데이터 엔지니어링","summary":"개인정보처리방침","title":"개인정보처리방침","type":"page"},{"content":" 안녕하세요, OTL입니다 # 저는 안정적이고 확장 가능한 데이터 인프라와 파이프라인을 구축하는 데이터 엔지니어입니다. 대규모 데이터의 수집, 변환, 서빙 과정에서 발생하는 다양한 문제를 해결하는 일에 보람을 느끼고 있습니다.\n블로그 소개 # 이 블로그는 실무에서 얻은 데이터 엔지니어링 지식을 공유하는 공간입니다. 실제 프로젝트에서 배운 교훈, 튜토리얼, 아키텍처 관련 의사결정, 그리고 데이터 분야에서 일하는 엔지니어분들께 도움이 될 만한 팁들을 다루고 있습니다.\n기술 스택 # 현재 주로 사용하고 있는 기술들입니다:\n스트림 처리: Apache Kafka 워크플로 오케스트레이션: Apache Airflow 쿼리 엔진: Trino, StarRocks 컨테이너 오케스트레이션: Kubernetes 언어: Python, SQL 인프라: Docker 연락처 # 이메일: nanta0032@naver.com 궁금한 점이나 제안 사항이 있으시면 편하게 연락 주세요!\n","externalUrl":null,"permalink":"/my-tech-blog/ko/about/","section":"OTL - 데이터 엔지니어링","summary":"블로그 소개","title":"소개","type":"page"}]