[{"content":"Joe Reis가 1,101명의 데이터 실무자를 대상으로 진행한 서베이 결과를 기반으로 2026년 데이터 엔지니어링 트렌드를 발표했다. 대규모 플랫폼의 데이터 엔지니어링 팀을 이끌고 있는 입장에서, 이 트렌드를 우리 팀의 현재 아키텍처와 대조하며 이미 잘 하고 있는 것과 앞으로 해야 할 것을 정리해본다.\n우리 아키텍처 한 줄 요약 S3를 중심 데이터 레이크로 두고, Apache Iceberg 테이블 포맷 위에 Trino(배치/애드혹 분석)와 StarRocks(실시간 OLAP)를 얹은 하이브리드 구조다. 데이터 수집은 Kafka + Debezium CDC와 Flink 스트리밍, 오케스트레이션은 Airflow를 깊이 커스터마이징하여 운영하고 있다.\n[Services] → Kafka + Debezium CDC → Flink → S3 (Iceberg) ↓ ┌─────┴─────┐ │ │ Trino StarRocks (배치/애드혹) (실시간 OLAP) │ │ └─────┬─────┘ ↓ Dashboard 1. AI 활용 — 이미 하고 있는 것과 넘어야 할 벽 트렌드 요약 서베이 응답자의 82%가 AI를 매일 사용하고 있지만, 64%는 아직 실험 단계나 단순 작업에만 활용하고 있다. Joe Reis는 2026년 말이면 \u0026ldquo;AI-assisted\u0026quot;라는 수식어가 직무 기술에서 사라질 것이라 예측한다.\n우리가 하고 있는 것 AI 코딩 도구를 활용한 파이프라인 개발은 이미 일상이 되었다. SQL 최적화, 코드 리뷰, 트러블슈팅 과정에서 LLM을 적극적으로 활용하고 있으며, 데이터 카탈로그와 연계한 자연어 기반 데이터 탐색도 시도하고 있다.\n해야 할 것 개인 단위의 AI 활용을 넘어서 팀 전체의 워크플로우에 AI를 임베드하는 것이 과제다.\n데이터 파이프라인 이상 감지 자동 스키마 진화 대응 데이터 품질 룰 자동 생성 Joe Reis가 말한 \u0026ldquo;10%의 AI-mature 팀\u0026quot;에 속하려면, AI를 단순 보조 도구가 아닌 플랫폼의 핵심 컴포넌트로 통합하는 전략이 필요하다.\n2. 데이터 모델링 위기와 시맨틱 레이어 — 가장 큰 숙제 트렌드 요약 응답자의 89%가 데이터 모델링에서 고통을 호소하고 있고, 시맨틱 모델을 사용하는 팀은 고작 5%다. Joe Reis는 시맨틱 레이어가 먼저 주류가 되고, 이후 LLM이 스키마를 즉석에서 해석하는 방향으로 진화할 것이라 본다.\n우리가 하고 있는 것 데이터 카탈로그를 통해 리니지와 메타데이터를 관리하고 있고, 테이블 레이어 체계(L1/L2/L3)를 정의하여 데이터 품질을 계층적으로 관리하려는 시도를 진행 중이다. Airflow 커스텀 오퍼레이터를 통한 데이터 검증 자동화도 운영하고 있다.\n해야 할 것 dbt 도입을 검토했으나 차세대 데이터 플랫폼 전환 전략과 맞물려 중단된 상태다. 현재 파이프라인을 dbt로 이관하기보다는 새로운 플랫폼으로 직접 이관하는 방향을 검토하고 있지만, 그 사이 데이터 변환의 표준화와 모듈화가 공백으로 남아있다. 이것이 Joe Reis가 말한 \u0026ldquo;89%의 고통\u0026quot;과 정확히 일치하는 부분이다.\n시맨틱 레이어 역시 미답 영역이다. 비즈니스 메트릭의 정의가 팀마다 다르고, 동일한 지표에 대해 서로 다른 SQL을 사용하는 문제가 존재한다. 서베이에서 시맨틱 모델 교육 수요가 19%로 높게 나온 것처럼, 조직 전체의 데이터 리터러시를 끌어올리는 작업이 시급하다.\n특히 AI 에이전트가 데이터를 자율적으로 활용하는 미래를 대비하면, 잘 정의된 시맨틱 레이어는 선택이 아닌 필수다. 플랫폼 전환이 지연되더라도 모델링 표준과 시맨틱 정의는 독립적으로 진행할 수 있고, 진행해야 한다.\n3. 오케스트레이션 통합 — Airflow의 미래 트렌드 요약 Airflow가 여전히 지배적이지만, Dagster가 소규모 기업에서 12%의 점유율을 보이며 바텀업으로 성장하고 있다. 오케스트레이션이 아예 없는 팀이 모든 기업 규모에서 20%라는 점도 놀랍다.\n우리가 하고 있는 것 Airflow를 깊이 커스터마이징하여 운영하고 있다. 자체 Provider 패키지를 개발하고, 데이터 검증 자동화 오퍼레이터, 커스텀 전송 오퍼레이터 등 플랫폼에 특화된 기능을 구현했다. 현재 Airflow 3.x 메이저 버전 업그레이드를 진행 중이며, Python 버전 업그레이드와 Breaking Change 대응을 체계적으로 계획하고 있다.\n해야 할 것 Airflow에 대한 깊은 투자는 강점이지만, 동시에 기술 부채이기도 하다.\n커스텀 Provider의 유지보수 부담 버전 업그레이드 시 호환성 이슈 AI 에이전트 오케스트레이션이라는 새로운 패러다임에 대한 대비 Joe Reis가 예측한 것처럼 오케스트레이션이 플랫폼에 흡수되는 방향도 지켜봐야 한다. 차세대 데이터 플랫폼과의 정합성을 고려하면, 오케스트레이션 전략의 중장기적 로드맵 수립이 시급하다.\n4. Lakehouse vs. Warehouse — 이미 답을 낸 영역 트렌드 요약 서베이에서 44%가 Warehouse, 27%가 Lakehouse, 12%가 Hybrid를 사용하고 있다. Snowflake과 Databricks의 기능이 수렴하면서 이 논쟁 자체가 무의미해지고 있다. Joe Reis는 2026년 말이면 \u0026ldquo;warehouse vs. lakehouse\u0026rdquo; 논쟁이 구식으로 느껴질 것이라 예측한다.\n우리가 하고 있는 것 이 트렌드에서 우리 팀은 이미 정답에 가까운 위치에 있다. S3 위에 Iceberg 오픈 테이블 포맷을 표준으로 채택하고, 용도에 따라 Trino와 StarRocks를 선택적으로 사용하는 구조는 Warehouse도 Lakehouse도 아닌, 양쪽의 장점을 취한 아키텍처다. CDC 파이프라인을 통해 실시간 데이터를 Iceberg 테이블로 적재하고, 배치와 실시간 분석을 동일한 데이터 위에서 수행할 수 있다.\n해야 할 것 Iceberg v3의 Deletion Vector, Row Lineage 등 새로운 기능을 적극 활용하기 위해서는 쿼리 엔진 전반의 호환성 확보가 필요하다. 현재 Trino와 StarRocks의 Iceberg v3 지원이 제한적이므로, 엔진 업그레이드 로드맵과 Iceberg 버전 전략을 연계해야 한다. 또한 오픈 테이블 포맷 기반 아키텍처의 거버넌스 체계 — 카탈로그 통합, 접근 제어, 데이터 품질 보장 — 를 더 강화해야 한다.\n5. 리더십이 병목이 되는 문제 — 가장 어렵고 가장 중요한 과제 트렌드 요약 데이터 엔지니어의 22%가 \u0026ldquo;리더십 방향 부재\u0026quot;를 주요 이슈로 꼽았고, 이는 레거시 기술 부채(26%)에 버금가는 수치다. Joe Reis는 2026년에 더 많은 데이터 팀이 해체되거나 엔지니어링 조직에 합병될 것이라 경고한다.\n우리가 하고 있는 것 데이터 플랫폼 팀이 독립적인 조직으로 존재하며, 인프라부터 수집, 변환, 분석 환경까지 End-to-End로 책임지는 구조를 갖추고 있다. 비즈니스 팀과의 직접적인 소통 채널을 유지하며, 데이터 요건을 직접 수렴하고 있다.\n해야 할 것 기술적 역량만으로는 팀의 존재 가치를 증명할 수 없다. Joe Reis가 강조한 것처럼 \u0026ldquo;비즈니스 가치를 증명한 팀만 살아남는다.\u0026rdquo;\n데이터 플랫폼의 ROI를 정량적으로 측정하고 커뮤니케이션하는 체계 AI 시대에 데이터 플랫폼이 어떤 역할을 해야 하는지에 대한 비전 수립 데이터 옵저버빌리티 도입을 통한 데이터 다운타임 감소 파이프라인 개발 생산성 지표화 등 구체적인 비즈니스 임팩트 제시 정리: 잘 하고 있는 것 vs. 해야 할 것 영역 잘 하고 있는 것 해야 할 것 AI 활용 개인 단위 AI 코딩 도구 적극 활용 팀 워크플로우에 AI 임베드, 운영 자동화 데이터 모델링 카탈로그 기반 메타데이터 관리, 레이어 체계 정의 시맨틱 레이어 도입, 데이터 변환 표준화 오케스트레이션 Airflow 깊은 커스터마이징, 3.x 업그레이드 진행 장기 오케스트레이션 전략, AI 에이전트 대응 Lakehouse/Warehouse Iceberg 기반 하이브리드 아키텍처 구축 완료 Iceberg v3 호환성, 거버넌스 체계 강화 리더십 End-to-End 플랫폼 팀 운영 비즈니스 임팩트 정량화, 데이터 옵저버빌리티 마치며 Joe Reis의 서베이에서 가장 인상적이었던 문장은 이것이다.\n\u0026ldquo;2026년 데이터 엔지니어링은 올바른 도구를 고르는 것보다 그 도구를 잘 활용할 조직적 근육을 키우는 것이 더 중요하다.\u0026rdquo;\n우리 팀은 기술 스택 면에서 트렌드의 앞쪽에 서 있다. Iceberg 기반 오픈 데이터 레이크, 실시간과 배치를 아우르는 하이브리드 아키텍처, 깊이 있는 Airflow 커스터마이징 등은 많은 조직이 아직 도달하지 못한 수준이다.\n하지만 기술적 우위만으로는 충분하지 않다. 데이터 변환 표준화, 시맨틱 레이어, 데이터 옵저버빌리티, AI 네이티브 워크플로우, 그리고 무엇보다 비즈니스 가치를 증명하는 리더십 — 이것이 2026년에 우리가 집중해야 할 방향이다.\n과거의 빚은 이자를 물고 있고, 페이데이가 다가오고 있다. 지금이 기반을 다질 때다.\n원문 참고: Where Data Engineering Is Heading in 2026 — Joe Reis\n","permalink":"https://NhoSW.github.io/my-tech-blog/ko/posts/2026-data-engineering-trends/","summary":"Joe Reis의 1,101명 서베이를 기반으로 한 2026년 데이터 엔지니어링 트렌드를, 대규모 플랫폼 데이터 엔지니어링 팀의 현재 아키텍처와 대조하며 정리했습니다. 이미 잘 하고 있는 것과 앞으로 해야 할 것을 솔직하게 돌아봅니다.","title":"2026 데이터 엔지니어링 트렌드와 대규모 플랫폼의 현주소"},{"content":"Trino를 프로덕션 쿼리 엔진으로 운영하는 팀이라면, 2025년 한 해 동안 느꼈을 것이다. 릴리스가 뜸해졌다. 감각의 문제가 아니라 숫자로 드러나는 변화다. 2024년 30개였던 Trino 오픈소스 릴리스가 2025년에는 11개로 줄었다. 63% 감소.\n이 글에서는 Starburst가 왜, 어떻게 AI 중심 플랫폼 기업으로 전환했는지를 분석하고, Trino 오픈소스 사용자 입장에서 이 변화를 어떻게 바라봐야 하는지 정리한다.\nTrino 릴리스, 무슨 일이 일어났나 릴리스 빈도의 급격한 변화 Trino 오픈소스의 릴리스 패턴을 분기별로 보면, 감소 추세가 뚜렷하다.\n기간 릴리스 수 평균 주기 비고 2024 Q4 9개 주 1회 안정적 패턴 2025 Q1 6개 2주 1회 감소 시작 2025 Q2 2개 월 1회 급격한 감소 2025 Q3 1개 분기 1회 최저점 2025 Q4 2개 1.5개월 1회 여전히 저조 2024년 Q4까지만 해도 매주 새 릴리스가 나왔다. 그런데 2025년 Q2부터 월 1회 수준으로 떨어졌고, Q3에는 분기 전체에 릴리스가 단 1개였다. Starburst Enterprise 릴리스도 마찬가지로 극소수에 그쳤다.\n숫자만 놓고 보면 심각해 보이지만, 이것이 Trino의 \u0026ldquo;쇠퇴\u0026quot;를 의미하는 건 아니다. Starburst의 전략적 선택이다.\n왜 줄었는가 Trino 오픈소스에 대한 Starburst의 기여도를 보면 답이 보인다. 2024년 기준으로 Starburst 팀이 Trino 전체 커밋의 **84%**를 차지했다. 138명의 기여자, 2,822개 커밋, 50개 이상 기업이 참여했지만, 실질적인 개발 동력은 Starburst였다. 그 Starburst가 엔지니어링 리소스를 다른 곳에 집중하기 시작한 것이다.\n그 \u0026ldquo;다른 곳\u0026quot;이 바로 AI다.\nStarburst의 AI 피벗 포지셔닝의 변화 Starburst의 공식 메시징 변화를 추적하면, 전환이 얼마나 의도적이었는지 알 수 있다.\n시기 포지셔닝 핵심 메시지 ~2023 Open Data Lakehouse Company Trino 기반 분산 쿼리 엔진 2024 Data Lake Analytics Platform 페더레이션 쿼리 + Iceberg 2025 Data Platform for Apps and AI AI Agent + Agentic Workforce \u0026ldquo;Open Data Lakehouse\u0026quot;에서 \u0026ldquo;Data Platform for Apps and AI\u0026quot;로. 단순한 마케팅 변화가 아니라, 제품 로드맵 전체가 이 방향으로 정렬되었다.\n2025년 주요 발표 타임라인 2025년 5월 — Launch Point\nStarburst는 AI Agent와 AI Workflows를 공식 발표했다.\nAI Agent: 자연어로 데이터를 쿼리하는 인터페이스. \u0026ldquo;What were our sales in Europe last quarter?\u0026ldquo;라는 질문이 자동으로 SQL로 변환된다. Air-gapped 환경(금융, 의료, 정부)을 명시적으로 지원하며, Google의 Agent2Agent 프로토콜과 Anthropic의 Model Context Protocol(MCP)을 지원한다. AI Workflows: Vector embeddings를 Iceberg 테이블에 저장하고, 구조화/반구조화/비구조화 데이터를 AI 학습에 활용할 수 있는 파이프라인. RAG(Retrieval-Augmented Generation)를 네이티브로 지원한다. 기타: Starburst Data Catalog(Hive Metastore 대체), Automated Table Maintenance(파일 정리 및 컴팩션 자동화), Native ODBC Driver, Role-based Query Routing 2025년 10월 — AI \u0026amp; Datanova 2025\n여기서 Starburst는 Agentic Workforce 플랫폼과 Lakeside AI Architecture를 발표하며 한 단계 더 나아갔다.\n핵심 개념은 Model-to-Data 아키텍처다. 기존의 접근 방식이 데이터를 중앙 웨어하우스로 모은 뒤 AI 모델을 돌리는 것이었다면, Starburst는 AI 모델을 데이터가 있는 곳으로 보내는 방식을 제안한다.\n기존 접근: Data → Centralized Warehouse → AI Model Starburst: AI Model → Federated Data (where it lives) 데이터를 이동시키지 않으므로 데이터 주권(GDPR, Schrems II)을 유지하면서도 통합 분석이 가능하다는 논리다. Citi, HSBC 같은 글로벌 금융기관이 165개국에 흩어진 데이터를 이 방식으로 통합하고 있다고 한다.\n기술 스택의 변화 Starburst의 기술 스택을 레이어로 표현하면, 2025년에 추가된 부분이 명확히 보인다.\n┌─────────────────────────────────────┐ │ AI Agent \u0026amp; Agent2Agent Protocol │ ← 2025 NEW ├─────────────────────────────────────┤ │ AI Workflows (Vector Store) │ ← 2025 NEW ├─────────────────────────────────────┤ │ Starburst Data Catalog │ ← 2025 NEW ├─────────────────────────────────────┤ │ Lakehouse (Trino + Iceberg) │ ├─────────────────────────────────────┤ │ Federated Data Sources (50+) │ └─────────────────────────────────────┘ Trino는 여전히 기반 레이어에 있지만, 혁신은 전부 위에서 일어나고 있다. Trino 오픈소스 릴리스가 줄어든 이유가 여기에 있다. 엔지니어링 리소스가 상위 레이어로 이동한 것이다.\nVector Store on Iceberg: 주목할 만한 기술적 혁신 2025년 Starburst 발표 중 기술적으로 가장 흥미로운 것은 Apache Iceberg 테이블에 직접 vector embeddings를 저장하는 접근이다.\n이게 왜 의미 있는가:\n별도의 벡터 DB가 필요 없다. Pinecone, Weaviate, Milvus 같은 전용 벡터 데이터베이스를 운영할 필요가 없어진다. 기존 데이터 엔지니어링 스킬을 그대로 활용한다. Iceberg 테이블을 다루는 방식 그대로 벡터 데이터를 관리할 수 있다. Iceberg의 장점이 벡터 데이터에도 적용된다. Time travel, ACID 트랜잭션, 스키마 진화, 파티셔닝 등을 벡터 데이터에도 활용할 수 있다. 거버넌스 정책이 일관성 있게 적용된다. 구조화 데이터와 벡터 데이터에 동일한 접근 제어, 감사 로그, 데이터 마스킹 정책을 적용할 수 있다. 오픈 포맷이므로 vendor lock-in이 없다. AI 워크로드가 데이터 플랫폼의 핵심 요구사항이 되는 미래를 가정하면, 이 접근은 상당히 실용적이다. 물론 전용 벡터 DB 대비 검색 성능은 트레이드오프가 있을 수 있지만, 운영 복잡도 감소와 거버넌스 통합이라는 장점은 엔터프라이즈 환경에서 매력적이다.\n비즈니스 성과: 전략이 시장에서 통하고 있는가 AI 피벗이 단순한 마케팅이 아니라는 것은 비즈니스 지표가 증명한다.\nFY25 실적 (2025년 2월 발표):\n지표 성과 신규 고객 전년 대비 20% 증가 Galaxy(SaaS) 고객 전년 대비 76% 증가 Galaxy 사용량 전년 대비 94% 증가 최대 계약 글로벌 금융기관과 8자리(억 단위) 다년 계약 파트너십 Dell Data Lakehouse의 쿼리 엔진으로 선정 특히 Galaxy(SaaS) 고객이 76% 증가했다는 것은 주목할 만하다. 클라우드 매니지드 서비스로의 전환이 가속화되고 있다는 의미이고, 이는 오픈소스 Trino를 직접 운영하는 팀들의 대안이기도 하다.\n주요 고객사도 인상적이다:\nHSBC: 165개국 데이터 통합 Citi: 글로벌 데이터 주권 유지하며 통합 분석 Vectra AI: 120개국 위협 탐지 플랫폼 ZoomInfo: 멀티클라우드 데이터 통합 경쟁 환경에서의 포지셔닝 데이터 플랫폼 시장에서 Starburst의 위치를 경쟁사와 비교하면 차별화 포인트가 명확해진다.\n기능 Databricks Snowflake Dremio Starburst AI Agent O O X O Federated Query 제한적 제한적 O 핵심 강점 Data Sovereignty 제한적 제한적 제한적 핵심 강점 오픈소스 기반 Spark X Arrow Trino Vector Store O O X O (Iceberg) On-prem + Cloud O 제한적 O 핵심 강점 Starburst의 핵심 차별화는 세 가지다:\n진정한 페더레이션: 50개 이상 데이터 소스에 대한 실시간 쿼리. 데이터를 이동시키지 않고 제자리에서 분석한다. 데이터 주권: 165개국 규제를 준수하면서 통합 분석을 제공한다. GDPR, Schrems II 환경에서 결정적 장점이다. 하이브리드 배포: On-premise와 멀티 클라우드를 동시에 지원한다. 규제 산업에서 클라우드 전환이 더딘 기업들에게 핵심 가치다. 반면 Databricks는 Spark + Delta Lake 중심의 AI/ML Lakehouse로, Unity Catalog으로 거버넌스를 강화하고 있다. Snowflake는 2024년 Iceberg 지원을 추가하고 Snowpark으로 AI/ML을 밀고 있지만, 여전히 데이터 중앙화가 전제다. Dremio는 Arrow Flight 기반 성능과 시맨틱 레이어를 강조하지만, 엔터프라이즈 기능에서는 아직 격차가 있다.\n흥미로운 것은 Starburst CEO Justin Borgman의 발언이다: \u0026ldquo;What they\u0026rsquo;ve done for Spark is what we aim to do for Presto(Trino).\u0026rdquo; Databricks가 Spark 오픈소스 위에 강력한 상용 플랫폼을 구축한 것처럼, Starburst도 Trino 위에 같은 구조를 만들겠다는 것이다.\nTrino 오픈소스, 괜찮을 것인가 오픈소스와 상용 기능의 분리 현재 Trino 오픈소스에 남아있는 것과 Starburst 전용으로 넘어간 것을 정리하면 다음과 같다.\nTrino 오픈소스:\n핵심 쿼리 엔진 기본 커넥터들 Fault-tolerant execution SQL MERGE 기본 보안 기능 Starburst 전용:\nWarp Speed (최대 7배 성능 향상) AI Agent \u0026amp; AI Workflows Starburst Data Catalog 고급 거버넌스 (RBAC, 데이터 마스킹, 감사 로그) Automated Table Maintenance Smart Indexing Materialized Views (일부) 가장 눈에 띄는 것은 Warp Speed다. 최대 7배 성능 향상을 제공하는 독점 인덱싱/캐싱 레이어가 상용 전용이라는 것은, 대규모 워크로드에서 오픈소스와 상용 제품의 성능 격차가 점점 벌어질 수 있다는 의미다.\n낙관적으로 볼 수 있는 근거 Trino 코어 엔진은 성숙 단계에 접어들었다. 분산 SQL 쿼리 엔진으로서 필요한 기능은 대부분 갖추고 있다. 릴리스 빈도가 줄었다고 품질이 떨어지는 것은 아니다. 커뮤니티는 여전히 활발하다. Trino Summit 2024는 Netflix, LinkedIn, Wise 등이 참여하며 성공적으로 개최되었고, Trino Community Broadcast도 지속 운영 중이다. Slack과 GitHub 활동도 유지되고 있다. 50개 이상 기업이 기여하고 있다. Starburst의 기여가 줄더라도 다른 기업들이 메울 여지는 있다. 우려할 점 84%의 커밋을 한 회사가 다른 곳에 집중하기 시작했다. 다른 기업들이 이 공백을 메울 인센티브가 충분한지는 미지수다. 성능 최적화의 핵심이 상용 전용이다. Warp Speed 없이 대규모 워크로드를 운영하는 팀은 갈수록 불리해질 수 있다. AI 관련 혁신이 모두 상용 제품에 집중되어 있다. 데이터 플랫폼에 AI가 필수가 되는 미래에서, 오픈소스만으로는 경쟁력 확보가 어려워질 수 있다. Trino 운영 팀이 고려해야 할 것 Trino를 프로덕션에서 운영하는 팀의 입장에서, 이 상황을 두 가지 시간 축으로 나눠서 생각해 볼 수 있다.\n단기 (1~2년): 큰 문제 없다 Trino 오픈소스는 여전히 안정적이고 프로덕션에서 검증된 기술이다. 핵심 기능은 충분히 성숙했고, 기본적인 쿼리 성능과 커넥터 생태계는 탄탄하다. 당장 대안으로 갈아타야 할 이유는 없다.\n중장기 (3~5년): 전략적 대비가 필요하다 오픈소스와 상용 제품의 기능 격차가 확대될 가능성을 감안해야 한다. 특히 다음 영역에서의 대비가 필요하다:\n성능 최적화: Warp Speed 없이 대규모 워크로드의 성능을 어떻게 확보할 것인가. 자체적인 캐싱 레이어, 인덱싱 전략, 또는 StarRocks 같은 보완 엔진의 역할 확대를 검토해야 한다. AI 통합: 데이터 플랫폼에 AI를 통합하는 것이 조직의 요구사항이 될 때, 오픈소스 Trino만으로 충분한지 평가해야 한다. Vector Store on Iceberg 같은 접근을 자체적으로 구현할 수 있는지, 혹은 다른 도구와의 조합이 필요한지. 거버넌스: 조직이 커지고 규제가 강화될수록, 고급 거버넌스 기능(RBAC, 데이터 마스킹, 감사 로그)의 필요성이 커진다. 오픈소스만으로 이를 충족할 수 있는지. 대안 평가: Starburst Galaxy 도입, 다른 쿼리 엔진으로의 전환, 또는 하이브리드 접근(배치는 Trino, 실시간은 StarRocks)을 주기적으로 평가해야 한다. 마치며 Starburst의 AI 피벗은 단순한 마케팅 전략이 아니다. 비즈니스 지표(Galaxy 고객 76% 증가, 역대 최대 계약)가 이 전략이 시장에서 통하고 있음을 증명하고 있다. 쿼리 엔진 회사에서 AI 플랫폼 기업으로의 전환은 되돌릴 수 없는 방향이다.\nTrino 오픈소스는 당장 죽지 않는다. 하지만 \u0026ldquo;충분히 성숙한\u0026rdquo; 상태로 유지보수 모드에 가까워지고 있으며, 혁신의 무게 중심은 명확하게 상용 제품으로 이동했다. 이것은 Databricks가 Spark에 대해 했던 것과 같은 패턴이다.\nTrino를 프로덕션에서 운영하는 팀이라면, 지금 당장은 안심해도 되지만, 3년 뒤를 위한 대비는 지금 시작해야 한다. 오픈소스의 안정성에 기대면서도, 성능 격차와 AI 통합이라는 두 가지 축에서 전략적 옵션을 확보해 두는 것이 현명한 접근이다.\n기술 부채는 늘 조용히 쌓인다. 그리고 언제나 우리가 생각했던 것보다 이자가 비싸다.\n참고 자료:\nTrino Release Notes Starburst Enterprise Release Notes TechTarget: Addition of new AI capabilities shows Starburst\u0026rsquo;s growth BigDataWire: Starburst\u0026rsquo;s New Platform Aims to Close AI\u0026rsquo;s Biggest Gap ","permalink":"https://NhoSW.github.io/my-tech-blog/ko/posts/starburst-trino-ai-pivot/","summary":"Starburst가 쿼리 엔진 회사에서 AI 플랫폼 기업으로 전환하면서 Trino 오픈소스 릴리스가 63% 감소했다. Trino를 프로덕션에서 운영하는 팀의 관점에서, 이 변화가 의미하는 것과 앞으로의 전략을 정리한다.","title":"Starburst의 AI 피벗: Trino 오픈소스는 괜찮을까?"},{"content":"도입 배경 데이터 파이프라인을 운영하다 보면 한 가지 고민에 반드시 부딪힌다. 실시간 대시보드를 어떻게 만들 것인가?\n우리 팀도 마찬가지였다. 기존 파이프라인은 다음과 같은 구조였다.\nService → Kafka → Iceberg → S3 → Trino → Airflow(5분) → Dashboard 겉보기엔 잘 동작했지만, 실무에서 체감하는 문제는 분명했다.\n최소 5분 지연: Airflow 스케줄 주기가 병목이었다 파이프라인 복잡도: Kafka → Flink → Redis → API → Dashboard로 이어지는 5개 이상의 컴포넌트 관리 반복되는 I/O: Trino가 매 쿼리마다 S3를 풀스캔하는 구조 높은 개발 비용: 새로운 실시간 대시보드 하나에 약 2주 소요 StarRocks를 도입한 후의 아키텍처는 이렇게 단순해졌다.\nService → Kafka → StarRocks → Dashboard (서브초 레이턴시) 중간 컴포넌트가 사라지면서 파이프라인이 극적으로 단순해졌고, 데이터가 Kafka에서 StarRocks로 직접 수집되면서 실시간성도 확보했다.\n도입 효과 약 3개월간의 PoC와 6개월간의 단계적 도입을 거쳐 다음과 같은 개선을 달성했다.\n항목 Before After 개선폭 대시보드 지연 5분 \u0026lt; 1초 ~300배 대시보드 개발 기간 ~2주 ~1주 50% 단축 파이프라인 컴포넌트 5개 이상 2개 60% 감소 쿼리 응답 시간 30~50초 5~10초 5~10배 하드웨어 비용 128GB × 18노드 64GB × 3노드 ~75% 절감 Trino는 절대적인 쿼리 시간에서는 빠르지만, Airflow 스케줄 지연을 포함한 end-to-end 레이턴시와 하드웨어 비용 효율 면에서 StarRocks가 실시간 워크로드에 더 적합했다.\n테이블 모델 선택 가이드 StarRocks를 처음 도입할 때 가장 중요한 결정이 테이블 모델 선택이다. 잘못 고르면 나중에 테이블을 다시 만들어야 한다.\n의사결정 흐름 ┌─────────────────────────────┐ │ 어떤 데이터를 저장하는가? │ └──────────────┬──────────────┘ │ ┌───────▼────────┐ │ UPDATE 필요? │ └───────┬────────┘ │ ┌────────┴────────┐ │ │ [아니오] [예] │ │ ┌─────▼─────┐ ┌─────▼──────┐ │ 집계 필요? │ │ Primary Key │ └─────┬─────┘ │ (빈번한 │ │ │ UPDATE) │ [아니오] [예] └────────────┘ │ │ ┌─────▼───┐ ┌▼──────────┐ │Duplicate│ │Aggregate │ │(원본 저장)│ │(자동 집계) ★│ └─────────┘ └────────────┘ 모델 비교 모델 중복 허용 UPDATE 자동 집계 적합한 용도 Duplicate Key O X X 로그, 원본 이벤트 Aggregate Key X 자동 O 실시간 통계 ★ Primary Key X O (고속) X 빈번한 UPDATE Duplicate Key: 원본 데이터 저장 클릭 로그, API 이벤트, 센서 데이터처럼 원본을 그대로 보관해야 할 때 사용한다.\nCREATE TABLE order_events ( event_id BIGINT, event_time DATETIME, order_id VARCHAR(50), user_id BIGINT, event_type VARCHAR(20), amount DECIMAL(10, 2) ) DUPLICATE KEY(event_id, event_time) PARTITION BY date_trunc(\u0026#39;day\u0026#39;, event_time) DISTRIBUTED BY HASH(event_id) BUCKETS 10; Aggregate Key: 실시간 통계 ★ 데이터가 수집되는 시점에 자동으로 집계가 일어난다. 이 모델이 StarRocks 도입의 핵심이었다.\nCREATE TABLE order_stats ( stat_time DATETIME NOT NULL COMMENT \u0026#39;5분 간격\u0026#39;, region VARCHAR(20) NOT NULL, delivery_type VARCHAR(20) NOT NULL, -- 집계 컬럼: 수집 시 자동으로 집계 함수 적용 order_count BIGINT SUM DEFAULT \u0026#34;0\u0026#34;, total_amount DECIMAL(15, 2) SUM DEFAULT \u0026#34;0\u0026#34;, user_bitmap BITMAP BITMAP_UNION, max_amount DECIMAL(10, 2) MAX ) AGGREGATE KEY(stat_time, region, delivery_type) PARTITION BY date_trunc(\u0026#39;day\u0026#39;, stat_time) DISTRIBUTED BY HASH(stat_time) BUCKETS 10; 사용 가능한 집계 함수:\n함수 용도 예시 SUM 합계 주문 건수, 매출 합계 MAX / MIN 최대/최소값 최고가, 최저가 REPLACE 최신 값 덮어쓰기 최종 상태 BITMAP_UNION 정확한 유니크 카운트 순 이용자 수 HLL_UNION 근사 유니크 카운트 대규모 카디널리티 BITMAP_UNION은 HyperLogLog와 달리 정확한 유니크 카운트를 제공한다. 비즈니스 KPI 대시보드처럼 정확도가 중요한 경우 반드시 이 방식을 사용하자.\nPrimary Key: 빈번한 UPDATE 주문 상태 추적, 재고 관리처럼 같은 키의 데이터가 자주 갱신되는 경우에 적합하다.\nCREATE TABLE orders ( order_id VARCHAR(50) NOT NULL, status VARCHAR(20), amount DECIMAL(10, 2), updated_at DATETIME ) PRIMARY KEY(order_id) DISTRIBUTED BY HASH(order_id) BUCKETS 10 PROPERTIES ( \u0026#34;enable_persistent_index\u0026#34; = \u0026#34;true\u0026#34; ); enable_persistent_index를 활성화하면 UPDATE 성능이 크게 향상된다.\n데이터 수집 Routine Load: Kafka 실시간 연동 Kafka 토픽에서 데이터를 연속으로 수집하는 방식이다. 대부분의 실시간 파이프라인에서 이 방식을 사용한다.\nCREATE ROUTINE LOAD order_load ON orders COLUMNS( order_id, user_id, timestamp_ms, amount, order_date = FROM_UNIXTIME(timestamp_ms / 1000) ) PROPERTIES ( \u0026#34;format\u0026#34; = \u0026#34;json\u0026#34;, \u0026#34;jsonpaths\u0026#34; = \u0026#34;[\\\u0026#34;$.orderId\\\u0026#34;,\\\u0026#34;$.userId\\\u0026#34;,\\\u0026#34;$.timestamp\\\u0026#34;,\\\u0026#34;$.amount\\\u0026#34;]\u0026#34; ) FROM KAFKA ( \u0026#34;kafka_broker_list\u0026#34; = \u0026#34;kafka-broker:9092\u0026#34;, \u0026#34;kafka_topic\u0026#34; = \u0026#34;orders\u0026#34; ); Aggregate Key 테이블과 결합하면 수집 시점에 변환과 집계를 동시에 처리할 수 있다.\nCREATE ROUTINE LOAD order_stats_load ON order_stats COLUMNS( timestamp_ms, region, amount, user_id, -- 5분 간격으로 라운딩 stat_time = FROM_UNIXTIME(FLOOR(timestamp_ms / 1000 / 300) * 300), order_count = 1, total_amount = amount, user_bitmap = BITMAP_HASH(user_id) ) WHERE amount \u0026gt; 0 PROPERTIES (\u0026#34;format\u0026#34; = \u0026#34;json\u0026#34;) FROM KAFKA ( \u0026#34;kafka_broker_list\u0026#34; = \u0026#34;kafka-broker:9092\u0026#34;, \u0026#34;kafka_topic\u0026#34; = \u0026#34;orders\u0026#34; ); 이 패턴 하나로 기존에 Flink로 처리하던 집계 로직을 SQL만으로 대체할 수 있었다.\nStream Load: 벌크 데이터 로딩 파일이나 API를 통한 일회성 대량 로딩에 적합하다.\n# CSV 파일 로딩 curl --location-trusted \\ -u user:password \\ -H \u0026#34;label:load_$(date +%Y%m%d%H%M%S)\u0026#34; \\ -H \u0026#34;column_separator:,\u0026#34; \\ -T data.csv \\ http://starrocks-fe:8030/api/mydb/mytable/_stream_load 성능 튜닝 실전 팁 Thread Pool 설정 동시 접속이 500 RPS 이상인 고부하 환경에서는 기본 Thread Pool 크기가 부족하다.\n# be.conf pipeline_scan_thread_pool_thread_num = 32 # 기본값: 24 pipeline_exec_thread_pool_thread_num = 32 # 기본값: 24 Bucket Count 가이드라인 데이터 크기 권장 Bucket 수 \u0026lt; 10 GB 10 10~50 GB 20 50~100 GB 30 \u0026gt; 100 GB 50+ 산정 공식: buckets = max(1, 데이터_크기_GB / 10)\n파티셔닝 전략 파티션 컬럼에 함수를 사용하면 파티션 프루닝이 동작하지 않는다. 이것은 생각보다 자주 실수하는 부분이다.\n-- ✅ 올바른 사용: 파티션 프루닝 동작 WHERE event_time \u0026gt;= NOW() - INTERVAL 3 DAY -- ❌ 잘못된 사용: 파티션 프루닝 불가 WHERE DATE(event_time) \u0026gt;= CURRENT_DATE - 3 TTL 설정 오래된 파티션을 자동으로 삭제하려면 TTL을 설정한다.\nPROPERTIES ( \u0026#34;partition_live_number\u0026#34; = \u0026#34;3\u0026#34; -- 최근 3개 파티션만 유지 ) 운영 노하우 Materialized View 관리 ASYNC 리프레시가 예고 없이 멈추는 경우가 있다. 정기적으로 상태를 확인하고, 문제 발생 시 수동으로 복구해야 한다.\n-- 상태 확인 SHOW MATERIALIZED VIEWS; -- 강제 동기 리프레시 REFRESH MATERIALIZED VIEW db.mv_name WITH SYNC MODE; -- 비활성화된 MV 재활성화 ALTER MATERIALIZED VIEW db.mv_name ACTIVE; Routine Load 모니터링 상태가 PAUSED로 전환되는 경우가 잦다. Kafka offset 문제나 비정상 메시지가 원인이다.\n-- 상태 확인 SHOW ROUTINE LOAD FOR db.load_job; -- 재개 RESUME ROUTINE LOAD FOR db.load_job; Scale-in 주의사항 노드를 축소할 때는 반드시 Decommission을 먼저 수행해야 한다. 이 절차 없이 노드를 줄이면 데이터가 유실된다.\n-- 1. 현재 노드 확인 SHOW PROC \u0026#39;/backends\u0026#39;; -- 2. 디커미션 시작 ALTER SYSTEM DECOMMISSION BACKEND \u0026#34;\u0026lt;BE_IP\u0026gt;:\u0026lt;HEARTBEAT_PORT\u0026gt;\u0026#34;; -- 3. TabletNum이 0이 될 때까지 대기 후 제거 ALTER SYSTEM DROP BACKEND \u0026#34;\u0026lt;BE_IP\u0026gt;:\u0026lt;HEARTBEAT_PORT\u0026gt;\u0026#34;; 도입 시 알아두면 좋은 것들 알려진 제약 사항 이슈 설명 대안 Routine Load 비정상 메시지 처리 한계 Kafka 단에서 사전 검증 datetime 파티션 Iceberg datetime 파티션 호환 이슈 대체 파티션 전략 사용 버전 업그레이드 4.x 대에서 버그 경험 스테이징 환경 필수 테스트 버전 업그레이드는 반드시 스테이징 환경에서 충분히 검증한 뒤 프로덕션에 적용하자. 실제로 여러 차례 업그레이드/다운그레이드를 반복한 경험이 있다. 롤백 계획은 항상 준비해두어야 한다.\n도입 체크리스트 배포 전\n유스케이스와 요구사항 정의 데이터 볼륨 및 증가량 추정 테이블 모델 선택 파티션 전략 설계 배포 후\nRoutine Load 작업 생성 및 검증 사용자 권한 설정 데이터 보관 정책(TTL) 설정 Scale-in/out 절차 문서화 모니터링 대시보드 구성 마치며 StarRocks 도입에서 얻은 핵심 교훈을 정리하면 다음과 같다.\nAggregate Key 모델이 핵심이다 — 수집 시점 자동 집계로 스토리지와 쿼리 성능을 동시에 잡을 수 있다 BITMAP_UNION으로 정확한 유니크 카운트를 확보하자 — 비즈니스 KPI에는 근사치가 아닌 정확한 수치가 필요하다 Routine Load + Aggregate Key 조합이 Flink를 대체한다 — SQL만으로 실시간 집계 파이프라인을 구축할 수 있다 운영 자동화에 투자하자 — Materialized View와 Routine Load 모니터링은 필수다 실시간 분석 워크로드에서 StarRocks는 파이프라인 복잡도를 획기적으로 줄여주는 강력한 선택지다. 다만 버전 업그레이드와 운영 안정성 측면에서는 아직 성숙해지는 과정에 있으므로, 충분한 PoC와 스테이징 검증을 거쳐 도입하길 권장한다.\n참고 자료: StarRocks 공식 문서\n","permalink":"https://NhoSW.github.io/my-tech-blog/ko/posts/starrocks-adoption-guide/","summary":"기존 Trino + Airflow 파이프라인의 5분 지연을 서브초 레이턴시로 개선한 StarRocks 도입 과정을 정리했습니다. 테이블 모델 선택, 데이터 수집, 성능 튜닝, 운영 노하우까지 실무에서 얻은 교훈을 공유합니다.","title":"StarRocks 도입기: 실시간 OLAP으로 데이터 파이프라인을 혁신한 이야기"},{"content":"왜 압축 설정이 중요한가 StarRocks를 운영하다 보면 데이터가 수십 TB 규모로 늘어나는 시점이 반드시 온다. 이때 압축 설정 하나로 스토리지 비용이 30~50% 차이 나는 경우를 여러 번 경험했다. 단순히 저장 공간만의 문제가 아니다. 압축률이 높으면 디스크 I/O가 줄어들어 스캔 성능이 좋아지고, 반대로 압축/해제에 CPU를 많이 쓰면 지연 시간이 늘어난다. 결국 워크로드 특성에 맞는 압축 알고리즘을 선택하는 것이 StarRocks 운영의 핵심 튜닝 포인트 중 하나다.\n지원되는 압축 알고리즘 비교 StarRocks는 여러 압축 알고리즘을 지원한다. 실무에서 주로 사용하는 세 가지를 비교해 보겠다.\n알고리즘 압축률 압축 속도 해제 속도 적합한 워크로드 LZ4 보통 (2~3x) 매우 빠름 매우 빠름 실시간 분석, 저지연 쿼리 ZSTD 높음 (4~6x) 보통 빠름 배치 분석, 콜드 데이터 Snappy 낮음 (1.5~2x) 빠름 빠름 범용, 레거시 호환 ZLIB 높음 (4~5x) 느림 보통 아카이빙, 저빈도 접근 데이터 개인적으로 가장 많이 쓰는 조합은 핫 데이터에 LZ4, 콜드 데이터에 ZSTD다. Snappy는 Hadoop 에코시스템에서 넘어온 데이터를 다룰 때 간혹 사용하지만, 신규 테이블에는 권장하지 않는다.\n테이블 생성 시 압축 설정 방법 테이블을 생성할 때 PROPERTIES에서 compression 속성을 지정하면 된다. 별도로 설정하지 않으면 StarRocks 기본값인 LZ4가 적용된다.\n실시간 분석용 테이블 (LZ4) CREATE TABLE analytics.realtime_events ( event_id BIGINT, user_id BIGINT, event_type VARCHAR(64), event_time DATETIME, properties JSON ) ENGINE = OLAP DUPLICATE KEY(event_id) DISTRIBUTED BY HASH(user_id) BUCKETS 32 PROPERTIES ( \u0026#34;replication_num\u0026#34; = \u0026#34;3\u0026#34;, \u0026#34;compression\u0026#34; = \u0026#34;LZ4\u0026#34; ); LZ4는 해제 속도가 압도적으로 빠르기 때문에, 대시보드 쿼리처럼 수백 밀리초 이내 응답이 필요한 테이블에 적합하다.\n배치 분석용 테이블 (ZSTD) CREATE TABLE warehouse.order_history ( order_id BIGINT, customer_id BIGINT, order_date DATE, total_amount DECIMAL(18, 2), status VARCHAR(32), items ARRAY\u0026lt;STRUCT\u0026lt;sku STRING, qty INT, price DECIMAL(10,2)\u0026gt;\u0026gt; ) ENGINE = OLAP DUPLICATE KEY(order_id) PARTITION BY RANGE(order_date) ( PARTITION p2025 VALUES LESS THAN (\u0026#39;2026-01-01\u0026#39;), PARTITION p2026 VALUES LESS THAN (\u0026#39;2027-01-01\u0026#39;) ) DISTRIBUTED BY HASH(customer_id) BUCKETS 16 PROPERTIES ( \u0026#34;replication_num\u0026#34; = \u0026#34;2\u0026#34;, \u0026#34;compression\u0026#34; = \u0026#34;ZSTD\u0026#34; ); ZSTD는 압축률이 LZ4 대비 1.5~2배 높아서, 파티션 단위로 수억 건 이상 적재되는 히스토리 테이블에서 스토리지 절감 효과가 크다.\n기존 테이블 압축 변경 이미 운영 중인 테이블의 압축 알고리즘을 변경하고 싶다면 ALTER TABLE을 사용할 수 있다. 단, 변경 이후 새로 적재되는 데이터부터 적용되며 기존 세그먼트는 Compaction이 수행되어야 반영된다는 점에 유의하자.\nALTER TABLE warehouse.order_history SET (\u0026#34;compression\u0026#34; = \u0026#34;ZSTD\u0026#34;); 워크로드별 권장 압축 설정 실무에서 반복적으로 검증한 결과를 기반으로 정리하면 다음과 같다.\n실시간 대시보드 / Ad-hoc 쿼리: LZ4를 권장한다. CPU 오버헤드가 거의 없어 P99 지연 시간에 미치는 영향이 최소화된다. 야간 배치 리포트 / ETL 결과 테이블: ZSTD를 권장한다. 쿼리 빈도가 낮고 데이터 양이 많은 경우 스토리지 절감 효과가 비용에 직접 반영된다. 로그성 대용량 적재: ZSTD를 사용하되 zstd_compression_level을 3 이하로 낮추면 압축 속도와 압축률 사이의 균형을 잡을 수 있다. 압축률과 성능 트레이드오프 실측 결과 약 50억 건(원본 약 800GB)의 이벤트 로그 테이블을 대상으로 압축 알고리즘별 벤치마크를 수행한 결과다.\n지표 LZ4 ZSTD (level 3) ZSTD (level 9) 압축 후 크기 320 GB 195 GB 170 GB 압축률 2.5x 4.1x 4.7x 단순 스캔 쿼리 (Avg) 1.2초 1.5초 1.8초 집계 쿼리 (Avg) 3.4초 3.8초 4.5초 데이터 적재 속도 120 MB/s 95 MB/s 60 MB/s LZ4 대비 ZSTD level 3은 스토리지를 약 39% 절감하면서도 쿼리 지연은 약 10~15%만 증가했다. 반면 ZSTD level 9는 추가 압축 이득 대비 적재 속도 저하가 커서 대부분의 환경에서는 level 3이 최적의 선택이었다.\n운영 팁과 모니터링 마지막으로 실무에서 압축 관련 운영 시 놓치기 쉬운 포인트를 정리한다.\nCompaction 모니터링을 반드시 하자. 압축 알고리즘을 변경한 뒤 Compaction이 완료되기 전까지 혼합 세그먼트가 존재하면 쿼리 성능이 일시적으로 불안정해질 수 있다. BE의 compaction_score 메트릭을 모니터링하여 Compaction 적체 여부를 확인해야 한다.\n테이블 단위로 압축 전략을 분리하라. 하나의 클러스터에서 모든 테이블에 동일한 압축을 적용하는 것은 비효율적이다. 접근 빈도, 데이터 크기, SLA에 따라 테이블별로 다르게 설정하는 것이 올바른 접근이다.\n디스크 사용량 추이를 추적하라. 압축 변경 후 SHOW DATA 명령으로 테이블별 실제 디스크 사용량을 주기적으로 확인하고, 기대한 압축률이 나오지 않는다면 데이터 특성(카디널리티, NULL 비율 등)을 재점검해야 한다.\nSHOW DATA FROM warehouse.order_history; 압축 설정은 한 번 정하고 끝나는 것이 아니라, 데이터 특성과 워크로드가 변함에 따라 지속적으로 재검토해야 하는 영역이다. 이 글이 StarRocks 운영에서 압축 전략을 수립하는 데 실질적인 참고가 되길 바란다.\n","permalink":"https://NhoSW.github.io/my-tech-blog/ko/posts/starrocks-compression-guide/","summary":"StarRocks에서 압축 설정을 최적화하여 스토리지 비용을 절감하고 쿼리 성능을 향상시키는 방법을 실무 경험을 바탕으로 정리했습니다.","title":"StarRocks 압축 설정 가이드: 성능과 스토리지 최적화"},{"content":"운영자 정보 본 블로그는 노승우가 운영하며, 사이트 주소는 https://nhosw.github.io/my-tech-blog/ 입니다.\n수집하는 정보 Google Analytics 본 사이트는 방문자의 이용 현황을 파악하기 위해 Google Analytics 4(GA4)를 사용합니다. GA4는 다음 정보를 수집합니다:\n방문한 페이지 및 체류 시간 대략적인 위치 정보 (국가/도시 수준) 기기 유형, 브라우저, 운영체제 유입 경로 (사이트를 어떻게 찾았는지) Google Analytics는 쿠키를 사용하여 고유 방문자를 구분합니다. 개인을 식별할 수 있는 정보는 의도적으로 수집하지 않습니다.\n자세한 내용은 Google 개인정보처리방침을 참고하세요.\nGoogle AdSense 본 사이트는 Google AdSense를 통해 광고를 게재할 수 있습니다. AdSense는 쿠키와 웹 비콘을 사용하여 이전 방문 기록을 기반으로 광고를 제공합니다.\nGoogle은 DART 쿠키를 사용하여 브라우징 기록에 기반한 광고를 제공합니다 Google 광고 설정에서 맞춤 광고를 비활성화할 수 있습니다 자세한 내용은 Google AdSense 개인정보처리방침을 참고하세요.\n댓글 본 사이트는 현재 댓글 기능을 제공하지 않습니다. 향후 댓글 기능이 추가되면 본 방침을 업데이트하겠습니다.\n쿠키 쿠키는 사용자의 기기에 저장되는 작은 텍스트 파일입니다. 본 사이트는 다음 목적으로 쿠키를 사용합니다:\n분석: 사이트 트래픽 측정 (Google Analytics) 광고: 관련 광고 제공 (Google AdSense) 환경설정: 테마 설정 기억 (다크/라이트 모드) 브라우저 설정을 통해 쿠키를 제어할 수 있습니다. 쿠키를 비활성화하면 사이트 기능에 영향을 줄 수 있습니다.\n외부 링크 블로그 게시물에는 외부 웹사이트로의 링크가 포함될 수 있습니다. 외부 사이트의 개인정보 보호 관행에 대해서는 책임지지 않습니다.\n이용자의 권리 이용자는 다음 권리를 가집니다:\n수집되는 데이터에 대해 알 권리 추적 비활성화 (브라우저 설정 또는 Google 광고 설정) 본인 데이터에 대한 정보 요청 방침 변경 본 개인정보처리방침은 수시로 업데이트될 수 있습니다. 변경 사항은 이 페이지에 게시됩니다.\n문의 본 개인정보처리방침에 대해 궁금한 점이 있으시면 소개 페이지의 연락처로 문의해 주세요.\n최종 수정일: 2026년 2월 23일\n","permalink":"https://NhoSW.github.io/my-tech-blog/ko/privacy-policy/","summary":"개인정보처리방침","title":"개인정보처리방침"},{"content":"안녕하세요, 노승우입니다 저는 안정적이고 확장 가능한 데이터 인프라와 파이프라인을 구축하는 데이터 엔지니어입니다. 대규모 데이터의 수집, 변환, 서빙 과정에서 발생하는 다양한 문제를 해결하는 일에 보람을 느끼고 있습니다.\n블로그 소개 이 블로그는 실무에서 얻은 데이터 엔지니어링 지식을 공유하는 공간입니다. 실제 프로젝트에서 배운 교훈, 튜토리얼, 아키텍처 관련 의사결정, 그리고 데이터 분야에서 일하는 엔지니어분들께 도움이 될 만한 팁들을 다루고 있습니다.\n기술 스택 현재 주로 사용하고 있는 기술들입니다:\n스트림 처리: Apache Kafka 워크플로 오케스트레이션: Apache Airflow 쿼리 엔진: Trino, StarRocks 컨테이너 오케스트레이션: Kubernetes 언어: Python, SQL 인프라: Docker 연락처 GitHub: github.com/your-username LinkedIn: linkedin.com/in/your-profile 이메일: your-email@example.com 궁금한 점이나 제안 사항이 있으시면 편하게 연락 주세요!\n","permalink":"https://NhoSW.github.io/my-tech-blog/ko/about/","summary":"블로그 소개","title":"소개"}]