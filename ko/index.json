[{"content":"도입 배경 데이터 파이프라인을 운영하다 보면 한 가지 고민에 반드시 부딪힌다. 실시간 대시보드를 어떻게 만들 것인가?\n우리 팀도 마찬가지였다. 기존 파이프라인은 다음과 같은 구조였다.\nService → Kafka → Iceberg → S3 → Trino → Airflow(5분) → Dashboard 겉보기엔 잘 동작했지만, 실무에서 체감하는 문제는 분명했다.\n최소 5분 지연: Airflow 스케줄 주기가 병목이었다 파이프라인 복잡도: Kafka → Flink → Redis → API → Dashboard로 이어지는 5개 이상의 컴포넌트 관리 반복되는 I/O: Trino가 매 쿼리마다 S3를 풀스캔하는 구조 높은 개발 비용: 새로운 실시간 대시보드 하나에 약 2주 소요 StarRocks를 도입한 후의 아키텍처는 이렇게 단순해졌다.\nService → Kafka → StarRocks → Dashboard (서브초 레이턴시) 중간 컴포넌트가 사라지면서 파이프라인이 극적으로 단순해졌고, 데이터가 Kafka에서 StarRocks로 직접 수집되면서 실시간성도 확보했다.\n도입 효과 약 3개월간의 PoC와 6개월간의 단계적 도입을 거쳐 다음과 같은 개선을 달성했다.\n항목 Before After 개선폭 대시보드 지연 5분 \u0026lt; 1초 ~300배 대시보드 개발 기간 ~2주 ~1주 50% 단축 파이프라인 컴포넌트 5개 이상 2개 60% 감소 쿼리 응답 시간 30~50초 5~10초 5~10배 하드웨어 비용 128GB × 18노드 64GB × 3노드 ~75% 절감 Trino는 절대적인 쿼리 시간에서는 빠르지만, Airflow 스케줄 지연을 포함한 end-to-end 레이턴시와 하드웨어 비용 효율 면에서 StarRocks가 실시간 워크로드에 더 적합했다.\n테이블 모델 선택 가이드 StarRocks를 처음 도입할 때 가장 중요한 결정이 테이블 모델 선택이다. 잘못 고르면 나중에 테이블을 다시 만들어야 한다.\n의사결정 흐름 ┌─────────────────────────────┐ │ 어떤 데이터를 저장하는가? │ └──────────────┬──────────────┘ │ ┌───────▼────────┐ │ UPDATE 필요? │ └───────┬────────┘ │ ┌────────┴────────┐ │ │ [아니오] [예] │ │ ┌─────▼─────┐ ┌─────▼──────┐ │ 집계 필요? │ │ Primary Key │ └─────┬─────┘ │ (빈번한 │ │ │ UPDATE) │ [아니오] [예] └────────────┘ │ │ ┌─────▼───┐ ┌▼──────────┐ │Duplicate│ │Aggregate │ │(원본 저장)│ │(자동 집계) ★│ └─────────┘ └────────────┘ 모델 비교 모델 중복 허용 UPDATE 자동 집계 적합한 용도 Duplicate Key O X X 로그, 원본 이벤트 Aggregate Key X 자동 O 실시간 통계 ★ Primary Key X O (고속) X 빈번한 UPDATE Duplicate Key: 원본 데이터 저장 클릭 로그, API 이벤트, 센서 데이터처럼 원본을 그대로 보관해야 할 때 사용한다.\nCREATE TABLE order_events ( event_id BIGINT, event_time DATETIME, order_id VARCHAR(50), user_id BIGINT, event_type VARCHAR(20), amount DECIMAL(10, 2) ) DUPLICATE KEY(event_id, event_time) PARTITION BY date_trunc(\u0026#39;day\u0026#39;, event_time) DISTRIBUTED BY HASH(event_id) BUCKETS 10; Aggregate Key: 실시간 통계 ★ 데이터가 수집되는 시점에 자동으로 집계가 일어난다. 이 모델이 StarRocks 도입의 핵심이었다.\nCREATE TABLE order_stats ( stat_time DATETIME NOT NULL COMMENT \u0026#39;5분 간격\u0026#39;, region VARCHAR(20) NOT NULL, delivery_type VARCHAR(20) NOT NULL, -- 집계 컬럼: 수집 시 자동으로 집계 함수 적용 order_count BIGINT SUM DEFAULT \u0026#34;0\u0026#34;, total_amount DECIMAL(15, 2) SUM DEFAULT \u0026#34;0\u0026#34;, user_bitmap BITMAP BITMAP_UNION, max_amount DECIMAL(10, 2) MAX ) AGGREGATE KEY(stat_time, region, delivery_type) PARTITION BY date_trunc(\u0026#39;day\u0026#39;, stat_time) DISTRIBUTED BY HASH(stat_time) BUCKETS 10; 사용 가능한 집계 함수:\n함수 용도 예시 SUM 합계 주문 건수, 매출 합계 MAX / MIN 최대/최소값 최고가, 최저가 REPLACE 최신 값 덮어쓰기 최종 상태 BITMAP_UNION 정확한 유니크 카운트 순 이용자 수 HLL_UNION 근사 유니크 카운트 대규모 카디널리티 BITMAP_UNION은 HyperLogLog와 달리 정확한 유니크 카운트를 제공한다. 비즈니스 KPI 대시보드처럼 정확도가 중요한 경우 반드시 이 방식을 사용하자.\nPrimary Key: 빈번한 UPDATE 주문 상태 추적, 재고 관리처럼 같은 키의 데이터가 자주 갱신되는 경우에 적합하다.\nCREATE TABLE orders ( order_id VARCHAR(50) NOT NULL, status VARCHAR(20), amount DECIMAL(10, 2), updated_at DATETIME ) PRIMARY KEY(order_id) DISTRIBUTED BY HASH(order_id) BUCKETS 10 PROPERTIES ( \u0026#34;enable_persistent_index\u0026#34; = \u0026#34;true\u0026#34; ); enable_persistent_index를 활성화하면 UPDATE 성능이 크게 향상된다.\n데이터 수집 Routine Load: Kafka 실시간 연동 Kafka 토픽에서 데이터를 연속으로 수집하는 방식이다. 대부분의 실시간 파이프라인에서 이 방식을 사용한다.\nCREATE ROUTINE LOAD order_load ON orders COLUMNS( order_id, user_id, timestamp_ms, amount, order_date = FROM_UNIXTIME(timestamp_ms / 1000) ) PROPERTIES ( \u0026#34;format\u0026#34; = \u0026#34;json\u0026#34;, \u0026#34;jsonpaths\u0026#34; = \u0026#34;[\\\u0026#34;$.orderId\\\u0026#34;,\\\u0026#34;$.userId\\\u0026#34;,\\\u0026#34;$.timestamp\\\u0026#34;,\\\u0026#34;$.amount\\\u0026#34;]\u0026#34; ) FROM KAFKA ( \u0026#34;kafka_broker_list\u0026#34; = \u0026#34;kafka-broker:9092\u0026#34;, \u0026#34;kafka_topic\u0026#34; = \u0026#34;orders\u0026#34; ); Aggregate Key 테이블과 결합하면 수집 시점에 변환과 집계를 동시에 처리할 수 있다.\nCREATE ROUTINE LOAD order_stats_load ON order_stats COLUMNS( timestamp_ms, region, amount, user_id, -- 5분 간격으로 라운딩 stat_time = FROM_UNIXTIME(FLOOR(timestamp_ms / 1000 / 300) * 300), order_count = 1, total_amount = amount, user_bitmap = BITMAP_HASH(user_id) ) WHERE amount \u0026gt; 0 PROPERTIES (\u0026#34;format\u0026#34; = \u0026#34;json\u0026#34;) FROM KAFKA ( \u0026#34;kafka_broker_list\u0026#34; = \u0026#34;kafka-broker:9092\u0026#34;, \u0026#34;kafka_topic\u0026#34; = \u0026#34;orders\u0026#34; ); 이 패턴 하나로 기존에 Flink로 처리하던 집계 로직을 SQL만으로 대체할 수 있었다.\nStream Load: 벌크 데이터 로딩 파일이나 API를 통한 일회성 대량 로딩에 적합하다.\n# CSV 파일 로딩 curl --location-trusted \\ -u user:password \\ -H \u0026#34;label:load_$(date +%Y%m%d%H%M%S)\u0026#34; \\ -H \u0026#34;column_separator:,\u0026#34; \\ -T data.csv \\ http://starrocks-fe:8030/api/mydb/mytable/_stream_load 성능 튜닝 실전 팁 Thread Pool 설정 동시 접속이 500 RPS 이상인 고부하 환경에서는 기본 Thread Pool 크기가 부족하다.\n# be.conf pipeline_scan_thread_pool_thread_num = 32 # 기본값: 24 pipeline_exec_thread_pool_thread_num = 32 # 기본값: 24 Bucket Count 가이드라인 데이터 크기 권장 Bucket 수 \u0026lt; 10 GB 10 10~50 GB 20 50~100 GB 30 \u0026gt; 100 GB 50+ 산정 공식: buckets = max(1, 데이터_크기_GB / 10)\n파티셔닝 전략 파티션 컬럼에 함수를 사용하면 파티션 프루닝이 동작하지 않는다. 이것은 생각보다 자주 실수하는 부분이다.\n-- ✅ 올바른 사용: 파티션 프루닝 동작 WHERE event_time \u0026gt;= NOW() - INTERVAL 3 DAY -- ❌ 잘못된 사용: 파티션 프루닝 불가 WHERE DATE(event_time) \u0026gt;= CURRENT_DATE - 3 TTL 설정 오래된 파티션을 자동으로 삭제하려면 TTL을 설정한다.\nPROPERTIES ( \u0026#34;partition_live_number\u0026#34; = \u0026#34;3\u0026#34; -- 최근 3개 파티션만 유지 ) 운영 노하우 Materialized View 관리 ASYNC 리프레시가 예고 없이 멈추는 경우가 있다. 정기적으로 상태를 확인하고, 문제 발생 시 수동으로 복구해야 한다.\n-- 상태 확인 SHOW MATERIALIZED VIEWS; -- 강제 동기 리프레시 REFRESH MATERIALIZED VIEW db.mv_name WITH SYNC MODE; -- 비활성화된 MV 재활성화 ALTER MATERIALIZED VIEW db.mv_name ACTIVE; Routine Load 모니터링 상태가 PAUSED로 전환되는 경우가 잦다. Kafka offset 문제나 비정상 메시지가 원인이다.\n-- 상태 확인 SHOW ROUTINE LOAD FOR db.load_job; -- 재개 RESUME ROUTINE LOAD FOR db.load_job; Scale-in 주의사항 노드를 축소할 때는 반드시 Decommission을 먼저 수행해야 한다. 이 절차 없이 노드를 줄이면 데이터가 유실된다.\n-- 1. 현재 노드 확인 SHOW PROC \u0026#39;/backends\u0026#39;; -- 2. 디커미션 시작 ALTER SYSTEM DECOMMISSION BACKEND \u0026#34;\u0026lt;BE_IP\u0026gt;:\u0026lt;HEARTBEAT_PORT\u0026gt;\u0026#34;; -- 3. TabletNum이 0이 될 때까지 대기 후 제거 ALTER SYSTEM DROP BACKEND \u0026#34;\u0026lt;BE_IP\u0026gt;:\u0026lt;HEARTBEAT_PORT\u0026gt;\u0026#34;; 도입 시 알아두면 좋은 것들 알려진 제약 사항 이슈 설명 대안 Routine Load 비정상 메시지 처리 한계 Kafka 단에서 사전 검증 datetime 파티션 Iceberg datetime 파티션 호환 이슈 대체 파티션 전략 사용 버전 업그레이드 4.x 대에서 버그 경험 스테이징 환경 필수 테스트 버전 업그레이드는 반드시 스테이징 환경에서 충분히 검증한 뒤 프로덕션에 적용하자. 실제로 여러 차례 업그레이드/다운그레이드를 반복한 경험이 있다. 롤백 계획은 항상 준비해두어야 한다.\n도입 체크리스트 배포 전\n유스케이스와 요구사항 정의 데이터 볼륨 및 증가량 추정 테이블 모델 선택 파티션 전략 설계 배포 후\nRoutine Load 작업 생성 및 검증 사용자 권한 설정 데이터 보관 정책(TTL) 설정 Scale-in/out 절차 문서화 모니터링 대시보드 구성 마치며 StarRocks 도입에서 얻은 핵심 교훈을 정리하면 다음과 같다.\nAggregate Key 모델이 핵심이다 — 수집 시점 자동 집계로 스토리지와 쿼리 성능을 동시에 잡을 수 있다 BITMAP_UNION으로 정확한 유니크 카운트를 확보하자 — 비즈니스 KPI에는 근사치가 아닌 정확한 수치가 필요하다 Routine Load + Aggregate Key 조합이 Flink를 대체한다 — SQL만으로 실시간 집계 파이프라인을 구축할 수 있다 운영 자동화에 투자하자 — Materialized View와 Routine Load 모니터링은 필수다 실시간 분석 워크로드에서 StarRocks는 파이프라인 복잡도를 획기적으로 줄여주는 강력한 선택지다. 다만 버전 업그레이드와 운영 안정성 측면에서는 아직 성숙해지는 과정에 있으므로, 충분한 PoC와 스테이징 검증을 거쳐 도입하길 권장한다.\n참고 자료: StarRocks 공식 문서\n","permalink":"https://NhoSW.github.io/my-tech-blog/ko/posts/starrocks-adoption-guide/","summary":"기존 Trino + Airflow 파이프라인의 5분 지연을 서브초 레이턴시로 개선한 StarRocks 도입 과정을 정리했습니다. 테이블 모델 선택, 데이터 수집, 성능 튜닝, 운영 노하우까지 실무에서 얻은 교훈을 공유합니다.","title":"StarRocks 도입기: 실시간 OLAP으로 데이터 파이프라인을 혁신한 이야기"},{"content":"왜 압축 설정이 중요한가 StarRocks를 운영하다 보면 데이터가 수십 TB 규모로 늘어나는 시점이 반드시 온다. 이때 압축 설정 하나로 스토리지 비용이 30~50% 차이 나는 경우를 여러 번 경험했다. 단순히 저장 공간만의 문제가 아니다. 압축률이 높으면 디스크 I/O가 줄어들어 스캔 성능이 좋아지고, 반대로 압축/해제에 CPU를 많이 쓰면 지연 시간이 늘어난다. 결국 워크로드 특성에 맞는 압축 알고리즘을 선택하는 것이 StarRocks 운영의 핵심 튜닝 포인트 중 하나다.\n지원되는 압축 알고리즘 비교 StarRocks는 여러 압축 알고리즘을 지원한다. 실무에서 주로 사용하는 세 가지를 비교해 보겠다.\n알고리즘 압축률 압축 속도 해제 속도 적합한 워크로드 LZ4 보통 (2~3x) 매우 빠름 매우 빠름 실시간 분석, 저지연 쿼리 ZSTD 높음 (4~6x) 보통 빠름 배치 분석, 콜드 데이터 Snappy 낮음 (1.5~2x) 빠름 빠름 범용, 레거시 호환 ZLIB 높음 (4~5x) 느림 보통 아카이빙, 저빈도 접근 데이터 개인적으로 가장 많이 쓰는 조합은 핫 데이터에 LZ4, 콜드 데이터에 ZSTD다. Snappy는 Hadoop 에코시스템에서 넘어온 데이터를 다룰 때 간혹 사용하지만, 신규 테이블에는 권장하지 않는다.\n테이블 생성 시 압축 설정 방법 테이블을 생성할 때 PROPERTIES에서 compression 속성을 지정하면 된다. 별도로 설정하지 않으면 StarRocks 기본값인 LZ4가 적용된다.\n실시간 분석용 테이블 (LZ4) CREATE TABLE analytics.realtime_events ( event_id BIGINT, user_id BIGINT, event_type VARCHAR(64), event_time DATETIME, properties JSON ) ENGINE = OLAP DUPLICATE KEY(event_id) DISTRIBUTED BY HASH(user_id) BUCKETS 32 PROPERTIES ( \u0026#34;replication_num\u0026#34; = \u0026#34;3\u0026#34;, \u0026#34;compression\u0026#34; = \u0026#34;LZ4\u0026#34; ); LZ4는 해제 속도가 압도적으로 빠르기 때문에, 대시보드 쿼리처럼 수백 밀리초 이내 응답이 필요한 테이블에 적합하다.\n배치 분석용 테이블 (ZSTD) CREATE TABLE warehouse.order_history ( order_id BIGINT, customer_id BIGINT, order_date DATE, total_amount DECIMAL(18, 2), status VARCHAR(32), items ARRAY\u0026lt;STRUCT\u0026lt;sku STRING, qty INT, price DECIMAL(10,2)\u0026gt;\u0026gt; ) ENGINE = OLAP DUPLICATE KEY(order_id) PARTITION BY RANGE(order_date) ( PARTITION p2025 VALUES LESS THAN (\u0026#39;2026-01-01\u0026#39;), PARTITION p2026 VALUES LESS THAN (\u0026#39;2027-01-01\u0026#39;) ) DISTRIBUTED BY HASH(customer_id) BUCKETS 16 PROPERTIES ( \u0026#34;replication_num\u0026#34; = \u0026#34;2\u0026#34;, \u0026#34;compression\u0026#34; = \u0026#34;ZSTD\u0026#34; ); ZSTD는 압축률이 LZ4 대비 1.5~2배 높아서, 파티션 단위로 수억 건 이상 적재되는 히스토리 테이블에서 스토리지 절감 효과가 크다.\n기존 테이블 압축 변경 이미 운영 중인 테이블의 압축 알고리즘을 변경하고 싶다면 ALTER TABLE을 사용할 수 있다. 단, 변경 이후 새로 적재되는 데이터부터 적용되며 기존 세그먼트는 Compaction이 수행되어야 반영된다는 점에 유의하자.\nALTER TABLE warehouse.order_history SET (\u0026#34;compression\u0026#34; = \u0026#34;ZSTD\u0026#34;); 워크로드별 권장 압축 설정 실무에서 반복적으로 검증한 결과를 기반으로 정리하면 다음과 같다.\n실시간 대시보드 / Ad-hoc 쿼리: LZ4를 권장한다. CPU 오버헤드가 거의 없어 P99 지연 시간에 미치는 영향이 최소화된다. 야간 배치 리포트 / ETL 결과 테이블: ZSTD를 권장한다. 쿼리 빈도가 낮고 데이터 양이 많은 경우 스토리지 절감 효과가 비용에 직접 반영된다. 로그성 대용량 적재: ZSTD를 사용하되 zstd_compression_level을 3 이하로 낮추면 압축 속도와 압축률 사이의 균형을 잡을 수 있다. 압축률과 성능 트레이드오프 실측 결과 약 50억 건(원본 약 800GB)의 이벤트 로그 테이블을 대상으로 압축 알고리즘별 벤치마크를 수행한 결과다.\n지표 LZ4 ZSTD (level 3) ZSTD (level 9) 압축 후 크기 320 GB 195 GB 170 GB 압축률 2.5x 4.1x 4.7x 단순 스캔 쿼리 (Avg) 1.2초 1.5초 1.8초 집계 쿼리 (Avg) 3.4초 3.8초 4.5초 데이터 적재 속도 120 MB/s 95 MB/s 60 MB/s LZ4 대비 ZSTD level 3은 스토리지를 약 39% 절감하면서도 쿼리 지연은 약 10~15%만 증가했다. 반면 ZSTD level 9는 추가 압축 이득 대비 적재 속도 저하가 커서 대부분의 환경에서는 level 3이 최적의 선택이었다.\n운영 팁과 모니터링 마지막으로 실무에서 압축 관련 운영 시 놓치기 쉬운 포인트를 정리한다.\nCompaction 모니터링을 반드시 하자. 압축 알고리즘을 변경한 뒤 Compaction이 완료되기 전까지 혼합 세그먼트가 존재하면 쿼리 성능이 일시적으로 불안정해질 수 있다. BE의 compaction_score 메트릭을 모니터링하여 Compaction 적체 여부를 확인해야 한다.\n테이블 단위로 압축 전략을 분리하라. 하나의 클러스터에서 모든 테이블에 동일한 압축을 적용하는 것은 비효율적이다. 접근 빈도, 데이터 크기, SLA에 따라 테이블별로 다르게 설정하는 것이 올바른 접근이다.\n디스크 사용량 추이를 추적하라. 압축 변경 후 SHOW DATA 명령으로 테이블별 실제 디스크 사용량을 주기적으로 확인하고, 기대한 압축률이 나오지 않는다면 데이터 특성(카디널리티, NULL 비율 등)을 재점검해야 한다.\nSHOW DATA FROM warehouse.order_history; 압축 설정은 한 번 정하고 끝나는 것이 아니라, 데이터 특성과 워크로드가 변함에 따라 지속적으로 재검토해야 하는 영역이다. 이 글이 StarRocks 운영에서 압축 전략을 수립하는 데 실질적인 참고가 되길 바란다.\n","permalink":"https://NhoSW.github.io/my-tech-blog/ko/posts/starracks-compression-guide/","summary":"StarRocks에서 압축 설정을 최적화하여 스토리지 비용을 절감하고 쿼리 성능을 향상시키는 방법을 실무 경험을 바탕으로 정리했습니다.","title":"StarRocks 압축 설정 가이드: 성능과 스토리지 최적화"},{"content":"안녕하세요, 노승우입니다 저는 안정적이고 확장 가능한 데이터 인프라와 파이프라인을 구축하는 데이터 엔지니어입니다. 대규모 데이터의 수집, 변환, 서빙 과정에서 발생하는 다양한 문제를 해결하는 일에 보람을 느끼고 있습니다.\n블로그 소개 이 블로그는 실무에서 얻은 데이터 엔지니어링 지식을 공유하는 공간입니다. 실제 프로젝트에서 배운 교훈, 튜토리얼, 아키텍처 관련 의사결정, 그리고 데이터 분야에서 일하는 엔지니어분들께 도움이 될 만한 팁들을 다루고 있습니다.\n기술 스택 현재 주로 사용하고 있는 기술들입니다:\n스트림 처리: Apache Kafka 워크플로 오케스트레이션: Apache Airflow 쿼리 엔진: Trino, StarRocks 컨테이너 오케스트레이션: Kubernetes 언어: Python, SQL 인프라: Docker 연락처 GitHub: github.com/your-username LinkedIn: linkedin.com/in/your-profile 이메일: your-email@example.com 궁금한 점이나 제안 사항이 있으시면 편하게 연락 주세요!\n","permalink":"https://NhoSW.github.io/my-tech-blog/ko/about/","summary":"블로그 소개","title":"소개"}]