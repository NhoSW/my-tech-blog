<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Iceberg on nanta - Data Engineering</title><link>https://nanta-data.dev/en/tags/iceberg/</link><description>Recent content in Iceberg on nanta - Data Engineering</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© 2026 nanta</copyright><lastBuildDate>Fri, 27 Feb 2026 00:00:00 +0000</lastBuildDate><atom:link href="https://nanta-data.dev/en/tags/iceberg/index.xml" rel="self" type="application/rss+xml"/><item><title>Building Iceberg Table Monitoring with Trino Meta-Tables and Prometheus Pushgateway</title><link>https://nanta-data.dev/en/posts/iceberg-table-monitoring/</link><pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/en/posts/iceberg-table-monitoring/</guid><description>As our Iceberg table count grew, we needed systematic monitoring for file health. We built dashboards using Trino meta-tables, Prometheus Pushgateway, and Grafana to track file counts, sizes, and partition distribution. Along the way we hit Trino bugs and performance issues worth documenting.</description></item><item><title>S3 Table Buckets PoC: Evaluating Managed Iceberg for CDC Workloads</title><link>https://nanta-data.dev/en/posts/s3-table-buckets-poc/</link><pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/en/posts/s3-table-buckets-poc/</guid><description>AWS S3 Table Buckets offer managed Iceberg tables with automatic compaction. We ran a PoC to see if they could solve our CDC table compaction problem. We validated Trino, Spark, and Kafka Connect integration, examined auto-compaction behavior, and assessed costs. The conclusion: not a fit for every table, but valuable specifically for CDC workloads with unpredictable partition-level updates.</description></item><item><title>Trino v451 to v476: Upgrading a Production Cluster Across 25 Versions</title><link>https://nanta-data.dev/en/posts/trino-v476-upgrade/</link><pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/en/posts/trino-v476-upgrade/</guid><description>We upgraded Trino from v451 to v476 — 25 minor versions in one jump. Blue/Green deployment on our OLAP clusters caught two regressions: a Materialized View refresh bug and a Parquet read failure. We binary-searched the root cause down to a single v469 commit and got a community fix within a day.</description></item><item><title>Building an ALB Log Pipeline with Filebeat, Flink, and Iceberg</title><link>https://nanta-data.dev/en/posts/alb-log-collection-system/</link><pubDate>Wed, 25 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/en/posts/alb-log-collection-system/</guid><description>We needed to turn CSV ALB logs sitting in S3 into a queryable Iceberg table. The first attempt with Flink&amp;rsquo;s filesystem connector ran out of memory. This post covers the redesign with Filebeat + SQS + Kafka, autoscaling, checkpoint tuning, and the operational surprises we hit along the way.</description></item><item><title>Iceberg - Why CDC Table Compaction Is So Tricky</title><link>https://nanta-data.dev/en/posts/iceberg-cdc-compaction-challenge/</link><pubDate>Tue, 24 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/en/posts/iceberg-cdc-compaction-challenge/</guid><description>Iceberg v2&amp;rsquo;s row-level delete implementation, the difference between position and equality deletes, and why compaction commits keep failing when a real-time CDC sink is running. Covers how v3 Deletion Vectors change the picture and the workaround we settled on for v2 in production.</description></item><item><title>2026 Data Engineering Trends and Where Large-Scale Platforms Stand</title><link>https://nanta-data.dev/en/posts/2026-data-engineering-trends/</link><pubDate>Mon, 23 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/en/posts/2026-data-engineering-trends/</guid><description>Analyzing 2026 data engineering trends from Joe Reis&amp;rsquo;s 1,101-respondent survey, contrasted with our team&amp;rsquo;s current architecture at a large-scale platform. An honest look at what we&amp;rsquo;re doing well and what we need to work on.</description></item><item><title>Starburst's AI Pivot: Is Trino Open Source Going to Be Okay?</title><link>https://nanta-data.dev/en/posts/starburst-trino-ai-pivot/</link><pubDate>Mon, 23 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/en/posts/starburst-trino-ai-pivot/</guid><description>Trino open-source releases dropped 63% as Starburst pivoted from a query engine company to an AI platform. From the perspective of a team running Trino in production, here&amp;rsquo;s what this shift means and what to do about it.</description></item></channel></rss>