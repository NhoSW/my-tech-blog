<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Data Engineering on nanta - 데이터 엔지니어링</title><link>https://nanta-data.dev/categories/data-engineering/</link><description>Recent content in Data Engineering on nanta - 데이터 엔지니어링</description><generator>Hugo -- gohugo.io</generator><language>ko</language><copyright>© 2026 nanta</copyright><lastBuildDate>Fri, 27 Feb 2026 00:00:00 +0000</lastBuildDate><atom:link href="https://nanta-data.dev/categories/data-engineering/index.xml" rel="self" type="application/rss+xml"/><item><title>BigQuery Data Transfer와 Airflow 통합: 매 배치마다 트랜스퍼를 생성하고 삭제하는 이유</title><link>https://nanta-data.dev/posts/bigquery-data-transfer-airflow/</link><pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/bigquery-data-transfer-airflow/</guid><description>S3 마트 테이블을 BigQuery로 인입하는 파이프라인을 구축했다. PoC에서는 BigQuery Data Transfer 스케줄링을 GCP 쪽에 맡겼지만, 운영으로 가면서 Airflow에 통합했다. 매 배치 틱마다 트랜스퍼 객체를 생성하고 데이터 로드 완료 후 삭제하는 구조다. 사용자 피드백으로 멀티데이 lookback, 동시 실행 쿼터 제한, 빈 소스 경로 감지까지 개선한 과정을 정리한다.</description></item><item><title>EKS Topology Aware Hint 적용 검토: 우리 클러스터에서는 의미 없었던 이유</title><link>https://nanta-data.dev/posts/eks-topology-aware-hints/</link><pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/eks-topology-aware-hints/</guid><description>EKS cross-AZ 통신 비용 절감을 위해 Topology Aware Hint 적용을 검토했다. EndpointSlice에 힌트는 정상적으로 붙었지만, 실제 효과는 없었다. AWS Load Balancer Controller의 IP 타깃 모드가 kube-proxy를 우회하고, 주요 내부 워크로드(Spark, Trino, Airflow)가 모두 싱글 존 또는 stateful 통신이라 힌트가 참조되는 경로 자체가 존재하지 않았다.</description></item><item><title>EMR on EKS VPA 검토기: AWS 공식 기능이 동작하지 않을 때</title><link>https://nanta-data.dev/posts/emr-on-eks-vpa-review/</link><pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/emr-on-eks-vpa-review/</guid><description>EMR on EKS 환경에서 Spark executor 리소스를 자동 최적화하려고 AWS 제공 VPA를 검토했다. 약 한 달간 PoC를 진행했지만 오퍼레이터 자체가 정상 동작하지 않았다. AWS 서포트 케이스를 여러 차례 열었고 매니페스트 번들까지 받아서 커스터마이징했지만 결국 포기했다.</description></item><item><title>Iceberg 테이블 모니터링 구축: Trino 메타테이블과 Prometheus Pushgateway</title><link>https://nanta-data.dev/posts/iceberg-table-monitoring/</link><pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/iceberg-table-monitoring/</guid><description>Iceberg 테이블 수가 늘어나면서 파일 상태를 체계적으로 모니터링할 필요가 생겼다. Trino 메타테이블을 활용해 파일 수, 크기, 파티션 분포를 추적하고 Prometheus Pushgateway와 Grafana로 대시보드를 구성했다. 과정에서 만난 Trino 버그와 성능 이슈도 정리했다.</description></item><item><title>Kafka Rack Awareness와 Spark: 현재 지원하지 않는다</title><link>https://nanta-data.dev/posts/kafka-rack-awareness-spark/</link><pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/kafka-rack-awareness-spark/</guid><description>Kafka 클러스터의 rack awareness를 Spark에도 적용해서 cross-AZ 네트워크 비용을 줄이려 했다. AZ 정보 추출까지는 해결했지만, Spark 자체가 Kafka 연동 시 rack awareness를 지원하지 않았다. 관련 티켓은 커뮤니티에 열려 있지만 PR은 닫힌 상태다.</description></item><item><title>S3 테이블 버킷 도입 검토: 매니지드 Iceberg의 가능성과 한계</title><link>https://nanta-data.dev/posts/s3-table-buckets-poc/</link><pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/s3-table-buckets-poc/</guid><description>AWS S3 테이블 버킷은 자동 컴팩션을 제공하는 매니지드 Iceberg다. CDC 싱크 테이블의 컴팩션 문제를 해결할 수 있을지 PoC를 진행했다. Trino, Spark, Kafka Connect 연동을 확인하고, 자동 컴팩션의 동작 특성과 비용을 검토했다. 결론은 모든 테이블에 쓸 서비스는 아니고, CDC 테이블에 한해서 가치가 있다는 것이다.</description></item><item><title>Superset 사용자 제보 이슈 6건 대응기</title><link>https://nanta-data.dev/posts/superset-user-reported-issues/</link><pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/superset-user-reported-issues/</guid><description>데이터 거버넌스팀에서 Superset 사용 중 발견한 이슈 6건을 대응했다. Slack 스크린샷 확장자 누락부터 CSV 다운로드 500 에러까지 난이도가 다양했다. 가장 까다로웠던 건 50만 행 이상 CSV 다운로드 시 PostgreSQL idle_in_transaction_session_timeout이 메타데이터 DB 커넥션을 끊어버리는 문제였다. 에러가 발생하는 커넥션과 원인이 되는 커넥션이 달라서, Redshift만 보고 있었으면 절대 못 찾았을 이슈다.</description></item><item><title>Superset에서 BigQuery가 무한 블로킹되는 이유: gevent와 gRPC의 호환성 문제</title><link>https://nanta-data.dev/posts/bigquery-bi-integration/</link><pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/bigquery-bi-integration/</guid><description>사용자 권한별로 BigQuery를 BI에서 사용할 수 있도록 Redash와 Superset에 연동했다. Redash는 스키마 조회 불가라는 알려진 한계가 있었고, Superset은 더 심각한 문제를 만났다. SqlLab에서는 정상인데 차트 화면에서 쿼리가 무한 블로킹됐다. 원인은 gunicorn의 gevent 워커가 Python 코어 라이브러리를 멍키패칭하면서 BigQuery SDK의 gRPC 호출을 교착시키는 문제였다. 워커 타입을 gthread로 교체해서 해결했고, 업스트림에 문서 픽스 PR을 기여했다.</description></item><item><title>Trino Alluxio 캐시 PoC: EBS 스루풋이 병목이었다</title><link>https://nanta-data.dev/posts/trino-alluxio-cache-poc/</link><pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/trino-alluxio-cache-poc/</guid><description>Trino의 Alluxio 기반 파일 시스템 캐시를 프로덕션 OLAP 환경에서 PoC했다. 캐시를 붙이기만 하면 빨라질 줄 알았는데 EBS 기본 스루풋 125MiB/s가 병목이었다. 스루풋 상향 후 쿼리 성능이 눈에 띄게 개선됐고 S3 API 비용도 월 440만 원 줄었다.</description></item><item><title>Trino Gateway 도입기: 제로 다운타임 배포와 멀티 클러스터 라우팅</title><link>https://nanta-data.dev/posts/trino-gateway-zero-downtime/</link><pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/trino-gateway-zero-downtime/</guid><description>Trino는 코디네이터 HA를 지원하지 않는다. 코디네이터를 재배포하면 다운타임이 생긴다. Trino Gateway를 도입해서 Blue/Green 배포로 제로 다운타임을 달성하고 BI/OLAP 클러스터를 헤더 기반으로 라우팅한 과정을 정리했다.</description></item><item><title>Trino v451에서 v476으로: 25개 버전을 건너뛴 운영 클러스터 업그레이드</title><link>https://nanta-data.dev/posts/trino-v476-upgrade/</link><pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/trino-v476-upgrade/</guid><description>Trino를 v451에서 v476으로 업그레이드했다. Blue/Green 배포로 OLAP 클러스터부터 점진 적용하는 과정에서 Materialized View 리그레션과 Parquet 읽기 리그레션을 발견했다. 바이너리 서치로 원인 버전을 v469로 좁히고, 커밋 단위 리버트로 원인 PR을 특정해서 커뮤니티에 이슈를 올렸더니 하루 만에 픽스가 나왔다.</description></item><item><title>ALB 로그를 Iceberg 테이블로 만들기까지</title><link>https://nanta-data.dev/posts/alb-log-collection-system/</link><pubDate>Wed, 25 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/alb-log-collection-system/</guid><description>S3에 CSV로 쌓이는 ALB 로그를 Iceberg 테이블로 바꾸는 시스템을 구축했다. Flink filesystem connector의 메모리 한계를 겪고 filebeat + SQS + Kafka 구조로 재설계한 과정, 오토스케일링 적용, 체크포인트 튜닝, 그리고 운영 중 마주친 여러 삽질을 정리했다.</description></item><item><title>Apache APISIX로 프록시 서버 구축하기. 일 13억 건 로그 비식별화 처리</title><link>https://nanta-data.dev/posts/apisix-proxy-server-guide/</link><pubDate>Tue, 24 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/apisix-proxy-server-guide/</guid><description>해외 트래킹 서버로 앱 로그를 전송할 때 개인정보를 비식별화해야 했다. Fluent-bit에서 시작해 Kong을 거쳐 APISIX에 정착한 과정, 커스텀 Lua 플러그인 개발, 5.5만 TPS 부하 테스트, Kubernetes 배포까지 실전 경험을 정리했다.</description></item><item><title>Iceberg - 왜 CDC 테이블의 컴팩션이 까다로운가</title><link>https://nanta-data.dev/posts/iceberg-cdc-compaction-challenge/</link><pubDate>Tue, 24 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/iceberg-cdc-compaction-challenge/</guid><description>Iceberg v2의 row-level delete 구현, position delete와 equality delete의 차이, 실시간 CDC 싱크와 컴팩션 간 커밋 충돌 원인을 코드 레벨에서 분석했다. v3 Deletion Vector가 이 문제를 어떻게 바꾸는지, 그리고 v2 환경에서의 운영 우회책까지 함께 정리한다.</description></item><item><title>2026 데이터 엔지니어링 트렌드와 대규모 플랫폼의 현주소</title><link>https://nanta-data.dev/posts/2026-data-engineering-trends/</link><pubDate>Mon, 23 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/2026-data-engineering-trends/</guid><description>Joe Reis의 1,101명 서베이를 기반으로 한 2026년 데이터 엔지니어링 트렌드를 대규모 플랫폼 데이터 엔지니어링 팀의 현재 아키텍처와 대조하며 정리했습니다. 이미 잘 하고 있는 것과 앞으로 해야 할 것을 솔직하게 돌아봅니다.</description></item><item><title>Airflow 3.0 마이그레이션 가이드: 대규모 DAG 환경에서의 실전 경험</title><link>https://nanta-data.dev/posts/airflow-3-migration-guide/</link><pubDate>Mon, 23 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/airflow-3-migration-guide/</guid><description>Airflow 2.x EOL을 앞두고 3.x로 마이그레이션한 실전 경험을 공유한다. Breaking Changes, 단계적 업그레이드 전략, DAG 호환성 확보 방법, 수백 개 DAG을 운영하는 환경에서 배운 교훈을 정리했다.</description></item><item><title>NVIDIA MIG 설정 가이드. A100 GPU 하나를 여러 개로 쪼개 쓰기</title><link>https://nanta-data.dev/posts/nvidia-mig-setup-guide/</link><pubDate>Mon, 23 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/nvidia-mig-setup-guide/</guid><description>A100 GPU 4장으로 최대 28개의 독립 GPU 인스턴스를 만들 수 있다. MIG 개념부터 mig-parted 설치, 슬라이스 구성, Kubernetes 연동까지 실전 경험을 정리했다.</description></item><item><title>Starburst의 AI 피벗: Trino 오픈소스는 괜찮을까?</title><link>https://nanta-data.dev/posts/starburst-trino-ai-pivot/</link><pubDate>Mon, 23 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/starburst-trino-ai-pivot/</guid><description>Starburst가 쿼리 엔진 회사에서 AI 플랫폼 기업으로 전환하면서 Trino 오픈소스 릴리스가 63% 감소했다. Trino를 프로덕션에서 운영하는 팀의 관점에서, 이 변화가 의미하는 것과 앞으로의 전략을 정리한다.</description></item><item><title>StarRocks 도입기: 실시간 OLAP으로 데이터 파이프라인을 뜯어고친 이야기</title><link>https://nanta-data.dev/posts/starrocks-adoption-guide/</link><pubDate>Mon, 23 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/starrocks-adoption-guide/</guid><description>기존 Trino + Airflow 파이프라인의 5분 지연을 서브초 레이턴시로 개선한 StarRocks 도입 과정을 정리했습니다. 테이블 모델 선택, 데이터 수집, 성능 튜닝, 운영 노하우까지 실무에서 얻은 교훈을 공유합니다.</description></item><item><title>StarRocks 압축 설정 가이드: 성능과 스토리지 최적화</title><link>https://nanta-data.dev/posts/starrocks-compression-guide/</link><pubDate>Mon, 23 Feb 2026 00:00:00 +0000</pubDate><guid>https://nanta-data.dev/posts/starrocks-compression-guide/</guid><description>StarRocks에서 압축 설정을 최적화해 스토리지 비용을 절감하고 쿼리 성능을 올리는 방법을 실무 경험 바탕으로 정리했다.</description></item></channel></rss>