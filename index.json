[{"content":"Joe Reis가 1,101명의 데이터 실무자를 대상으로 진행한 서베이 결과를 기반으로 2026년 데이터 엔지니어링 트렌드를 발표했다. 대규모 플랫폼의 데이터 엔지니어링 팀을 이끌고 있는 입장에서, 이 트렌드를 우리 팀의 현재 아키텍처와 대조하며 이미 잘 하고 있는 것과 앞으로 해야 할 것을 정리해본다.\n우리 아키텍처 한 줄 요약 # S3를 중심 데이터 레이크로 두고, Apache Iceberg 테이블 포맷 위에 Trino(배치/애드혹 분석)와 StarRocks(실시간 OLAP)를 얹은 하이브리드 구조다. 데이터 수집은 Kafka + Debezium CDC와 Flink 스트리밍, 오케스트레이션은 Airflow를 깊이 커스터마이징하여 운영하고 있다.\n[Services] → Kafka + Debezium CDC → Flink → S3 (Iceberg) ↓ ┌─────┴─────┐ │ │ Trino StarRocks (배치/애드혹) (실시간 OLAP) │ │ └─────┬─────┘ ↓ Dashboard 1. AI 활용 — 이미 하고 있는 것과 넘어야 할 벽 # 트렌드 요약 # 서베이 응답자의 82%가 AI를 매일 사용하고 있지만, 64%는 아직 실험 단계나 단순 작업에만 활용하고 있다. Joe Reis는 2026년 말이면 \u0026ldquo;AI-assisted\u0026quot;라는 수식어가 직무 기술에서 사라질 것이라 예측한다.\n우리가 하고 있는 것 # AI 코딩 도구를 활용한 파이프라인 개발은 이미 일상이 되었다. SQL 최적화, 코드 리뷰, 트러블슈팅 과정에서 LLM을 적극적으로 활용하고 있으며, 데이터 카탈로그와 연계한 자연어 기반 데이터 탐색도 시도하고 있다.\n해야 할 것 # 개인 단위의 AI 활용을 넘어서 팀 전체의 워크플로우에 AI를 임베드하는 것이 과제다.\n데이터 파이프라인 이상 감지 자동 스키마 진화 대응 데이터 품질 룰 자동 생성 Joe Reis가 말한 \u0026ldquo;10%의 AI-mature 팀\u0026quot;에 속하려면, AI를 단순 보조 도구가 아닌 플랫폼의 핵심 컴포넌트로 통합하는 전략이 필요하다.\n2. 데이터 모델링 위기와 시맨틱 레이어 — 가장 큰 숙제 # 트렌드 요약 # 응답자의 89%가 데이터 모델링에서 고통을 호소하고 있고, 시맨틱 모델을 사용하는 팀은 고작 5%다. Joe Reis는 시맨틱 레이어가 먼저 주류가 되고, 이후 LLM이 스키마를 즉석에서 해석하는 방향으로 진화할 것이라 본다.\n우리가 하고 있는 것 # 데이터 카탈로그를 통해 리니지와 메타데이터를 관리하고 있고, 테이블 레이어 체계(L1/L2/L3)를 정의하여 데이터 품질을 계층적으로 관리하려는 시도를 진행 중이다. Airflow 커스텀 오퍼레이터를 통한 데이터 검증 자동화도 운영하고 있다.\n해야 할 것 # dbt 도입을 검토했으나 차세대 데이터 플랫폼 전환 전략과 맞물려 중단된 상태다. 현재 파이프라인을 dbt로 이관하기보다는 새로운 플랫폼으로 직접 이관하는 방향을 검토하고 있지만, 그 사이 데이터 변환의 표준화와 모듈화가 공백으로 남아있다. 이것이 Joe Reis가 말한 \u0026ldquo;89%의 고통\u0026quot;과 정확히 일치하는 부분이다.\n시맨틱 레이어 역시 미답 영역이다. 비즈니스 메트릭의 정의가 팀마다 다르고, 동일한 지표에 대해 서로 다른 SQL을 사용하는 문제가 존재한다. 서베이에서 시맨틱 모델 교육 수요가 19%로 높게 나온 것처럼, 조직 전체의 데이터 리터러시를 끌어올리는 작업이 시급하다.\n특히 AI 에이전트가 데이터를 자율적으로 활용하는 미래를 대비하면, 잘 정의된 시맨틱 레이어는 선택이 아닌 필수다. 플랫폼 전환이 지연되더라도 모델링 표준과 시맨틱 정의는 독립적으로 진행할 수 있고, 진행해야 한다.\n3. 오케스트레이션 통합 — Airflow의 미래 # 트렌드 요약 # Airflow가 여전히 지배적이지만, Dagster가 소규모 기업에서 12%의 점유율을 보이며 바텀업으로 성장하고 있다. 오케스트레이션이 아예 없는 팀이 모든 기업 규모에서 20%라는 점도 놀랍다.\n우리가 하고 있는 것 # Airflow를 깊이 커스터마이징하여 운영하고 있다. 자체 Provider 패키지를 개발하고, 데이터 검증 자동화 오퍼레이터, 커스텀 전송 오퍼레이터 등 플랫폼에 특화된 기능을 구현했다. 현재 Airflow 3.x 메이저 버전 업그레이드를 진행 중이며, Python 버전 업그레이드와 Breaking Change 대응을 체계적으로 계획하고 있다.\n해야 할 것 # Airflow에 대한 깊은 투자는 강점이지만, 동시에 기술 부채이기도 하다.\n커스텀 Provider의 유지보수 부담 버전 업그레이드 시 호환성 이슈 AI 에이전트 오케스트레이션이라는 새로운 패러다임에 대한 대비 Joe Reis가 예측한 것처럼 오케스트레이션이 플랫폼에 흡수되는 방향도 지켜봐야 한다. 차세대 데이터 플랫폼과의 정합성을 고려하면, 오케스트레이션 전략의 중장기적 로드맵 수립이 시급하다.\n4. Lakehouse vs. Warehouse — 이미 답을 낸 영역 # 트렌드 요약 # 서베이에서 44%가 Warehouse, 27%가 Lakehouse, 12%가 Hybrid를 사용하고 있다. Snowflake과 Databricks의 기능이 수렴하면서 이 논쟁 자체가 무의미해지고 있다. Joe Reis는 2026년 말이면 \u0026ldquo;warehouse vs. lakehouse\u0026rdquo; 논쟁이 구식으로 느껴질 것이라 예측한다.\n우리가 하고 있는 것 # 이 트렌드에서 우리 팀은 이미 정답에 가까운 위치에 있다. S3 위에 Iceberg 오픈 테이블 포맷을 표준으로 채택하고, 용도에 따라 Trino와 StarRocks를 선택적으로 사용하는 구조는 Warehouse도 Lakehouse도 아닌, 양쪽의 장점을 취한 아키텍처다. CDC 파이프라인을 통해 실시간 데이터를 Iceberg 테이블로 적재하고, 배치와 실시간 분석을 동일한 데이터 위에서 수행할 수 있다.\n해야 할 것 # Iceberg v3의 Deletion Vector, Row Lineage 등 새로운 기능을 적극 활용하기 위해서는 쿼리 엔진 전반의 호환성 확보가 필요하다. 현재 Trino와 StarRocks의 Iceberg v3 지원이 제한적이므로, 엔진 업그레이드 로드맵과 Iceberg 버전 전략을 연계해야 한다. 또한 오픈 테이블 포맷 기반 아키텍처의 거버넌스 체계 — 카탈로그 통합, 접근 제어, 데이터 품질 보장 — 를 더 강화해야 한다.\n5. 리더십이 병목이 되는 문제 — 가장 어렵고 가장 중요한 과제 # 트렌드 요약 # 데이터 엔지니어의 22%가 \u0026ldquo;리더십 방향 부재\u0026quot;를 주요 이슈로 꼽았고, 이는 레거시 기술 부채(26%)에 버금가는 수치다. Joe Reis는 2026년에 더 많은 데이터 팀이 해체되거나 엔지니어링 조직에 합병될 것이라 경고한다.\n우리가 하고 있는 것 # 데이터 플랫폼 팀이 독립적인 조직으로 존재하며, 인프라부터 수집, 변환, 분석 환경까지 End-to-End로 책임지는 구조를 갖추고 있다. 비즈니스 팀과의 직접적인 소통 채널을 유지하며, 데이터 요건을 직접 수렴하고 있다.\n해야 할 것 # 기술적 역량만으로는 팀의 존재 가치를 증명할 수 없다. Joe Reis가 강조한 것처럼 \u0026ldquo;비즈니스 가치를 증명한 팀만 살아남는다.\u0026rdquo;\n데이터 플랫폼의 ROI를 정량적으로 측정하고 커뮤니케이션하는 체계 AI 시대에 데이터 플랫폼이 어떤 역할을 해야 하는지에 대한 비전 수립 데이터 옵저버빌리티 도입을 통한 데이터 다운타임 감소 파이프라인 개발 생산성 지표화 등 구체적인 비즈니스 임팩트 제시 정리: 잘 하고 있는 것 vs. 해야 할 것 # 영역 잘 하고 있는 것 해야 할 것 AI 활용 개인 단위 AI 코딩 도구 적극 활용 팀 워크플로우에 AI 임베드, 운영 자동화 데이터 모델링 카탈로그 기반 메타데이터 관리, 레이어 체계 정의 시맨틱 레이어 도입, 데이터 변환 표준화 오케스트레이션 Airflow 깊은 커스터마이징, 3.x 업그레이드 진행 장기 오케스트레이션 전략, AI 에이전트 대응 Lakehouse/Warehouse Iceberg 기반 하이브리드 아키텍처 구축 완료 Iceberg v3 호환성, 거버넌스 체계 강화 리더십 End-to-End 플랫폼 팀 운영 비즈니스 임팩트 정량화, 데이터 옵저버빌리티 마치며 # Joe Reis의 서베이에서 가장 인상적이었던 문장은 이것이다.\n\u0026ldquo;2026년 데이터 엔지니어링은 올바른 도구를 고르는 것보다 그 도구를 잘 활용할 조직적 근육을 키우는 것이 더 중요하다.\u0026rdquo;\n우리 팀은 기술 스택 면에서 트렌드의 앞쪽에 서 있다. Iceberg 기반 오픈 데이터 레이크, 실시간과 배치를 아우르는 하이브리드 아키텍처, 깊이 있는 Airflow 커스터마이징 등은 많은 조직이 아직 도달하지 못한 수준이다.\n하지만 기술적 우위만으로는 충분하지 않다. 데이터 변환 표준화, 시맨틱 레이어, 데이터 옵저버빌리티, AI 네이티브 워크플로우, 그리고 무엇보다 비즈니스 가치를 증명하는 리더십 — 이것이 2026년에 우리가 집중해야 할 방향이다.\n과거의 빚은 이자를 물고 있고, 페이데이가 다가오고 있다.\n원문 참고: Where Data Engineering Is Heading in 2026 — Joe Reis\n","date":"February 23, 2026","externalUrl":null,"permalink":"/my-tech-blog/ko/posts/2026-data-engineering-trends/","section":"글 목록","summary":"Joe Reis의 1,101명 서베이를 기반으로 한 2026년 데이터 엔지니어링 트렌드를, 대규모 플랫폼 데이터 엔지니어링 팀의 현재 아키텍처와 대조하며 정리했습니다. 이미 잘 하고 있는 것과 앞으로 해야 할 것을 솔직하게 돌아봅니다.","title":"2026 데이터 엔지니어링 트렌드와 대규모 플랫폼의 현주소","type":"posts"},{"content":"","date":"February 23, 2026","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/ai/","section":"Tags","summary":"","title":"Ai","type":"tags"},{"content":"","date":"February 23, 2026","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/airflow/","section":"Tags","summary":"","title":"Airflow","type":"tags"},{"content":"Airflow 2.x의 End of Life가 2026년 4월 22일로 다가오고 있다. 우리 팀은 수백 개의 DAG을 운영하는 프로덕션 환경에서 Airflow 3.x 마이그레이션을 진행했다. 이 글은 그 과정에서 마주친 Breaking Changes, 단계적 업그레이드 전략, 그리고 대규모 DAG 환경에서의 실전 교훈을 정리한 기록이다.\n왜 지금 마이그레이션해야 하는가 # Airflow 3.x의 핵심 개선사항 # Airflow 3.x는 단순한 메이저 버전 업데이트가 아니다. 아키텍처 수준에서 근본적인 변화가 일어났다.\nDAG 버전 관리: dag_id에 버전 서픽스를 붙이거나, 스케줄 변경 시 스케줄링이 꼬이는 문제에서 해방된다. 네이티브 백필: CLI나 커스텀 플러그인에 의존하던 백필이 웹 UI에서 직접 지원된다. 이벤트/애셋 기반 트리거: 단순 cron 표현식을 넘어 다양한 스케줄링 방식을 제공한다. React 기반 웹 UI: Flask App Builder 기반에서 React로 전면 개편되어 사용성이 크게 향상되었다. 아키텍처 변화: API Server의 등장 # 3.x에서 가장 큰 아키텍처 변화는 API Server가 메타 DB에 접근하는 유일한 관문이 되었다는 점이다.\nAirflow 2.x: Webserver ─── MetaDB Worker ────── MetaDB Scheduler ─── MetaDB DAG Code ──── MetaDB (직접 접근 가능) Airflow 3.x: API Server ── MetaDB (유일한 접근 경로) Webserver ─── API Server Worker ────── API Server Scheduler ─── API Server DAG Code ──── API Server (직접 접근 불가) 이 변화로 인해 DAG 최상위 코드에서 메타 DB에 직접 접근하던 모든 패턴이 깨진다. 이것이 마이그레이션에서 가장 큰 영향을 미치는 변경사항이다.\n단계적 업그레이드 전략 # 한 번에 최신 버전으로 올리는 것은 위험하다. 우리는 4단계 전략을 수립했다.\n1단계: 2.x 최신 버전(2.11)으로 업데이트 (선택) # 3.x로 직접 올리는 과정에서 이슈가 발생할 경우를 대비한 안전장치다. 2.11에서는 3.x에서 제거될 기능들에 대한 deprecation 경고가 표시되므로, 어떤 코드를 수정해야 하는지 사전에 파악할 수 있다.\n2단계: 3.0.x로 업데이트 # Python 3.9 환경에서는 최신 3.1.x가 아닌 3.0.x까지만 지원된다. Python 버전 업그레이드 전에 Airflow 메이저 버전을 먼저 올린다.\n3단계: Python 버전 업그레이드 (3.9 → 3.12+) # Airflow 3.1.x는 Python 3.9를 지원하지 않는다. Python 3.12 이상을 목표로 하되, 의존성 호환 이슈가 있으면 3.10이나 3.11로 타협한다.\n4단계: 3.1.x로 업데이트 # 최종적으로 최신 stable 릴리스로 올린다.\n환경별 순차 적용 # DEV → BETA \u0026amp; 개인환경 → STAGE → PROD 각 환경에서 충분한 검증을 거친 후 다음 환경으로 진행한다. 우리는 DEV 환경에서 약 2주, BETA에서 1주의 검증 기간을 가졌다.\n주요 Breaking Changes와 대응 방법 # 1. schedule_interval → schedule # 가장 흔하게 마주치는 변경사항이다. 기존 schedule_interval에 전달하던 cron 표현식을 그대로 schedule에 전달하면 된다.\n# Before (Airflow 2.x) DAG( dag_id=\u0026#34;my_dag\u0026#34;, schedule_interval=\u0026#34;5 2 * * *\u0026#34;, ) # After (Airflow 3.x) DAG( dag_id=\u0026#34;my_dag\u0026#34;, schedule=\u0026#34;5 2 * * *\u0026#34;, ) 단순 치환이지만, DAG 수가 수백 개라면 누락 없이 전부 바꿔야 한다. CI에서 자동 검증하는 방법은 뒤에서 다룬다.\n2. 존재하지 않는 오퍼레이터 인자 전달 불가 # Airflow 3.x에서는 개별 태스크가 메타 DB상에 시리얼라이즈된 DAG을 받아 실행하도록 변경되었다. 이로 인해 allow_illegal_arguments 설정이 제거되고, 오퍼레이터에 정의되지 않은 인자를 전달하면 DAG 임포트 자체가 실패한다.\n# 이런 코드가 2.x에서는 경고 없이 동작했지만, 3.x에서는 에러가 발생한다 MyOperator( task_id=\u0026#34;my_task\u0026#34;, num_partition=10, # 실제 인자명은 num_partitions (복수형) ) TypeError: Invalid arguments were passed to MyOperator (task_id: my_task). Invalid arguments were: **kwargs: {\u0026#39;num_partition\u0026#39;: 10} 이 변경은 오히려 잠재적 버그를 발견하는 계기가 된다. 오랫동안 오타가 있는 인자가 무시되고 있었다면, 이번 마이그레이션에서 바로잡을 수 있다.\n3. Deprecated 컨텍스트/템플릿 변수 제거 # 2.x에서 deprecated 경고만 뜨던 변수들이 3.x에서는 완전히 제거되었다. 가장 영향이 큰 것은 execution_date다.\nDeprecated 변수 대체 변수 {{ execution_date }} {{ logical_date }} 또는 {{ data_interval_start }} {{ next_execution_date }} {{ data_interval_end }} {{ prev_execution_date_success }} {{ prev_data_interval_start_success }} Jinja 템플릿과 Python 코드 양쪽 모두 수정해야 한다.\n# Jinja 템플릿 # Before \u0026#34;SELECT * FROM table WHERE dt = \u0026#39;{{ execution_date }}\u0026#39;\u0026#34; # After \u0026#34;SELECT * FROM table WHERE dt = \u0026#39;{{ logical_date }}\u0026#39;\u0026#34; # Python context # Before execution_date = context[\u0026#34;execution_date\u0026#34;] # After logical_date = context[\u0026#34;logical_date\u0026#34;] 4. DB별 Operator 통합 → SQLExecuteQueryOperator # MySQL, PostgreSQL, Trino 등 DB별로 개별 존재하던 Operator가 하나의 SQLExecuteQueryOperator로 통합되었다. 내부적으로 커넥션 타입에 따라 적절한 Hook을 자동으로 선택한다.\n# Before (Airflow 2.x) from airflow.providers.mysql.operators.mysql import MySqlOperator MySqlOperator( task_id=\u0026#34;task\u0026#34;, mysql_conn_id=\u0026#34;my_conn\u0026#34;, sql=\u0026#34;SELECT 1\u0026#34; ) # After (Airflow 3.x) from airflow.providers.common.sql.operators.sql import SQLExecuteQueryOperator SQLExecuteQueryOperator( task_id=\u0026#34;task\u0026#34;, conn_id=\u0026#34;my_conn\u0026#34;, # DB별 conn_id → 통합 conn_id sql=\u0026#34;SELECT 1\u0026#34; ) 5. DummyOperator → EmptyOperator # 2.x와 3.x 양쪽에서 모두 동작하는 임포트 경로를 사용해야 한다.\n# v2에서만 동작 (3.x에서 에러) from airflow.operators.dummy import DummyOperator # v3에서만 동작 from airflow.providers.standard.operators.empty import EmptyOperator # v2 \u0026amp; v3 모두 호환 (권장) from airflow.operators.empty import EmptyOperator 6. SimpleHttpOperator → HttpOperator # # Before from airflow.providers.http.operators.http import SimpleHttpOperator # After from airflow.providers.http.operators.http import HttpOperator 7. Connection getter 메서드 → 속성 직접 참조 # Connection 클래스의 인터페이스가 더 Pythonic하게 변경되었다.\n# Before conn = BaseHook.get_connection(\u0026#34;my_conn\u0026#34;) password = conn.get_password() host = conn.get_host() # After conn = BaseHook.get_connection(\u0026#34;my_conn\u0026#34;) password = conn.password host = conn.host 8. 기타 패키지 경로 변경 # # cached_property # Before: from airflow.compat.functools import cached_property # After: from functools import cached_property (Python 내장) # KubernetesPodOperator # Before: from airflow.providers.cncf.kubernetes.operators.kubernetes_pod import ... # After: from airflow.providers.cncf.kubernetes.operators.pod import ... 대규모 DAG 환경에서의 마이그레이션 전략 # CI 파이프라인에 v3 호환성 검증 추가 # 수백 개의 DAG을 수동으로 검증하는 것은 불가능하다. MR(Merge Request) 단계에서 v3 호환성을 자동으로 검증하는 CI 잡을 추가했다.\n# .gitlab-ci.yml 예시 airflow-v3-compat-check: stage: test image: apache/airflow:3.0.6-python3.12 script: - pip install -r requirements.txt - python -m py_compile dags/**/*.py - airflow dags list --output table allow_failure: true # 초기에는 경고만, 이후 필수로 전환 처음에는 allow_failure: true로 시작해서 현황을 파악하고, 마이그레이션 기한이 다가오면 필수 검증으로 전환한다.\n이관 허들을 의도적으로 높여라 # 이것이 우리가 얻은 가장 중요한 교훈이다.\n모든 DAG 코드에 일괄 호환성 패치를 적용할 수도 있었다. 하지만 우리는 의도적으로 이관 난이도를 유지하기로 결정했다. 이유는 명확하다.\n관성적으로 운영되고 있지만 실제로는 사용하지 않는 DAG이 상당수 존재한다.\n마이그레이션을 계기로 DAG 소유자들이 **\u0026ldquo;이 DAG이 정말 필요한가?\u0026rdquo;**를 스스로 검토하도록 유도한 것이다. 결과적으로 상당수의 불필요한 DAG이 정리되었고, 이는 운영 부담 감소로 이어졌다.\n구체적인 프로세스:\n비활성 DAG 목록을 취합하여 공유 시트에 정리 DAG 소유자/소속 부서에 유지 필요 여부를 기한 내 확인하도록 안내 기한 내 응답 없으면 비활성화 v3 호환성 패치는 소유자가 직접 수행 커스텀 Provider 패키지 선제 대응 # 사내 커스텀 오퍼레이터나 유틸리티를 Provider 패키지로 제공하고 있다면, Airflow 코어의 Breaking Changes를 흡수하는 호환 레이어를 먼저 준비하는 것이 핵심이다.\n우리는 커스텀 Provider 패키지를 4차례에 걸쳐 점진적으로 업데이트했다.\nv3.0.0: 기본 호환성 확보 v3.0.1: 오퍼레이터 인자 검증 대응 v3.0.2: deprecated 컨텍스트 변수 호환 레이어 추가 v3.0.3: 문서 및 마이너 버그 수정 사용자 코드의 변경은 최소화하되, Provider 패키지 내부에서 v2/v3 분기 처리를 하는 방식으로 접근했다.\nHelm Chart 업데이트 # Kubernetes 환경에서 Airflow를 운영한다면 Helm Chart도 함께 업데이트해야 한다. 3.x에서 도입된 DAG Processor 컴포넌트와 API Server 분리를 반영해야 하기 때문이다.\n우선 기존 차트 버전에서 호환성을 확인한 후, 안정화되면 최신 stable 버전으로 업데이트하는 2단계 접근이 안전하다.\nFAB Auth Manager 이슈 # 3.x에서 React 기반으로 웹이 전면 개편되면서, 기존 Flask App Builder(FAB) 기반 Auth Manager가 기본 패키지에서 제거되었다. 커스텀 Security Manager를 사용하고 있다면 추가 설치와 코드 수정이 필요하다.\nFailed to import WoowaSecurityManager, using default security manager 이런 에러가 발생하면 FAB Auth Manager 패키지를 명시적으로 설치하고, 임포트 경로를 업데이트해야 한다.\n마치며 # Airflow 3.x 마이그레이션은 단순한 버전 업그레이드가 아니다. 아키텍처 변화(API Server 중심), 코드 호환성 변경, 인프라 업데이트까지 광범위한 작업이 필요하다.\n핵심 교훈을 정리하면 다음과 같다.\n단계적으로 올려라 — 한 번에 최신 버전으로 뛰지 말고, 2.11 → 3.0.x → Python 업그레이드 → 3.1.x 순서로 진행하라. CI에서 자동 검증하라 — 수백 개 DAG의 호환성을 사람이 확인하는 건 불가능하다. 마이그레이션을 정리의 기회로 삼아라 — 이관 허들을 의도적으로 유지해서 불필요한 DAG을 자연스럽게 걸러내라. 커스텀 Provider를 선제 업데이트하라 — 사용자 코드의 변경을 최소화하는 호환 레이어가 핵심이다. Airflow 2.x EOL까지 아직 시간이 있다고 안심하지 말자. 대규모 환경에서의 마이그레이션은 예상보다 오래 걸린다. 지금 시작해도 늦지 않다.\n참고 자료:\nUpgrading to Airflow 3 - Apache Airflow Documentation Apache Airflow 3 is Generally Available! Airflow 3.x Release Notes ","date":"February 23, 2026","externalUrl":null,"permalink":"/my-tech-blog/ko/posts/airflow-3-migration-guide/","section":"글 목록","summary":"Airflow 2.x EOL을 앞두고 3.x로 마이그레이션한 실전 경험을 공유한다. 주요 Breaking Changes, 단계적 업그레이드 전략, DAG 호환성 확보 방법, 그리고 수백 개의 DAG을 운영하는 환경에서 배운 교훈을 정리했다.","title":"Airflow 3.0 마이그레이션 가이드: 대규모 DAG 환경에서의 실전 경험","type":"posts"},{"content":"","date":"February 23, 2026","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/bali/","section":"Tags","summary":"","title":"Bali","type":"tags"},{"content":"","date":"23 February 2026","externalUrl":null,"permalink":"/my-tech-blog/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"23 February 2026","externalUrl":null,"permalink":"/my-tech-blog/tags/compression/","section":"Tags","summary":"","title":"Compression","type":"tags"},{"content":"","date":"23 February 2026","externalUrl":null,"permalink":"/my-tech-blog/categories/data-engineering/","section":"Categories","summary":"","title":"Data Engineering","type":"categories"},{"content":"","date":"February 23, 2026","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/data-engineering/","section":"Tags","summary":"","title":"Data-Engineering","type":"tags"},{"content":"","date":"23 February 2026","externalUrl":null,"permalink":"/my-tech-blog/tags/data-pipeline/","section":"Tags","summary":"","title":"Data-Pipeline","type":"tags"},{"content":"","date":"February 23, 2026","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/digital-nomad/","section":"Tags","summary":"","title":"Digital-Nomad","type":"tags"},{"content":"","date":"February 23, 2026","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/family/","section":"Tags","summary":"","title":"Family","type":"tags"},{"content":"","date":"February 23, 2026","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/iceberg/","section":"Tags","summary":"","title":"Iceberg","type":"tags"},{"content":"","date":"23 February 2026","externalUrl":null,"permalink":"/my-tech-blog/tags/kafka/","section":"Tags","summary":"","title":"Kafka","type":"tags"},{"content":"","date":"February 23, 2026","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/lakehouse/","section":"Tags","summary":"","title":"Lakehouse","type":"tags"},{"content":"","date":"February 23, 2026","externalUrl":null,"permalink":"/my-tech-blog/ko/categories/life/","section":"Categories","summary":"","title":"Life","type":"categories"},{"content":"","date":"February 23, 2026","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/migration/","section":"Tags","summary":"","title":"Migration","type":"tags"},{"content":"","date":"23 February 2026","externalUrl":null,"permalink":"/my-tech-blog/tags/olap/","section":"Tags","summary":"","title":"Olap","type":"tags"},{"content":"","date":"February 23, 2026","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/open-source/","section":"Tags","summary":"","title":"Open-Source","type":"tags"},{"content":"","date":"23 February 2026","externalUrl":null,"permalink":"/my-tech-blog/tags/optimization/","section":"Tags","summary":"","title":"Optimization","type":"tags"},{"content":"","date":"February 23, 2026","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/orchestration/","section":"Tags","summary":"","title":"Orchestration","type":"tags"},{"content":"","date":"23 February 2026","externalUrl":null,"permalink":"/my-tech-blog/","section":"OTL - Data Engineering","summary":"","title":"OTL - Data Engineering","type":"page"},{"content":"","date":"23 February 2026","externalUrl":null,"permalink":"/my-tech-blog/tags/performance-tuning/","section":"Tags","summary":"","title":"Performance-Tuning","type":"tags"},{"content":"","date":"23 February 2026","externalUrl":null,"permalink":"/my-tech-blog/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"February 23, 2026","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/python/","section":"Tags","summary":"","title":"Python","type":"tags"},{"content":"","date":"23 February 2026","externalUrl":null,"permalink":"/my-tech-blog/tags/real-time/","section":"Tags","summary":"","title":"Real-Time","type":"tags"},{"content":"","date":"February 23, 2026","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/remote-work/","section":"Tags","summary":"","title":"Remote-Work","type":"tags"},{"content":"","date":"February 23, 2026","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/starburst/","section":"Tags","summary":"","title":"Starburst","type":"tags"},{"content":"Trino를 프로덕션 쿼리 엔진으로 운영하는 팀이라면, 2025년 한 해 동안 느꼈을 것이다. 릴리스가 뜸해졌다. 감각의 문제가 아니라 숫자로 드러나는 변화다. 2024년 30개였던 Trino 오픈소스 릴리스가 2025년에는 11개로 줄었다. 63% 감소.\n이 글에서는 Starburst가 왜, 어떻게 AI 중심 플랫폼 기업으로 전환했는지를 분석하고, Trino 오픈소스 사용자 입장에서 이 변화를 어떻게 바라봐야 하는지 정리한다.\nTrino 릴리스, 무슨 일이 일어났나 # 릴리스 빈도의 급격한 변화 # Trino 오픈소스의 릴리스 패턴을 분기별로 보면, 감소 추세가 뚜렷하다.\n기간 릴리스 수 평균 주기 비고 2024 Q4 9개 주 1회 안정적 패턴 2025 Q1 6개 2주 1회 감소 시작 2025 Q2 2개 월 1회 급격한 감소 2025 Q3 1개 분기 1회 최저점 2025 Q4 2개 1.5개월 1회 여전히 저조 2024년 Q4까지만 해도 매주 새 릴리스가 나왔다. 그런데 2025년 Q2부터 월 1회 수준으로 떨어졌고, Q3에는 분기 전체에 릴리스가 단 1개였다. Starburst Enterprise 릴리스도 마찬가지로 극소수에 그쳤다.\n숫자만 놓고 보면 심각해 보이지만, 이것이 Trino의 \u0026ldquo;쇠퇴\u0026quot;를 의미하는 건 아니다. Starburst의 전략적 선택이다.\n왜 줄었는가 # Trino 오픈소스에 대한 Starburst의 기여도를 보면 답이 보인다. 2024년 기준으로 Starburst 팀이 Trino 전체 커밋의 **84%**를 차지했다. 138명의 기여자, 2,822개 커밋, 50개 이상 기업이 참여했지만, 실질적인 개발 동력은 Starburst였다. 그 Starburst가 엔지니어링 리소스를 다른 곳에 집중하기 시작한 것이다.\n그 \u0026ldquo;다른 곳\u0026quot;이 바로 AI다.\nStarburst의 AI 피벗 # 포지셔닝의 변화 # Starburst의 공식 메시징 변화를 추적하면, 전환이 얼마나 의도적이었는지 알 수 있다.\n시기 포지셔닝 핵심 메시지 ~2023 Open Data Lakehouse Company Trino 기반 분산 쿼리 엔진 2024 Data Lake Analytics Platform 페더레이션 쿼리 + Iceberg 2025 Data Platform for Apps and AI AI Agent + Agentic Workforce \u0026ldquo;Open Data Lakehouse\u0026quot;에서 \u0026ldquo;Data Platform for Apps and AI\u0026quot;로. 단순한 마케팅 변화가 아니라, 제품 로드맵 전체가 이 방향으로 정렬되었다.\n2025년 주요 발표 타임라인 # 2025년 5월 — Launch Point\nStarburst는 AI Agent와 AI Workflows를 공식 발표했다.\nAI Agent: 자연어로 데이터를 쿼리하는 인터페이스. \u0026ldquo;What were our sales in Europe last quarter?\u0026ldquo;라는 질문이 자동으로 SQL로 변환된다. Air-gapped 환경(금융, 의료, 정부)을 명시적으로 지원하며, Google의 Agent2Agent 프로토콜과 Anthropic의 Model Context Protocol(MCP)을 지원한다. AI Workflows: Vector embeddings를 Iceberg 테이블에 저장하고, 구조화/반구조화/비구조화 데이터를 AI 학습에 활용할 수 있는 파이프라인. RAG(Retrieval-Augmented Generation)를 네이티브로 지원한다. 기타: Starburst Data Catalog(Hive Metastore 대체), Automated Table Maintenance(파일 정리 및 컴팩션 자동화), Native ODBC Driver, Role-based Query Routing 2025년 10월 — AI \u0026amp; Datanova 2025\n여기서 Starburst는 Agentic Workforce 플랫폼과 Lakeside AI Architecture를 발표하며 한 단계 더 나아갔다.\n핵심 개념은 Model-to-Data 아키텍처다. 기존의 접근 방식이 데이터를 중앙 웨어하우스로 모은 뒤 AI 모델을 돌리는 것이었다면, Starburst는 AI 모델을 데이터가 있는 곳으로 보내는 방식을 제안한다.\n기존 접근: Data → Centralized Warehouse → AI Model Starburst: AI Model → Federated Data (where it lives) 데이터를 이동시키지 않으므로 데이터 주권(GDPR, Schrems II)을 유지하면서도 통합 분석이 가능하다는 논리다. Citi, HSBC 같은 글로벌 금융기관이 165개국에 흩어진 데이터를 이 방식으로 통합하고 있다고 한다.\n기술 스택의 변화 # Starburst의 기술 스택을 레이어로 표현하면, 2025년에 추가된 부분이 명확히 보인다.\n┌─────────────────────────────────────┐ │ AI Agent \u0026amp; Agent2Agent Protocol │ ← 2025 NEW ├─────────────────────────────────────┤ │ AI Workflows (Vector Store) │ ← 2025 NEW ├─────────────────────────────────────┤ │ Starburst Data Catalog │ ← 2025 NEW ├─────────────────────────────────────┤ │ Lakehouse (Trino + Iceberg) │ ├─────────────────────────────────────┤ │ Federated Data Sources (50+) │ └─────────────────────────────────────┘ Trino는 여전히 기반 레이어에 있지만, 혁신은 전부 위에서 일어나고 있다. Trino 오픈소스 릴리스가 줄어든 이유가 여기에 있다. 엔지니어링 리소스가 상위 레이어로 이동한 것이다.\nVector Store on Iceberg: 주목할 만한 기술적 혁신 # 2025년 Starburst 발표 중 기술적으로 가장 흥미로운 것은 Apache Iceberg 테이블에 직접 vector embeddings를 저장하는 접근이다.\n이게 왜 의미 있는가:\n별도의 벡터 DB가 필요 없다. Pinecone, Weaviate, Milvus 같은 전용 벡터 데이터베이스를 운영할 필요가 없어진다. 기존 데이터 엔지니어링 스킬을 그대로 활용한다. Iceberg 테이블을 다루는 방식 그대로 벡터 데이터를 관리할 수 있다. Iceberg의 장점이 벡터 데이터에도 적용된다. Time travel, ACID 트랜잭션, 스키마 진화, 파티셔닝 등을 벡터 데이터에도 활용할 수 있다. 거버넌스 정책이 일관성 있게 적용된다. 구조화 데이터와 벡터 데이터에 동일한 접근 제어, 감사 로그, 데이터 마스킹 정책을 적용할 수 있다. 오픈 포맷이므로 vendor lock-in이 없다. AI 워크로드가 데이터 플랫폼의 핵심 요구사항이 되는 미래를 가정하면, 이 접근은 상당히 실용적이다. 물론 전용 벡터 DB 대비 검색 성능은 트레이드오프가 있을 수 있지만, 운영 복잡도 감소와 거버넌스 통합이라는 장점은 엔터프라이즈 환경에서 매력적이다.\n비즈니스 성과: 전략이 시장에서 통하고 있는가 # AI 피벗이 단순한 마케팅이 아니라는 것은 비즈니스 지표가 증명한다.\nFY25 실적 (2025년 2월 발표):\n지표 성과 신규 고객 전년 대비 20% 증가 Galaxy(SaaS) 고객 전년 대비 76% 증가 Galaxy 사용량 전년 대비 94% 증가 최대 계약 글로벌 금융기관과 8자리(억 단위) 다년 계약 파트너십 Dell Data Lakehouse의 쿼리 엔진으로 선정 특히 Galaxy(SaaS) 고객이 76% 증가했다는 것은 주목할 만하다. 클라우드 매니지드 서비스로의 전환이 가속화되고 있다는 의미이고, 이는 오픈소스 Trino를 직접 운영하는 팀들의 대안이기도 하다.\n주요 고객사도 인상적이다:\nHSBC: 165개국 데이터 통합 Citi: 글로벌 데이터 주권 유지하며 통합 분석 Vectra AI: 120개국 위협 탐지 플랫폼 ZoomInfo: 멀티클라우드 데이터 통합 경쟁 환경에서의 포지셔닝 # 데이터 플랫폼 시장에서 Starburst의 위치를 경쟁사와 비교하면 차별화 포인트가 명확해진다.\n기능 Databricks Snowflake Dremio Starburst AI Agent O O X O Federated Query 제한적 제한적 O 핵심 강점 Data Sovereignty 제한적 제한적 제한적 핵심 강점 오픈소스 기반 Spark X Arrow Trino Vector Store O O X O (Iceberg) On-prem + Cloud O 제한적 O 핵심 강점 Starburst의 핵심 차별화는 세 가지다:\n진정한 페더레이션: 50개 이상 데이터 소스에 대한 실시간 쿼리. 데이터를 이동시키지 않고 제자리에서 분석한다. 데이터 주권: 165개국 규제를 준수하면서 통합 분석을 제공한다. GDPR, Schrems II 환경에서 결정적 장점이다. 하이브리드 배포: On-premise와 멀티 클라우드를 동시에 지원한다. 규제 산업에서 클라우드 전환이 더딘 기업들에게 핵심 가치다. 반면 Databricks는 Spark + Delta Lake 중심의 AI/ML Lakehouse로, Unity Catalog으로 거버넌스를 강화하고 있다. Snowflake는 2024년 Iceberg 지원을 추가하고 Snowpark으로 AI/ML을 밀고 있지만, 여전히 데이터 중앙화가 전제다. Dremio는 Arrow Flight 기반 성능과 시맨틱 레이어를 강조하지만, 엔터프라이즈 기능에서는 아직 격차가 있다.\n흥미로운 것은 Starburst CEO Justin Borgman의 발언이다: \u0026ldquo;What they\u0026rsquo;ve done for Spark is what we aim to do for Presto(Trino).\u0026rdquo; Databricks가 Spark 오픈소스 위에 강력한 상용 플랫폼을 구축한 것처럼, Starburst도 Trino 위에 같은 구조를 만들겠다는 것이다.\nTrino 오픈소스, 괜찮을 것인가 # 오픈소스와 상용 기능의 분리 # 현재 Trino 오픈소스에 남아있는 것과 Starburst 전용으로 넘어간 것을 정리하면 다음과 같다.\nTrino 오픈소스:\n핵심 쿼리 엔진 기본 커넥터들 Fault-tolerant execution SQL MERGE 기본 보안 기능 Starburst 전용:\nWarp Speed (최대 7배 성능 향상) AI Agent \u0026amp; AI Workflows Starburst Data Catalog 고급 거버넌스 (RBAC, 데이터 마스킹, 감사 로그) Automated Table Maintenance Smart Indexing Materialized Views (일부) 가장 눈에 띄는 것은 Warp Speed다. 최대 7배 성능 향상을 제공하는 독점 인덱싱/캐싱 레이어가 상용 전용이라는 것은, 대규모 워크로드에서 오픈소스와 상용 제품의 성능 격차가 점점 벌어질 수 있다는 의미다.\n낙관적으로 볼 수 있는 근거 # Trino 코어 엔진은 성숙 단계에 접어들었다. 분산 SQL 쿼리 엔진으로서 필요한 기능은 대부분 갖추고 있다. 릴리스 빈도가 줄었다고 품질이 떨어지는 것은 아니다. 커뮤니티는 여전히 활발하다. Trino Summit 2024는 Netflix, LinkedIn, Wise 등이 참여하며 성공적으로 개최되었고, Trino Community Broadcast도 지속 운영 중이다. Slack과 GitHub 활동도 유지되고 있다. 50개 이상 기업이 기여하고 있다. Starburst의 기여가 줄더라도 다른 기업들이 메울 여지는 있다. 우려할 점 # 84%의 커밋을 한 회사가 다른 곳에 집중하기 시작했다. 다른 기업들이 이 공백을 메울 인센티브가 충분한지는 미지수다. 성능 최적화의 핵심이 상용 전용이다. Warp Speed 없이 대규모 워크로드를 운영하는 팀은 갈수록 불리해질 수 있다. AI 관련 혁신이 모두 상용 제품에 집중되어 있다. 데이터 플랫폼에 AI가 필수가 되는 미래에서, 오픈소스만으로는 경쟁력 확보가 어려워질 수 있다. Trino 운영 팀이 고려해야 할 것 # Trino를 프로덕션에서 운영하는 팀의 입장에서, 이 상황을 두 가지 시간 축으로 나눠서 생각해 볼 수 있다.\n단기 (1~2년): 큰 문제 없다 # Trino 오픈소스는 여전히 안정적이고 프로덕션에서 검증된 기술이다. 핵심 기능은 충분히 성숙했고, 기본적인 쿼리 성능과 커넥터 생태계는 탄탄하다. 당장 대안으로 갈아타야 할 이유는 없다.\n중장기 (3~5년): 전략적 대비가 필요하다 # 오픈소스와 상용 제품의 기능 격차가 확대될 가능성을 감안해야 한다. 특히 다음 영역에서의 대비가 필요하다:\n성능 최적화: Warp Speed 없이 대규모 워크로드의 성능을 어떻게 확보할 것인가. 자체적인 캐싱 레이어, 인덱싱 전략, 또는 StarRocks 같은 보완 엔진의 역할 확대를 검토해야 한다. AI 통합: 데이터 플랫폼에 AI를 통합하는 것이 조직의 요구사항이 될 때, 오픈소스 Trino만으로 충분한지 평가해야 한다. Vector Store on Iceberg 같은 접근을 자체적으로 구현할 수 있는지, 혹은 다른 도구와의 조합이 필요한지. 거버넌스: 조직이 커지고 규제가 강화될수록, 고급 거버넌스 기능(RBAC, 데이터 마스킹, 감사 로그)의 필요성이 커진다. 오픈소스만으로 이를 충족할 수 있는지. 대안 평가: Starburst Galaxy 도입, 다른 쿼리 엔진으로의 전환, 또는 하이브리드 접근(배치는 Trino, 실시간은 StarRocks)을 주기적으로 평가해야 한다. 마치며 # Starburst의 AI 피벗은 단순한 마케팅 전략이 아니다. 비즈니스 지표(Galaxy 고객 76% 증가, 역대 최대 계약)가 이 전략이 시장에서 통하고 있음을 증명하고 있다. 쿼리 엔진 회사에서 AI 플랫폼 기업으로의 전환은 되돌릴 수 없는 방향이다.\nTrino 오픈소스는 당장 죽지 않는다. 하지만 \u0026ldquo;충분히 성숙한\u0026rdquo; 상태로 유지보수 모드에 가까워지고 있으며, 혁신의 무게 중심은 명확하게 상용 제품으로 이동했다. 이것은 Databricks가 Spark에 대해 했던 것과 같은 패턴이다.\nTrino를 프로덕션에서 운영하는 팀이라면, 지금 당장은 안심해도 되지만, 3년 뒤를 위한 대비는 지금 시작해야 한다. 오픈소스의 안정성에 기대면서도, 성능 격차와 AI 통합이라는 두 가지 축에서 전략적 옵션을 확보해 두는 것이 현명한 접근이다.\n기술 부채는 늘 조용히 쌓인다. 그리고 언제나 우리가 생각했던 것보다 이자가 비싸다.\n참고 자료:\nTrino Release Notes Starburst Enterprise Release Notes TechTarget: Addition of new AI capabilities shows Starburst\u0026rsquo;s growth BigDataWire: Starburst\u0026rsquo;s New Platform Aims to Close AI\u0026rsquo;s Biggest Gap ","date":"February 23, 2026","externalUrl":null,"permalink":"/my-tech-blog/ko/posts/starburst-trino-ai-pivot/","section":"글 목록","summary":"Starburst가 쿼리 엔진 회사에서 AI 플랫폼 기업으로 전환하면서 Trino 오픈소스 릴리스가 63% 감소했다. Trino를 프로덕션에서 운영하는 팀의 관점에서, 이 변화가 의미하는 것과 앞으로의 전략을 정리한다.","title":"Starburst의 AI 피벗: Trino 오픈소스는 괜찮을까?","type":"posts"},{"content":"","date":"23 February 2026","externalUrl":null,"permalink":"/my-tech-blog/tags/starrocks/","section":"Tags","summary":"","title":"Starrocks","type":"tags"},{"content":"","date":"23 February 2026","externalUrl":null,"permalink":"/my-tech-blog/categories/starrocks/","section":"Categories","summary":"","title":"StarRocks","type":"categories"},{"content":" Background # If you run data pipelines long enough, you inevitably face one question: How do you build real-time dashboards?\nOur team was no different. Our existing pipeline looked like this:\nService → Kafka → Iceberg → S3 → Trino → Airflow(5min) → Dashboard On the surface it worked fine, but the pain points in practice were clear:\nAt least 5 minutes of latency: The Airflow schedule interval was the bottleneck Pipeline complexity: Managing 5+ components chained as Kafka → Flink → Redis → API → Dashboard Redundant I/O: Trino full-scanned S3 on every query High development cost: Each new real-time dashboard took roughly 2 weeks to build After adopting StarRocks, the architecture simplified to this:\nService → Kafka → StarRocks → Dashboard (sub-second latency) Eliminating the intermediate components dramatically simplified the pipeline, and ingesting data directly from Kafka into StarRocks gave us the real-time capability we needed.\nResults # After approximately 3 months of PoC and 6 months of phased rollout, we achieved the following improvements:\nMetric Before After Improvement Dashboard latency 5 min \u0026lt; 1 sec ~300x Dashboard dev time ~2 weeks ~1 week 50% reduction Pipeline components 5+ 2 60% reduction Query response time 30~50 sec 5~10 sec 5~10x Hardware cost 128 GB x 18 nodes 64 GB x 3 nodes ~75% savings Trino is fast in terms of raw query time, but when factoring in Airflow schedule delays and end-to-end latency, along with hardware cost efficiency, StarRocks proved to be a better fit for real-time workloads.\nTable Model Selection Guide # Choosing the right table model is the most important decision when first adopting StarRocks. A wrong choice means you will have to recreate the table later.\nDecision Flow # ┌─────────────────────────────┐ │ What data are you storing? │ └──────────────┬──────────────┘ │ ┌───────▼────────┐ │ Need UPDATE? │ └───────┬────────┘ │ ┌────────┴────────┐ │ │ [No] [Yes] │ │ ┌─────▼─────┐ ┌─────▼──────┐ │ Need │ │ Primary Key │ │aggregation?│ │ (frequent │ └─────┬─────┘ │ UPDATE) │ │ └────────────┘ [No] [Yes] │ │ ┌─────▼───┐ ┌▼──────────┐ │Duplicate│ │Aggregate │ │(raw data)│ │(auto-agg) ★│ └─────────┘ └────────────┘ Model Comparison # Model Duplicates Allowed UPDATE Auto-aggregation Best For Duplicate Key O X X Logs, raw events Aggregate Key X Auto O Real-time statistics ★ Primary Key X O (fast) X Frequent UPDATEs Duplicate Key: Storing Raw Data # Use this when you need to preserve original data as-is, such as click logs, API events, or sensor data.\nCREATE TABLE order_events ( event_id BIGINT, event_time DATETIME, order_id VARCHAR(50), user_id BIGINT, event_type VARCHAR(20), amount DECIMAL(10, 2) ) DUPLICATE KEY(event_id, event_time) PARTITION BY date_trunc(\u0026#39;day\u0026#39;, event_time) DISTRIBUTED BY HASH(event_id) BUCKETS 10; Aggregate Key: Real-time Statistics ★ # Data is automatically aggregated at ingestion time. This model was the key reason for adopting StarRocks.\nCREATE TABLE order_stats ( stat_time DATETIME NOT NULL COMMENT \u0026#39;5-minute intervals\u0026#39;, region VARCHAR(20) NOT NULL, delivery_type VARCHAR(20) NOT NULL, -- Aggregate columns: aggregate functions applied automatically at ingestion order_count BIGINT SUM DEFAULT \u0026#34;0\u0026#34;, total_amount DECIMAL(15, 2) SUM DEFAULT \u0026#34;0\u0026#34;, user_bitmap BITMAP BITMAP_UNION, max_amount DECIMAL(10, 2) MAX ) AGGREGATE KEY(stat_time, region, delivery_type) PARTITION BY date_trunc(\u0026#39;day\u0026#39;, stat_time) DISTRIBUTED BY HASH(stat_time) BUCKETS 10; Available aggregate functions:\nFunction Purpose Example SUM Summation Order count, total revenue MAX / MIN Maximum / minimum value Highest price, lowest price REPLACE Overwrite with latest value Latest status BITMAP_UNION Exact unique count Unique visitors HLL_UNION Approximate unique count High-cardinality sets Unlike HyperLogLog, BITMAP_UNION provides exact unique counts. For business KPI dashboards where accuracy matters, always use this approach.\nPrimary Key: Frequent UPDATEs # Best suited for scenarios where the same key is frequently updated, such as order status tracking or inventory management.\nCREATE TABLE orders ( order_id VARCHAR(50) NOT NULL, status VARCHAR(20), amount DECIMAL(10, 2), updated_at DATETIME ) PRIMARY KEY(order_id) DISTRIBUTED BY HASH(order_id) BUCKETS 10 PROPERTIES ( \u0026#34;enable_persistent_index\u0026#34; = \u0026#34;true\u0026#34; ); Enabling enable_persistent_index significantly improves UPDATE performance.\nData Ingestion # Routine Load: Real-time Kafka Integration # This approach continuously ingests data from a Kafka topic. It is the method used in most real-time pipelines.\nCREATE ROUTINE LOAD order_load ON orders COLUMNS( order_id, user_id, timestamp_ms, amount, order_date = FROM_UNIXTIME(timestamp_ms / 1000) ) PROPERTIES ( \u0026#34;format\u0026#34; = \u0026#34;json\u0026#34;, \u0026#34;jsonpaths\u0026#34; = \u0026#34;[\\\u0026#34;$.orderId\\\u0026#34;,\\\u0026#34;$.userId\\\u0026#34;,\\\u0026#34;$.timestamp\\\u0026#34;,\\\u0026#34;$.amount\\\u0026#34;]\u0026#34; ) FROM KAFKA ( \u0026#34;kafka_broker_list\u0026#34; = \u0026#34;kafka-broker:9092\u0026#34;, \u0026#34;kafka_topic\u0026#34; = \u0026#34;orders\u0026#34; ); When combined with an Aggregate Key table, transformation and aggregation happen simultaneously at ingestion time.\nCREATE ROUTINE LOAD order_stats_load ON order_stats COLUMNS( timestamp_ms, region, amount, user_id, -- Round to 5-minute intervals stat_time = FROM_UNIXTIME(FLOOR(timestamp_ms / 1000 / 300) * 300), order_count = 1, total_amount = amount, user_bitmap = BITMAP_HASH(user_id) ) WHERE amount \u0026gt; 0 PROPERTIES (\u0026#34;format\u0026#34; = \u0026#34;json\u0026#34;) FROM KAFKA ( \u0026#34;kafka_broker_list\u0026#34; = \u0026#34;kafka-broker:9092\u0026#34;, \u0026#34;kafka_topic\u0026#34; = \u0026#34;orders\u0026#34; ); This single pattern replaced the aggregation logic that previously required Flink \u0026ndash; using nothing but SQL.\nStream Load: Bulk Data Loading # Ideal for one-time bulk loads via files or APIs.\n# CSV file loading curl --location-trusted \\ -u user:password \\ -H \u0026#34;label:load_$(date +%Y%m%d%H%M%S)\u0026#34; \\ -H \u0026#34;column_separator:,\u0026#34; \\ -T data.csv \\ http://starrocks-fe:8030/api/mydb/mytable/_stream_load Performance Tuning Tips # Thread Pool Configuration # In high-load environments with 500+ RPS of concurrent connections, the default thread pool size is insufficient.\n# be.conf pipeline_scan_thread_pool_thread_num = 32 # default: 24 pipeline_exec_thread_pool_thread_num = 32 # default: 24 Bucket Count Guidelines # Data Size Recommended Buckets \u0026lt; 10 GB 10 10~50 GB 20 50~100 GB 30 \u0026gt; 100 GB 50+ Formula: buckets = max(1, data_size_GB / 10)\nPartitioning Strategy # Applying functions to partition columns prevents partition pruning. This is a more common mistake than you might think.\n-- ✅ Correct: partition pruning works WHERE event_time \u0026gt;= NOW() - INTERVAL 3 DAY -- ❌ Incorrect: partition pruning disabled WHERE DATE(event_time) \u0026gt;= CURRENT_DATE - 3 TTL Configuration # To automatically drop old partitions, configure TTL.\nPROPERTIES ( \u0026#34;partition_live_number\u0026#34; = \u0026#34;3\u0026#34; -- Keep only the 3 most recent partitions ) Operational Know-how # Materialized View Management # ASYNC refresh can stop without warning. Periodically check the status and manually recover when issues arise.\n-- Check status SHOW MATERIALIZED VIEWS; -- Force synchronous refresh REFRESH MATERIALIZED VIEW db.mv_name WITH SYNC MODE; -- Reactivate a deactivated MV ALTER MATERIALIZED VIEW db.mv_name ACTIVE; Routine Load Monitoring # The status frequently transitions to PAUSED. Common causes include Kafka offset issues or malformed messages.\n-- Check status SHOW ROUTINE LOAD FOR db.load_job; -- Resume RESUME ROUTINE LOAD FOR db.load_job; Scale-in Precautions # When scaling down nodes, you must perform a Decommission first. Removing nodes without this procedure will result in data loss.\n-- 1. Check current nodes SHOW PROC \u0026#39;/backends\u0026#39;; -- 2. Start decommission ALTER SYSTEM DECOMMISSION BACKEND \u0026#34;\u0026lt;BE_IP\u0026gt;:\u0026lt;HEARTBEAT_PORT\u0026gt;\u0026#34;; -- 3. Wait until TabletNum reaches 0, then remove ALTER SYSTEM DROP BACKEND \u0026#34;\u0026lt;BE_IP\u0026gt;:\u0026lt;HEARTBEAT_PORT\u0026gt;\u0026#34;; Things to Know Before Adopting # Known Limitations # Issue Description Workaround Routine Load Limited handling of malformed messages Pre-validate on the Kafka side datetime partitions Compatibility issues with Iceberg datetime partitions Use an alternative partitioning strategy Version upgrades Encountered bugs in 4.x releases Always test in a staging environment Always thoroughly validate version upgrades in a staging environment before applying them to production. We went through several rounds of upgrades and rollbacks ourselves. Have a rollback plan ready at all times.\nAdoption Checklist # Pre-deployment\nDefine use cases and requirements Estimate data volume and growth rate Choose table models Design partitioning strategy Post-deployment\nCreate and verify Routine Load jobs Configure user permissions Set data retention policies (TTL) Document scale-in/out procedures Build monitoring dashboards Conclusion # Here are the key lessons we learned from adopting StarRocks:\nThe Aggregate Key model is the centerpiece \u0026ndash; Automatic aggregation at ingestion time optimizes both storage and query performance Use BITMAP_UNION for exact unique counts \u0026ndash; Business KPIs demand precise numbers, not approximations Routine Load + Aggregate Key replaces Flink \u0026ndash; You can build a real-time aggregation pipeline with SQL alone Invest in operational automation \u0026ndash; Monitoring Materialized Views and Routine Load is essential For real-time analytics workloads, StarRocks is a powerful option that dramatically reduces pipeline complexity. That said, it is still maturing in terms of version upgrade stability and operational robustness, so we recommend conducting thorough PoC testing and staging validation before adopting it.\nReference: StarRocks Official Docs\n","date":"23 February 2026","externalUrl":null,"permalink":"/my-tech-blog/posts/starrocks-adoption-guide/","section":"Posts","summary":"How we reduced pipeline latency from 5 minutes to sub-second by adopting StarRocks. Covers table model selection, data ingestion, performance tuning, and operational lessons from production.","title":"StarRocks Adoption Story: Revolutionizing Data Pipelines with Real-time OLAP","type":"posts"},{"content":" Why Compression Settings Matter # When you operate StarRocks long enough, there will inevitably come a point where your data grows to tens of terabytes. I have seen, time and again, cases where a single compression setting made a 30 to 50 percent difference in storage costs. But this is not just about disk space. Higher compression ratios reduce disk I/O and improve scan performance, while overly aggressive compression burns CPU and increases latency. Ultimately, choosing the right compression algorithm for your workload is one of the most important tuning decisions in StarRocks operations.\nComparing Supported Compression Algorithms # StarRocks supports several compression algorithms. Here is a comparison of the three most commonly used in practice.\nAlgorithm Compression Ratio Compression Speed Decompression Speed Best-fit Workload LZ4 Moderate (2-3x) Very fast Very fast Real-time analytics, low-latency queries ZSTD High (4-6x) Moderate Fast Batch analytics, cold data Snappy Low (1.5-2x) Fast Fast General purpose, legacy compatibility ZLIB High (4-5x) Slow Moderate Archiving, infrequently accessed data Personally, the combination I use most often is LZ4 for hot data and ZSTD for cold data. I occasionally use Snappy when dealing with data migrated from the Hadoop ecosystem, but I do not recommend it for new tables.\nSetting Compression When Creating a Table # You can specify the compression algorithm via the compression property in PROPERTIES when creating a table. If no value is set, StarRocks defaults to LZ4.\nReal-time Analytics Table (LZ4) # CREATE TABLE analytics.realtime_events ( event_id BIGINT, user_id BIGINT, event_type VARCHAR(64), event_time DATETIME, properties JSON ) ENGINE = OLAP DUPLICATE KEY(event_id) DISTRIBUTED BY HASH(user_id) BUCKETS 32 PROPERTIES ( \u0026#34;replication_num\u0026#34; = \u0026#34;3\u0026#34;, \u0026#34;compression\u0026#34; = \u0026#34;LZ4\u0026#34; ); LZ4 has overwhelmingly fast decompression speed, making it ideal for tables that need to serve dashboard queries with sub-second response times.\nBatch Analytics Table (ZSTD) # CREATE TABLE warehouse.order_history ( order_id BIGINT, customer_id BIGINT, order_date DATE, total_amount DECIMAL(18, 2), status VARCHAR(32), items ARRAY\u0026lt;STRUCT\u0026lt;sku STRING, qty INT, price DECIMAL(10,2)\u0026gt;\u0026gt; ) ENGINE = OLAP DUPLICATE KEY(order_id) PARTITION BY RANGE(order_date) ( PARTITION p2025 VALUES LESS THAN (\u0026#39;2026-01-01\u0026#39;), PARTITION p2026 VALUES LESS THAN (\u0026#39;2027-01-01\u0026#39;) ) DISTRIBUTED BY HASH(customer_id) BUCKETS 16 PROPERTIES ( \u0026#34;replication_num\u0026#34; = \u0026#34;2\u0026#34;, \u0026#34;compression\u0026#34; = \u0026#34;ZSTD\u0026#34; ); ZSTD achieves 1.5 to 2 times higher compression ratios than LZ4, which translates into significant storage savings on history tables where hundreds of millions of rows accumulate per partition.\nChanging Compression on an Existing Table # If you want to change the compression algorithm on a table that is already in production, you can use ALTER TABLE. Keep in mind, however, that the new setting only applies to data loaded after the change. Existing segments will not be recompressed until a compaction cycle runs against them.\nALTER TABLE warehouse.order_history SET (\u0026#34;compression\u0026#34; = \u0026#34;ZSTD\u0026#34;); Recommended Compression Settings by Workload # The following recommendations are based on patterns I have validated repeatedly in production environments.\nReal-time dashboards / Ad-hoc queries: Use LZ4. Its CPU overhead is negligible, minimizing the impact on P99 latency. Nightly batch reports / ETL result tables: Use ZSTD. When query frequency is low and data volume is high, the storage savings translate directly into cost reductions. High-volume log ingestion: Use ZSTD, but lower zstd_compression_level to 3 or below. This strikes a good balance between compression speed and compression ratio. Benchmark Results: Compression Ratio vs. Performance Tradeoffs # The following benchmark was run against an event log table containing approximately 5 billion rows (roughly 800 GB uncompressed).\nMetric LZ4 ZSTD (level 3) ZSTD (level 9) Compressed size 320 GB 195 GB 170 GB Compression ratio 2.5x 4.1x 4.7x Simple scan query (Avg) 1.2 s 1.5 s 1.8 s Aggregation query (Avg) 3.4 s 3.8 s 4.5 s Data ingestion throughput 120 MB/s 95 MB/s 60 MB/s Compared to LZ4, ZSTD level 3 reduced storage by approximately 39% while only increasing query latency by about 10 to 15 percent. ZSTD level 9, on the other hand, offered diminishing compression gains at the cost of a steep drop in ingestion throughput, making level 3 the optimal choice in most environments.\nOperational Tips and Monitoring # Here are three tips from production experience:\nAlways monitor compaction. Keep an eye on the compaction_score metric. When compression settings change or data volumes spike, compaction can fall behind, leading to degraded query performance from an excessive number of small segments. Separate compression strategies at the table level. Do not apply a single compression algorithm across your entire cluster. Match the algorithm to each table\u0026rsquo;s access pattern \u0026ndash; LZ4 for frequently queried tables, ZSTD for archival ones. Track disk usage trends over time. Use SHOW DATA to monitor how each table\u0026rsquo;s storage footprint evolves after compression changes. SHOW DATA FROM warehouse.order_history; Compression is not a set-it-and-forget-it decision. As data volumes grow and query patterns shift, it is worth revisiting your compression settings periodically. Even a small adjustment can yield meaningful improvements in both performance and infrastructure costs over time.\n","date":"23 February 2026","externalUrl":null,"permalink":"/my-tech-blog/posts/starrocks-compression-guide/","section":"Posts","summary":"A practical guide to optimizing compression settings in StarRocks. Covers algorithm comparison, per-workload recommendations, benchmark results, and operational tips from production experience.","title":"StarRocks Compression Guide: Optimizing Performance and Storage","type":"posts"},{"content":"","date":"23 February 2026","externalUrl":null,"permalink":"/my-tech-blog/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"February 23, 2026","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/trends/","section":"Tags","summary":"","title":"Trends","type":"tags"},{"content":"","date":"February 23, 2026","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/trino/","section":"Tags","summary":"","title":"Trino","type":"tags"},{"content":"","date":"February 23, 2026","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/vector-store/","section":"Tags","summary":"","title":"Vector-Store","type":"tags"},{"content":"","date":"February 23, 2026","externalUrl":null,"permalink":"/my-tech-blog/ko/tags/workation/","section":"Tags","summary":"","title":"Workation","type":"tags"},{"content":"발리하면 떠오르는 이미지가 있다. 서핑, 열대 자연, 코워킹 스페이스에서 노트북을 펼친 디지털 노마드. 워케이션(workation)의 성지라는 수식어가 붙는 곳이다.\n나도 그 이미지에 이끌렸다. 아이에게는 해외 유치원이라는 새로운 경험을, 가족에게는 일상에서의 해방감을 줄 수 있을 거라 기대했다. 2023년 초, 회사의 해외 리모트 근무 제도를 활용해 발리에서 약 한 달간 일하고 생활했다.\n결론부터 말하면, 아이가 있는 가정에게 발리 리모트 근무는 생각보다 별로였다. 이 글은 그 솔직한 기록이다. 발리 리모트 근무를 고민하는 분들, 특히 어린 아이가 있는 가정이라면 이 글이 판단에 도움이 되었으면 한다.\n출발 전: 준비해야 할 것들 # 승인과 세무 이슈 # 해외 리모트 근무는 비행기표를 사기 전에 회사 승인부터 받아야 한다. 승인 과정에서 일정 변경이 생길 수 있기 때문이다.\n나의 경우, 처음에 3개월 체류를 신청했으나 세무 검토 과정에서 세법상 2개월 이하만 가능하다는 회신을 받았다. 해외 체류 기간에 따라 세금 처리가 달라지기 때문이다. 비행기표를 이미 끊어놨다면 변경 수수료를 물어야 할 뻔했다. 반드시 승인 확정 후에 항공권을 구매하자.\n항공권은 대한항공 마일리지를 사용했는데, 비용 대비 차감되는 마일리지가 적어서 가성비가 좋았다.\n숙소: 빌라의 함정 # 발리 숙소는 크게 두 가지 선택지가 있다. 호텔/리조트를 전전하거나, 월 단위로 빌라를 빌리거나.\n나는 호텔에서 3일 정도 지내본 뒤, 수영장이 딸린 발리스러운 빌라를 월 단위로 계약했다. 사진으로 보면 정말 근사하다. 야자수 아래 프라이빗 풀, 넓은 거실, 열대 정원. 문제는 실제로 살아보면 다르다는 것이다. 결국 빌라를 취소하고 다시 호텔로 돌아왔다.\n빌라의 현실:\n벌레가 많다. 개미, 모기는 기본이고 이름 모를 벌레들이 출몰한다. 호텔/리조트는 방역을 하지만 빌라는 그렇지 않다. 침구류와 청소 상태가 불안정하다. 관리 수준이 숙소마다 천차만별이다. 상수도 문제. 후술하겠지만, 이것이 가장 큰 문제다. 교통이 불편하다. 빌라가 저렴한 이유가 있다. 대부분 도심에서 떨어져 있고, 발리에서 걸어 다니는 건 사실상 불가능하다. 한 달 이상 체류할 거라면 빌라가 합리적으로 보이지만, 특히 아이가 있다면 호텔이나 서비스드 레지던스가 낫다. 관리, 위생, 편의성 모든 면에서 그렇다.\n위생: 발리의 가장 큰 리스크 # 인도네시아 여행 커뮤니티에서 가장 많이 나오는 토픽이 있다. \u0026ldquo;병원 어디 가야 해요?\u0026rdquo;, \u0026ldquo;약 좀 주세요\u0026rdquo;, \u0026ldquo;샤워기 필터 구합니다.\u0026rdquo;\n과장이 아니다.\n물 문제 # 발리는 지하수를 끌어다 쓰는 곳이 많다. 오염된 경우가 적지 않아서, 비누로 빡빡 씻어도 몸이 계속 미끈미끈한 느낌이 가시지 않는다. 유럽의 석회수와는 또 다른 종류의 불쾌함이다.\n수영장은 발리 곳곳에 널려 있지만, 소독약 냄새가 안 나는 곳이 많다. 소독약 냄새가 안 난다는 건, 소독을 안 한다는 뜻이다. 세균과 박테리아가 번식하기 좋은 열대 기후에서.\n비치도 안심할 수 없다. 서핑 중 육지에서 흘러들어온 오염된 바닷물을 삼키고 아픈 사람이 많다. 카페에서 나오는 차가운 음료의 얼음이 정수된 물로 만든 것인지도 확신할 수 없다.\n아이의 입원 # 출국 전 나름 준비를 했다. 장티푸스 예방접종을 맞고, 출국 전날 종합병원에서 피검사로 염증 수치와 백혈구 수치를 확인했다. 유산균도 2주 전부터 복용시켰다.\n도착 3일 만에 아이에게 고열이 찾아왔다.\n평소 38도 위로 올라간 적이 없던 아이가 39.5도까지 치솟았다. 응급실을 세 번 갔다. 세 번째 응급실에서는 귀가하겠다고 하니 \u0026ldquo;책임지지 않겠다\u0026quot;는 서명을 하고 가라고 했다. 결국 병동에 입원. 4일간 입원했다.\n이때의 경험은 지금 돌이켜 봐도 힘들다.\n기본적으로 낙후된 인도네시아 의료 시설에 대한 불신. 의사소통도 어렵다. 아이가 응급실에 있는데 비가 쏟아지면서 천장이 무너져 내렸다. 굉음과 함께 천장 조명이 떨어지고, 놀라서 아이를 안고 뛰쳐나온 직후 천장이 내려앉았다. 그 지역에서 제일 좋다는 병원에서 벌어진 일이다. 응급실 한 번 방문에 검사비 포함 약 50만 원. 총 의료비 300만 원 이상. 여행자 보험 가입은 필수다. 반드시 보장 내용을 꼼꼼히 확인하고, 의료비 보장 한도가 충분한 상품으로 들어야 한다. 그리고 솔직히 말하면, 이 경험 이후 **\u0026ldquo;뭘 위해 여기 있어야 하나\u0026rdquo;**라는 생각이 머리에서 떠나지 않았다.\n아이와의 일상: 기대와 현실 # 할 것이 없다 # 한국에서 아이와 하는 일상을 떠올려 보자. 책 읽어주기, 산책, 놀이터, 키즈카페, 장난감 놀이, 주말 캠핑. 발리에서는 이것 중 거의 아무것도 할 수 없다.\n책이 없다. 한글 동화책을 한 보따리 가져가지 않는 한, 읽어줄 책이 없다. 산책이 불가능하다. 발리에는 인도(보도)가 거의 없다. \u0026ldquo;3발자국 이상 걸으려면 오토바이를 불러야 한다\u0026quot;는 말이 과장이 아니다. 강렬한 햇빛 아래 매연을 맞으며 걷다 보면 오토바이에 발이 깔릴 것 같은 공포를 느낀다. 아이와 산책은 상상도 못 한다. 놀이터가 거의 없다. 한국처럼 아파트 단지마다 놀이터가 있는 환경이 아니다. 법적으로도 의무 시설이 아닌 듯하다. 아주 가끔 하나씩 보이는데, 시설 수준이 한국에 비해 현저히 떨어진다. 실내 놀이 환경이 없다. 집에는 익숙한 장난감이 있지만 여기에는 없다. 결국 한국에서는 안 보여줬던 유튜브를 보여주게 된다. 이것이 현실이다.\n기대했던 유치원 # 발리에 호주 교민이 많다 보니 영어 기반 유치원이 잘 되어 있다. 아이에게 영어 환경을 경험시켜 줄 수 있을 거라는 기대가 컸다.\n하지만 아이의 성향을 간과했다. 우리 아이는 소극적이고, 먼저 다가가는 성격이 아니다. 원생 대부분이 영어를 쓰는 환경에서 2주 동안 혼자 노는 아이를 지켜봐야 했다. 결국 유치원을 그만 보내기로 했다. 기대가 컸던 만큼 실망도 컸다.\n아이의 성향에 따라 경험이 완전히 달라진다. 사교적이고 적응이 빠른 아이라면 좋은 경험이 될 수도 있겠지만, 모든 아이가 그런 것은 아니다. 아이의 성격을 냉정하게 고려해야 한다.\n나의 일상: Vacation이 아니라 Workation이다 # 없던 시간이 생겨나지 않는다 # 한국에서의 일상을 돌아보자. 부지런한 성격은 아니다. 아침에 일어나서 아이 밥 먹이고 유치원 보내고, 일하다가, 퇴근하면 아이와 놀아주고, 아이가 잠들면 짧으면 한 시간, 길면 두 시간의 자유 시간. 유튜브 보거나 밀린 일 하거나 운동하거나.\n발리라고 해서 없던 시간이 생겨나지 않는다. 하루에 내 시간이 한 시간인 사람이 장소를 옮겼다고 갑자기 세 시간이 되지 않는다. 오히려 출퇴근 시간이 늘어났다.\n인터넷: VPN의 벽 # 집에서 일하는 것은 사실상 불가능했다. 인터넷 속도가 느리고, 정전이 잦고, 인터넷이 수시로 끊긴다.\n코워킹 스페이스는 다르다. 좋은 코워킹 스페이스는 UPS와 자체 발전기를 갖추고 있고, 여러 ISP와 계약해서 한쪽이 끊겨도 다른 회선으로 유지된다. 회사에서 제시한 최저 인터넷 속도를 대부분 만족한다.\n문제는 VPN이다. 회사 보안 정책상 VPN을 켜고 일해야 하는데, VPN을 켜는 순간 인터넷 속도가 원래의 10~20% 수준으로 떨어진다. VPN을 켜도 원활하게 일할 수 있는 코워킹 스페이스는 발리 전체에 몇 개 안 된다. 그런 곳은 하루 이용료가 2만 원 정도로 비싸고, 숙소에서 가깝지도 않다.\n저녁 시간의 현실 # 퇴근 후 밤 시간. 서핑이나 야외 액티비티는 불가능한 시간이다. 유럽처럼 거리에서 뮤지션이 공연하는 문화도 아니다. 현실적으로 할 수 있는 것은 괜찮은 음식점이나 바에서 맛있는 것을 먹고 술 한 잔 하는 정도다.\n그런데 이것도 녹록지 않다.\n술 문화가 발달하지 않았다. 이슬람 국가라는 배경 때문인지, 크래프트 비어는 로컬 브루어리 2~3곳이 전부이고, 해외 크래프트 비어는 아예 없다. 증류주는 비싸고, 와인은 수입산이라 종류가 한정적이고 가격이 높다. 괜찮은 곳은 한국만큼 비싸다. 음료를 따로 시키고, 세금이 15~20% 붙는다. 매일 괜찮은 곳에서 먹기에는 통장 잔고가 부담스럽다. 저렴한 곳에서 먹다 보면, 남의 나라까지 와서 왜 이 고생을 하고 있나 하는 생각이 든다. 도착한 지 2주 만에 통장 잔고가 급격히 줄어드는 것을 목격했다.\n그래도 좋았던 것 # 부정적인 이야기만 한 것 같아서, 좋았던 것도 솔직하게 적는다.\n코워킹 스페이스 # 발리의 코워킹 스페이스 문화는 확실히 인상적이다. PC방 같기도 하고, 도서관 같기도 하고, 카페 같기도 한 공간. 여기는 이런 분위기구나, 저기는 이런 메뉴가 맛있네, 하면서 코워킹 스페이스를 구경하는 것 자체가 재미있는 경험이었다. 전 세계에서 온 디지털 노마드들과 같은 공간에서 일하는 느낌도 나쁘지 않았다.\n비치클럽 # 뒤에는 수영장, 앞에는 바다. 음악과 맛있는 음식. 발리의 비치클럽은 확실히 특별한 경험이다. 젊은이들이 즐기는 모습을 구경하는 것만으로도 활력이 되었다.\n주말 # 주말에는 비로소 내가 발리에 놀러 온 것 같았다. 투어도 하고, 비치클럽도 가고, 서핑도 한다. 평일에는 느낄 수 없었던 발리의 매력이 주말에 몰아서 찾아온다. 역설적이지만 이것이 \u0026ldquo;워케이션\u0026quot;이라는 단어의 정확한 의미였다. work과 vacation이 동시에 오는 게 아니라, 번갈아 오는 것이다.\n정리: 발리 리모트 근무, 누구에게 맞는가 # 한 달간의 경험을 정리하면, 발리 리모트 근무의 만족도는 라이프 스타일에 따라 극명하게 갈린다.\n조건 만족도 이유 미혼 or 커플 (아이 없음) 높음 액티비티, 자유 시간, 유연한 일정 아이가 있는 가정 낮음 위생 리스크, 할 것 없음, 시간 부족 VPN 불필요한 업무 높음 코워킹 스페이스 활용 자유로움 VPN 필수 업무 보통 코워킹 스페이스 선택지 제한 넉넉한 예산 높음 좋은 숙소 + 좋은 음식 = 좋은 경험 빠듯한 예산 낮음 저렴한 곳 전전하다 지침 가기 전에 체크할 것 # 아이가 있는 가정이 그래도 가겠다면:\n여행자 보험: 의료비 보장 한도를 반드시 확인. 응급실 한 번에 50만 원이 나올 수 있다. 장티푸스 예방접종: 출국 최소 2주 전에 접종. 숙소: 빌라보다 호텔이나 서비스드 레지던스. 위생과 관리가 다르다. VPN 테스트: 회사 VPN을 켠 상태에서 일할 수 있는 코워킹 스페이스를 사전에 조사. 아이 준비물: 한글 책, 장난감, 태블릿에 오프라인 콘텐츠 다운로드. 유치원: 아이 성향을 냉정하게 판단. 소극적인 아이에게 영어 유치원은 스트레스가 될 수 있다. 예산: 한국에서의 생활비 + 30~50% 여유를 잡아야 한다. 발리가 저렴하다는 것은 로컬 음식과 로컬 숙소 기준이다. 한국인이 만족할 수준의 생활을 하려면 한국과 비슷하거나 더 들 수 있다. 마치며 # 돌아와서 생각해 보면, 발리 리모트 근무에서 가장 크게 느낀 것은 이것이다.\n장소를 바꾼다고 삶이 바뀌지 않는다. 하루에 자유 시간이 한 시간인 사람은 발리에서도 한 시간이다. 아이를 돌봐야 하는 부모는 발리에서도 아이를 돌봐야 한다. 거기에 위생 리스크, 의료 불안, 인프라 불편까지 더해진다.\n그럼에도 불구하고 이 경험을 후회하지는 않는다. 해보지 않았으면 계속 궁금했을 것이고, 발리에 대한 막연한 환상을 품고 살았을 것이다. 환상을 현실로 확인한 것 자체가 가치 있었다.\n다만, 같은 조건(어린 아이 동반)으로 다시 해외 리모트 근무를 한다면 발리는 아닐 것이다. 의료 인프라가 탄탄하고, 아이와 산책할 수 있는 도시. 보도가 있고, 놀이터가 있고, 수돗물을 믿을 수 있는 곳. 일상의 기본이 갖춰진 도시에서의 워케이션이 진짜 워케이션이다.\n","date":"February 23, 2026","externalUrl":null,"permalink":"/my-tech-blog/ko/posts/bali-remote-work-with-family/","section":"글 목록","summary":"서핑, 자연, 디지털 노마드의 성지 발리. 아이를 데리고 한 달간 리모트 근무를 했다. 기대했던 것과 실제 경험 사이의 간극을 솔직하게 기록한다.","title":"발리 리모트 근무 후기: 아이와 함께한 한 달, 솔직한 기록","type":"posts"},{"content":" Hi, I\u0026rsquo;m OTL # I\u0026rsquo;m a data engineer focused on building reliable, scalable data infrastructure and pipelines. I enjoy solving the challenges that come with moving, transforming, and serving data at scale.\nAbout This Blog # This blog is a place where I share practical data engineering knowledge \u0026ndash; lessons learned from real-world projects, tutorials, architecture decisions, and tips that I hope will be useful to fellow engineers working in the data space.\nTech Stack # Here are the core technologies I work with on a daily basis:\nStream Processing: Apache Kafka Workflow Orchestration: Apache Airflow Query Engines: Trino, StarRocks Container Orchestration: Kubernetes Languages: Python, SQL Infrastructure: Docker Contact # Email: nanta0032@naver.com Feel free to reach out if you have questions, suggestions, or just want to connect!\n","externalUrl":null,"permalink":"/my-tech-blog/about/","section":"OTL - Data Engineering","summary":"About me and this blog","title":"About","type":"page"},{"content":" Who We Are # This blog is operated by OTL. The site address is https://nhosw.github.io/my-tech-blog/.\nWhat Data We Collect # Google Analytics # This site uses Google Analytics 4 (GA4) to understand how visitors use the site. GA4 collects:\nPages you visit and how long you stay Your approximate location (country/city level) Device type, browser, and operating system Referral source (how you found this site) Google Analytics uses cookies to distinguish unique visitors. No personally identifiable information is intentionally collected.\nFor more information, see Google\u0026rsquo;s Privacy Policy.\nGoogle AdSense # This site may display advertisements through Google AdSense. AdSense may use cookies and web beacons to serve ads based on your prior visits to this and other websites.\nGoogle uses the DART cookie to serve ads based on your browsing history You may opt out of personalized advertising by visiting Google Ads Settings For more information, see Google AdSense Privacy Policy.\nComments # This site does not currently have a comment system. If one is added in the future, this policy will be updated.\nCookies # Cookies are small text files stored on your device. This site uses cookies for:\nAnalytics: To measure site traffic (Google Analytics) Advertising: To serve relevant ads (Google AdSense) Preferences: To remember your theme preference (dark/light mode) You can control cookies through your browser settings. Disabling cookies may affect site functionality.\nThird-Party Links # Blog posts may contain links to external websites. We are not responsible for the privacy practices of other sites.\nYour Rights # You have the right to:\nKnow what data is being collected Opt out of tracking (via browser settings or Google Ads Settings) Request information about your data Changes to This Policy # This privacy policy may be updated from time to time. Changes will be posted on this page.\nContact # If you have questions about this privacy policy, please contact us via the information on the About page.\nLast updated: February 23, 2026\n","externalUrl":null,"permalink":"/my-tech-blog/privacy-policy/","section":"OTL - Data Engineering","summary":"Privacy Policy","title":"Privacy Policy","type":"page"}]