[{"content":"Background If you run data pipelines long enough, you inevitably face one question: How do you build real-time dashboards?\nOur team was no different. Our existing pipeline looked like this:\nService → Kafka → Iceberg → S3 → Trino → Airflow(5min) → Dashboard On the surface it worked fine, but the pain points in practice were clear:\nAt least 5 minutes of latency: The Airflow schedule interval was the bottleneck Pipeline complexity: Managing 5+ components chained as Kafka → Flink → Redis → API → Dashboard Redundant I/O: Trino full-scanned S3 on every query High development cost: Each new real-time dashboard took roughly 2 weeks to build After adopting StarRocks, the architecture simplified to this:\nService → Kafka → StarRocks → Dashboard (sub-second latency) Eliminating the intermediate components dramatically simplified the pipeline, and ingesting data directly from Kafka into StarRocks gave us the real-time capability we needed.\nResults After approximately 3 months of PoC and 6 months of phased rollout, we achieved the following improvements:\nMetric Before After Improvement Dashboard latency 5 min \u0026lt; 1 sec ~300x Dashboard dev time ~2 weeks ~1 week 50% reduction Pipeline components 5+ 2 60% reduction Query response time 30~50 sec 5~10 sec 5~10x Hardware cost 128 GB x 18 nodes 64 GB x 3 nodes ~75% savings Trino is fast in terms of raw query time, but when factoring in Airflow schedule delays and end-to-end latency, along with hardware cost efficiency, StarRocks proved to be a better fit for real-time workloads.\nTable Model Selection Guide Choosing the right table model is the most important decision when first adopting StarRocks. A wrong choice means you will have to recreate the table later.\nDecision Flow ┌─────────────────────────────┐ │ What data are you storing? │ └──────────────┬──────────────┘ │ ┌───────▼────────┐ │ Need UPDATE? │ └───────┬────────┘ │ ┌────────┴────────┐ │ │ [No] [Yes] │ │ ┌─────▼─────┐ ┌─────▼──────┐ │ Need │ │ Primary Key │ │aggregation?│ │ (frequent │ └─────┬─────┘ │ UPDATE) │ │ └────────────┘ [No] [Yes] │ │ ┌─────▼───┐ ┌▼──────────┐ │Duplicate│ │Aggregate │ │(raw data)│ │(auto-agg) ★│ └─────────┘ └────────────┘ Model Comparison Model Duplicates Allowed UPDATE Auto-aggregation Best For Duplicate Key O X X Logs, raw events Aggregate Key X Auto O Real-time statistics ★ Primary Key X O (fast) X Frequent UPDATEs Duplicate Key: Storing Raw Data Use this when you need to preserve original data as-is, such as click logs, API events, or sensor data.\nCREATE TABLE order_events ( event_id BIGINT, event_time DATETIME, order_id VARCHAR(50), user_id BIGINT, event_type VARCHAR(20), amount DECIMAL(10, 2) ) DUPLICATE KEY(event_id, event_time) PARTITION BY date_trunc(\u0026#39;day\u0026#39;, event_time) DISTRIBUTED BY HASH(event_id) BUCKETS 10; Aggregate Key: Real-time Statistics ★ Data is automatically aggregated at ingestion time. This model was the key reason for adopting StarRocks.\nCREATE TABLE order_stats ( stat_time DATETIME NOT NULL COMMENT \u0026#39;5-minute intervals\u0026#39;, region VARCHAR(20) NOT NULL, delivery_type VARCHAR(20) NOT NULL, -- Aggregate columns: aggregate functions applied automatically at ingestion order_count BIGINT SUM DEFAULT \u0026#34;0\u0026#34;, total_amount DECIMAL(15, 2) SUM DEFAULT \u0026#34;0\u0026#34;, user_bitmap BITMAP BITMAP_UNION, max_amount DECIMAL(10, 2) MAX ) AGGREGATE KEY(stat_time, region, delivery_type) PARTITION BY date_trunc(\u0026#39;day\u0026#39;, stat_time) DISTRIBUTED BY HASH(stat_time) BUCKETS 10; Available aggregate functions:\nFunction Purpose Example SUM Summation Order count, total revenue MAX / MIN Maximum / minimum value Highest price, lowest price REPLACE Overwrite with latest value Latest status BITMAP_UNION Exact unique count Unique visitors HLL_UNION Approximate unique count High-cardinality sets Unlike HyperLogLog, BITMAP_UNION provides exact unique counts. For business KPI dashboards where accuracy matters, always use this approach.\nPrimary Key: Frequent UPDATEs Best suited for scenarios where the same key is frequently updated, such as order status tracking or inventory management.\nCREATE TABLE orders ( order_id VARCHAR(50) NOT NULL, status VARCHAR(20), amount DECIMAL(10, 2), updated_at DATETIME ) PRIMARY KEY(order_id) DISTRIBUTED BY HASH(order_id) BUCKETS 10 PROPERTIES ( \u0026#34;enable_persistent_index\u0026#34; = \u0026#34;true\u0026#34; ); Enabling enable_persistent_index significantly improves UPDATE performance.\nData Ingestion Routine Load: Real-time Kafka Integration This approach continuously ingests data from a Kafka topic. It is the method used in most real-time pipelines.\nCREATE ROUTINE LOAD order_load ON orders COLUMNS( order_id, user_id, timestamp_ms, amount, order_date = FROM_UNIXTIME(timestamp_ms / 1000) ) PROPERTIES ( \u0026#34;format\u0026#34; = \u0026#34;json\u0026#34;, \u0026#34;jsonpaths\u0026#34; = \u0026#34;[\\\u0026#34;$.orderId\\\u0026#34;,\\\u0026#34;$.userId\\\u0026#34;,\\\u0026#34;$.timestamp\\\u0026#34;,\\\u0026#34;$.amount\\\u0026#34;]\u0026#34; ) FROM KAFKA ( \u0026#34;kafka_broker_list\u0026#34; = \u0026#34;kafka-broker:9092\u0026#34;, \u0026#34;kafka_topic\u0026#34; = \u0026#34;orders\u0026#34; ); When combined with an Aggregate Key table, transformation and aggregation happen simultaneously at ingestion time.\nCREATE ROUTINE LOAD order_stats_load ON order_stats COLUMNS( timestamp_ms, region, amount, user_id, -- Round to 5-minute intervals stat_time = FROM_UNIXTIME(FLOOR(timestamp_ms / 1000 / 300) * 300), order_count = 1, total_amount = amount, user_bitmap = BITMAP_HASH(user_id) ) WHERE amount \u0026gt; 0 PROPERTIES (\u0026#34;format\u0026#34; = \u0026#34;json\u0026#34;) FROM KAFKA ( \u0026#34;kafka_broker_list\u0026#34; = \u0026#34;kafka-broker:9092\u0026#34;, \u0026#34;kafka_topic\u0026#34; = \u0026#34;orders\u0026#34; ); This single pattern replaced the aggregation logic that previously required Flink \u0026ndash; using nothing but SQL.\nStream Load: Bulk Data Loading Ideal for one-time bulk loads via files or APIs.\n# CSV file loading curl --location-trusted \\ -u user:password \\ -H \u0026#34;label:load_$(date +%Y%m%d%H%M%S)\u0026#34; \\ -H \u0026#34;column_separator:,\u0026#34; \\ -T data.csv \\ http://starrocks-fe:8030/api/mydb/mytable/_stream_load Performance Tuning Tips Thread Pool Configuration In high-load environments with 500+ RPS of concurrent connections, the default thread pool size is insufficient.\n# be.conf pipeline_scan_thread_pool_thread_num = 32 # default: 24 pipeline_exec_thread_pool_thread_num = 32 # default: 24 Bucket Count Guidelines Data Size Recommended Buckets \u0026lt; 10 GB 10 10~50 GB 20 50~100 GB 30 \u0026gt; 100 GB 50+ Formula: buckets = max(1, data_size_GB / 10)\nPartitioning Strategy Applying functions to partition columns prevents partition pruning. This is a more common mistake than you might think.\n-- ✅ Correct: partition pruning works WHERE event_time \u0026gt;= NOW() - INTERVAL 3 DAY -- ❌ Incorrect: partition pruning disabled WHERE DATE(event_time) \u0026gt;= CURRENT_DATE - 3 TTL Configuration To automatically drop old partitions, configure TTL.\nPROPERTIES ( \u0026#34;partition_live_number\u0026#34; = \u0026#34;3\u0026#34; -- Keep only the 3 most recent partitions ) Operational Know-how Materialized View Management ASYNC refresh can stop without warning. Periodically check the status and manually recover when issues arise.\n-- Check status SHOW MATERIALIZED VIEWS; -- Force synchronous refresh REFRESH MATERIALIZED VIEW db.mv_name WITH SYNC MODE; -- Reactivate a deactivated MV ALTER MATERIALIZED VIEW db.mv_name ACTIVE; Routine Load Monitoring The status frequently transitions to PAUSED. Common causes include Kafka offset issues or malformed messages.\n-- Check status SHOW ROUTINE LOAD FOR db.load_job; -- Resume RESUME ROUTINE LOAD FOR db.load_job; Scale-in Precautions When scaling down nodes, you must perform a Decommission first. Removing nodes without this procedure will result in data loss.\n-- 1. Check current nodes SHOW PROC \u0026#39;/backends\u0026#39;; -- 2. Start decommission ALTER SYSTEM DECOMMISSION BACKEND \u0026#34;\u0026lt;BE_IP\u0026gt;:\u0026lt;HEARTBEAT_PORT\u0026gt;\u0026#34;; -- 3. Wait until TabletNum reaches 0, then remove ALTER SYSTEM DROP BACKEND \u0026#34;\u0026lt;BE_IP\u0026gt;:\u0026lt;HEARTBEAT_PORT\u0026gt;\u0026#34;; Things to Know Before Adopting Known Limitations Issue Description Workaround Routine Load Limited handling of malformed messages Pre-validate on the Kafka side datetime partitions Compatibility issues with Iceberg datetime partitions Use an alternative partitioning strategy Version upgrades Encountered bugs in 4.x releases Always test in a staging environment Always thoroughly validate version upgrades in a staging environment before applying them to production. We went through several rounds of upgrades and rollbacks ourselves. Have a rollback plan ready at all times.\nAdoption Checklist Pre-deployment\nDefine use cases and requirements Estimate data volume and growth rate Choose table models Design partitioning strategy Post-deployment\nCreate and verify Routine Load jobs Configure user permissions Set data retention policies (TTL) Document scale-in/out procedures Build monitoring dashboards Conclusion Here are the key lessons we learned from adopting StarRocks:\nThe Aggregate Key model is the centerpiece \u0026ndash; Automatic aggregation at ingestion time optimizes both storage and query performance Use BITMAP_UNION for exact unique counts \u0026ndash; Business KPIs demand precise numbers, not approximations Routine Load + Aggregate Key replaces Flink \u0026ndash; You can build a real-time aggregation pipeline with SQL alone Invest in operational automation \u0026ndash; Monitoring Materialized Views and Routine Load is essential For real-time analytics workloads, StarRocks is a powerful option that dramatically reduces pipeline complexity. That said, it is still maturing in terms of version upgrade stability and operational robustness, so we recommend conducting thorough PoC testing and staging validation before adopting it.\nReference: StarRocks Official Docs\n","permalink":"https://NhoSW.github.io/my-tech-blog/posts/starrocks-adoption-guide/","summary":"How we reduced pipeline latency from 5 minutes to sub-second by adopting StarRocks. Covers table model selection, data ingestion, performance tuning, and operational lessons from production.","title":"StarRocks Adoption Story: Revolutionizing Data Pipelines with Real-time OLAP"},{"content":"Why Compression Settings Matter When you operate StarRocks long enough, there will inevitably come a point where your data grows to tens of terabytes. I have seen, time and again, cases where a single compression setting made a 30 to 50 percent difference in storage costs. But this is not just about disk space. Higher compression ratios reduce disk I/O and improve scan performance, while overly aggressive compression burns CPU and increases latency. Ultimately, choosing the right compression algorithm for your workload is one of the most important tuning decisions in StarRocks operations.\nComparing Supported Compression Algorithms StarRocks supports several compression algorithms. Here is a comparison of the three most commonly used in practice.\nAlgorithm Compression Ratio Compression Speed Decompression Speed Best-fit Workload LZ4 Moderate (2-3x) Very fast Very fast Real-time analytics, low-latency queries ZSTD High (4-6x) Moderate Fast Batch analytics, cold data Snappy Low (1.5-2x) Fast Fast General purpose, legacy compatibility ZLIB High (4-5x) Slow Moderate Archiving, infrequently accessed data Personally, the combination I use most often is LZ4 for hot data and ZSTD for cold data. I occasionally use Snappy when dealing with data migrated from the Hadoop ecosystem, but I do not recommend it for new tables.\nSetting Compression When Creating a Table You can specify the compression algorithm via the compression property in PROPERTIES when creating a table. If no value is set, StarRocks defaults to LZ4.\nReal-time Analytics Table (LZ4) CREATE TABLE analytics.realtime_events ( event_id BIGINT, user_id BIGINT, event_type VARCHAR(64), event_time DATETIME, properties JSON ) ENGINE = OLAP DUPLICATE KEY(event_id) DISTRIBUTED BY HASH(user_id) BUCKETS 32 PROPERTIES ( \u0026#34;replication_num\u0026#34; = \u0026#34;3\u0026#34;, \u0026#34;compression\u0026#34; = \u0026#34;LZ4\u0026#34; ); LZ4 has overwhelmingly fast decompression speed, making it ideal for tables that need to serve dashboard queries with sub-second response times.\nBatch Analytics Table (ZSTD) CREATE TABLE warehouse.order_history ( order_id BIGINT, customer_id BIGINT, order_date DATE, total_amount DECIMAL(18, 2), status VARCHAR(32), items ARRAY\u0026lt;STRUCT\u0026lt;sku STRING, qty INT, price DECIMAL(10,2)\u0026gt;\u0026gt; ) ENGINE = OLAP DUPLICATE KEY(order_id) PARTITION BY RANGE(order_date) ( PARTITION p2025 VALUES LESS THAN (\u0026#39;2026-01-01\u0026#39;), PARTITION p2026 VALUES LESS THAN (\u0026#39;2027-01-01\u0026#39;) ) DISTRIBUTED BY HASH(customer_id) BUCKETS 16 PROPERTIES ( \u0026#34;replication_num\u0026#34; = \u0026#34;2\u0026#34;, \u0026#34;compression\u0026#34; = \u0026#34;ZSTD\u0026#34; ); ZSTD achieves 1.5 to 2 times higher compression ratios than LZ4, which translates into significant storage savings on history tables where hundreds of millions of rows accumulate per partition.\nChanging Compression on an Existing Table If you want to change the compression algorithm on a table that is already in production, you can use ALTER TABLE. Keep in mind, however, that the new setting only applies to data loaded after the change. Existing segments will not be recompressed until a compaction cycle runs against them.\nALTER TABLE warehouse.order_history SET (\u0026#34;compression\u0026#34; = \u0026#34;ZSTD\u0026#34;); Recommended Compression Settings by Workload The following recommendations are based on patterns I have validated repeatedly in production environments.\nReal-time dashboards / Ad-hoc queries: Use LZ4. Its CPU overhead is negligible, minimizing the impact on P99 latency. Nightly batch reports / ETL result tables: Use ZSTD. When query frequency is low and data volume is high, the storage savings translate directly into cost reductions. High-volume log ingestion: Use ZSTD, but lower zstd_compression_level to 3 or below. This strikes a good balance between compression speed and compression ratio. Benchmark Results: Compression Ratio vs. Performance Tradeoffs The following benchmark was run against an event log table containing approximately 5 billion rows (roughly 800 GB uncompressed).\nMetric LZ4 ZSTD (level 3) ZSTD (level 9) Compressed size 320 GB 195 GB 170 GB Compression ratio 2.5x 4.1x 4.7x Simple scan query (Avg) 1.2 s 1.5 s 1.8 s Aggregation query (Avg) 3.4 s 3.8 s 4.5 s Data ingestion throughput 120 MB/s 95 MB/s 60 MB/s Compared to LZ4, ZSTD level 3 reduced storage by approximately 39% while only increasing query latency by about 10 to 15 percent. ZSTD level 9, on the other hand, offered diminishing compression gains at the cost of a steep drop in ingestion throughput, making level 3 the optimal choice in most environments.\nOperational Tips and Monitoring Here are three tips from production experience:\nAlways monitor compaction. Keep an eye on the compaction_score metric. When compression settings change or data volumes spike, compaction can fall behind, leading to degraded query performance from an excessive number of small segments. Separate compression strategies at the table level. Do not apply a single compression algorithm across your entire cluster. Match the algorithm to each table\u0026rsquo;s access pattern \u0026ndash; LZ4 for frequently queried tables, ZSTD for archival ones. Track disk usage trends over time. Use SHOW DATA to monitor how each table\u0026rsquo;s storage footprint evolves after compression changes. SHOW DATA FROM warehouse.order_history; Compression is not a set-it-and-forget-it decision. As data volumes grow and query patterns shift, it is worth revisiting your compression settings periodically. Even a small adjustment can yield meaningful improvements in both performance and infrastructure costs over time.\n","permalink":"https://NhoSW.github.io/my-tech-blog/posts/starrocks-compression-guide/","summary":"A practical guide to optimizing compression settings in StarRocks. Covers algorithm comparison, per-workload recommendations, benchmark results, and operational tips from production experience.","title":"StarRocks Compression Guide: Optimizing Performance and Storage"},{"content":"Hi, I\u0026rsquo;m Seungwoo Noh I\u0026rsquo;m a data engineer focused on building reliable, scalable data infrastructure and pipelines. I enjoy solving the challenges that come with moving, transforming, and serving data at scale.\nAbout This Blog This blog is a place where I share practical data engineering knowledge \u0026ndash; lessons learned from real-world projects, tutorials, architecture decisions, and tips that I hope will be useful to fellow engineers working in the data space.\nTech Stack Here are the core technologies I work with on a daily basis:\nStream Processing: Apache Kafka Workflow Orchestration: Apache Airflow Query Engines: Trino, StarRocks Container Orchestration: Kubernetes Languages: Python, SQL Infrastructure: Docker Contact GitHub: github.com/your-username LinkedIn: linkedin.com/in/your-profile Email: your-email@example.com Feel free to reach out if you have questions, suggestions, or just want to connect!\n","permalink":"https://NhoSW.github.io/my-tech-blog/about/","summary":"About me and this blog","title":"About"},{"content":"Who We Are This blog is operated by Seungwoo Noh. The site address is https://nhosw.github.io/my-tech-blog/.\nWhat Data We Collect Google Analytics This site uses Google Analytics 4 (GA4) to understand how visitors use the site. GA4 collects:\nPages you visit and how long you stay Your approximate location (country/city level) Device type, browser, and operating system Referral source (how you found this site) Google Analytics uses cookies to distinguish unique visitors. No personally identifiable information is intentionally collected.\nFor more information, see Google\u0026rsquo;s Privacy Policy.\nGoogle AdSense This site may display advertisements through Google AdSense. AdSense may use cookies and web beacons to serve ads based on your prior visits to this and other websites.\nGoogle uses the DART cookie to serve ads based on your browsing history You may opt out of personalized advertising by visiting Google Ads Settings For more information, see Google AdSense Privacy Policy.\nComments This site does not currently have a comment system. If one is added in the future, this policy will be updated.\nCookies Cookies are small text files stored on your device. This site uses cookies for:\nAnalytics: To measure site traffic (Google Analytics) Advertising: To serve relevant ads (Google AdSense) Preferences: To remember your theme preference (dark/light mode) You can control cookies through your browser settings. Disabling cookies may affect site functionality.\nThird-Party Links Blog posts may contain links to external websites. We are not responsible for the privacy practices of other sites.\nYour Rights You have the right to:\nKnow what data is being collected Opt out of tracking (via browser settings or Google Ads Settings) Request information about your data Changes to This Policy This privacy policy may be updated from time to time. Changes will be posted on this page.\nContact If you have questions about this privacy policy, please contact us via the information on the About page.\nLast updated: February 23, 2026\n","permalink":"https://NhoSW.github.io/my-tech-blog/privacy-policy/","summary":"Privacy Policy","title":"Privacy Policy"}]