[{"content":"","date":"2026년 2월 27일","externalUrl":null,"permalink":"/tags/alluxio/","section":"Tags","summary":"","title":"Alluxio","type":"tags"},{"content":"","date":"2026년 2월 27일","externalUrl":null,"permalink":"/tags/cache/","section":"Tags","summary":"","title":"Cache","type":"tags"},{"content":"","date":"2026년 2월 27일","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"2026년 2월 27일","externalUrl":null,"permalink":"/categories/data-engineering/","section":"Categories","summary":"","title":"Data Engineering","type":"categories"},{"content":"","date":"2026년 2월 27일","externalUrl":null,"permalink":"/tags/ebs/","section":"Tags","summary":"","title":"Ebs","type":"tags"},{"content":"","date":"2026년 2월 27일","externalUrl":null,"permalink":"/tags/kubernetes/","section":"Tags","summary":"","title":"Kubernetes","type":"tags"},{"content":"","date":"2026년 2월 27일","externalUrl":null,"permalink":"/","section":"nanta - 데이터 엔지니어링","summary":"","title":"nanta - 데이터 엔지니어링","type":"page"},{"content":"","date":"2026년 2월 27일","externalUrl":null,"permalink":"/tags/performance/","section":"Tags","summary":"","title":"Performance","type":"tags"},{"content":"","date":"2026년 2월 27일","externalUrl":null,"permalink":"/tags/s3/","section":"Tags","summary":"","title":"S3","type":"tags"},{"content":"","date":"2026년 2월 27일","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"2026년 2월 27일","externalUrl":null,"permalink":"/tags/trino/","section":"Tags","summary":"","title":"Trino","type":"tags"},{"content":"OLAP 환경에서 Trino를 메인 쿼리 엔진으로 쓰고 있었다. ClickHouse 도입을 검토하던 중 기술 스택 단일화 측면에서 Trino를 개선하는 게 낫겠다는 판단이 섰다. 그래서 Trino 버전을 v433에서 v451로 올렸다. 주목적은 Alluxio 기반 캐시 기능 활용이었다.\n이전에 쓰던 Rubix 캐시는 deprecated 상태였고 Alluxio 캐시는 v439에서 추가된 뒤 v445에서 race condition 버그가 수정되면서 쓸 만한 상태가 됐다.\n이 글은 Blue/Green 배포 환경에서 Alluxio 캐시를 PoC한 과정과 그 과정에서 마주친 병목을 정리한 기록이다.\nAlluxio 캐시가 뭔가 # Trino가 S3에서 데이터를 읽을 때마다 네트워크를 타야 한다. 같은 파일을 여러 번 읽어도 매번 S3 API를 호출한다. Alluxio 캐시는 한 번 읽은 데이터를 워커 노드의 로컬 디스크에 저장해서 두 번째부터는 로컬에서 읽는 방식이다.\n카탈로그 설정에 몇 줄 추가하면 동작한다.\nfs.cache.enabled=true fs.cache.max-sizes=50GB fs.cache.directories=/mnt/cache Hive, Iceberg, Delta Lake 커넥터에서 사용할 수 있다. 우리는 hive_zeppelin과 iceberg 두 카탈로그에 적용했다.\n제약사항 # PoC를 시작하기 전에 알아둬야 할 제약이 있었다.\n캐시가 카탈로그/클러스터 간에 공유되지 않는다 # 같은 S3 버킷을 바라보는 카탈로그가 여럿 있어도 캐시는 각 카탈로그별로 따로 관리된다. 커넥터 구조상 파일 시스템을 카탈로그마다 독립적으로 인스턴스화하기 때문이다. 클러스터 간 공유는 당연히 안 된다.\n이 문제를 해결하려는 네이티브 Alluxio 파일 시스템 PR이 2024년 9월에 머지됐다(Trino 460). 카탈로그 간, 클러스터 간 캐시 공유가 가능해진다. 다만 공유 캐시 파일 시스템 접근이 S3 직접 접근보다 빠를지는 별도 검증이 필요하다.\n스팟 인스턴스와 캐시는 궁합이 안 맞다 # 워커의 캐시 데이터 생애주기는 해당 워커 노드의 생애주기와 같다. 노드가 사라지면 캐시도 증발한다.\n문제는 우리 환경이 거의 99% 스팟 노드라는 거다. 스팟 회수가 일어나면 해당 워커의 캐시가 통째로 날아간다. 오토스케일링으로 스케일인될 때도 마찬가지다. 캐시 웜업에 시간이 걸리는데 노드가 자주 바뀌면 웜업 효과를 보기 어렵다.\n스키마 단위 제어가 안 된다 # 캐시 활성화는 카탈로그 단위로 all-or-nothing이다. temp 스키마처럼 재사용 빈도가 거의 없는 테이블도 전부 캐싱된다. 주요 스키마만 선택적으로 캐싱할 수 있으면 좋겠지만 현재는 지원하지 않는다.\nfs.cache.skip-paths 옵션을 추가하는 PR이 있었지만 설계 방향에 대한 의견 차이로 닫혔다. 파일 경로 기반이 아니라 스키마/테이블 단위로 제어해야 한다는 게 리뷰어의 의견이었다.\nPoC 구성 # Blue/Green 중 한쪽에만 적용 # 비용 문제로 스테이지 환경을 프로덕션과 동일하게 구축하기 어려웠다. 그래서 OLAP과 BI 클러스터의 Blue/Green 중 Blue 클러스터에만 캐시를 적용하고 1~2주간 쿼리 성능 지표를 비교하기로 했다.\n앞단에 Trino Gateway가 있어서 각 백엔드의 현재 쿼리 수를 기준으로 부하를 분산한다. 유입되는 쿼리가 완전히 동일하진 않지만 2주 정도 데이터가 쌓이면 유의미한 비교가 된다고 판단했다.\n볼륨 구성 # 워커 팟과 노드를 1:1로 매핑하는 게 Trino 베스트 프랙티스다. StatefulSet + volumeClaimTemplate으로 팟 단위 볼륨을 구성할 수도 있지만 우리는 노드에 캐시 전용 EBS 볼륨을 마운트하고 워커 팟에서 hostPath로 접근하게 구성했다.\n초기 캐시 볼륨은 워커당 50GB. hive_zeppelin 카탈로그에 60%, iceberg 카탈로그에 30%를 할당했다.\n적용 순서 # OLAP Blue 클러스터에 선적용 (2024-07-30) BI Blue 클러스터에 선적용 (2024-07-31) Grafana에 p25/p50/p75/p99/avg/max 쿼리 수행시간 비교 패널 추가 JMX 메트릭으로 캐시 사용 현황 모니터링 BI 클러스터는 같은 대시보드 내 여러 차트가 동일 테이블의 같은 날짜 범위를 조회하는 경우가 많아서 캐시 효과가 더 클 거라 기대했다.\nEBS 스루풋 병목 # 캐시를 켜고 며칠 지켜봤다. 드라마틱한 차이는 없었다. 캐시 적중률은 괜찮은데 왜 성능 차이가 안 나지?\n캐시 볼륨 메트릭을 까봤더니 원인이 보였다. EBS 쓰기 스루풋이 설정된 최대치인 125MiB/s에 계속 도달하고 있었다. gp3 볼륨의 기본 스루풋이 125MiB/s인데 캐시 쓰기가 이 한도를 꽉 채우고 있던 거다.\n캐시가 아무리 빨라도 디스크 쓰기가 병목이면 소용이 없다.\n스루풋 상향 # gp3에서 설정 가능한 최대 스루풋인 1000MiB/s로 올렸다.\nBI 클러스터: 오후 2시 45분경 적용 OLAP 클러스터: 오후 3시 45분경 적용 결과가 바로 나타났다. 스루풋 상향 후 캐시 적용 클러스터(Blue)의 쿼리 수행 지표가 확실히 좋아졌다. 쓰기 스루풋이 200MiB 정도까지 올라가도 최대치(1000MiB)에는 한참 여유가 있었다. 읽기까지 합치면 대략 300MiB 수준이었다.\ngp3 스루풋만 올리면 됐지 io2 같은 고성능 볼륨 타입은 필요 없었다. io2의 최대 스루풋도 1000MiB/s로 동일하고 높은 IOPS가 필요한 워크로드도 아니었으니까.\n캐시 볼륨 사이징 # 초기 50GB는 금방 꽉 찼다. 허용된 최대 캐시 사이즈(hive 60% + iceberg 30% = 45GB)를 모두 채워 쓰고 있었다. 캐시 공간이 부족하면 오래된 데이터부터 밀려나는데 너무 빨리 밀려나면 캐시 효과가 떨어진다.\n볼륨 사이즈를 키웠다.\n클러스터 변경 전 변경 후 BI 워커 50GB 150GB → 1.5TB OLAP 워커 50GB 2TB OLAP 코디네이터 - 1TB (iceberg 메타데이터 캐시용) 카탈로그별 할당 비율도 실제 사용량을 보고 조정했다. hive가 iceberg보다 캐시를 훨씬 많이 쓰고 있어서 hive 60% → 85%, iceberg 30% → 10%로 재배분했다.\nEBS 스토리지 비용이 걱정됐지만 확인해보니 월 비용이 크지 않았다. 캐시 덕분에 워커 수가 20% 줄어든 효과가 EBS 비용 증가분을 상쇄하고도 남았다.\n필요 이상으로 크게 잡아놓고 Grafana에 각 노드의 캐시 볼륨 사용률 차트를 추가해서 지켜본 뒤 낭비되면 줄이는 방식으로 접근했다.\nFIFO가 LRU보다 나을 수 있다 # Trino의 Alluxio 캐시는 LRU 같은 정교한 교체 알고리즘이 아니라 FIFO 방식으로 동작한다. 가장 먼저 캐시된 데이터를 먼저 내보낸다.\n직관적으로는 LRU가 나아 보이지만 FIFO가 유리한 경우도 있다.\nOne-hit wonder 제거: 한 번만 읽히고 다시 안 읽히는 데이터를 빠르게 밀어낸다. LRU는 최근 접근 시간을 갱신하느라 이런 데이터가 캐시에 더 오래 남을 수 있다. SSD 친화적: FIFO는 랜덤 액세스를 최소화한다. SSD나 플래시 메모리 기반 스토리지에서 쓰기 증폭(write amplification)이 적다. 초기 단계 기능이라 교체 알고리즘이 단순한 건 맞지만 OLAP 워크로드에서 FIFO가 반드시 나쁜 선택은 아니다.\n결과 # 쿼리 성능 # 캐시 활성화 + EBS 스루풋 상향 이후 Blue 클러스터가 Green 대비 일관되게 빠른 경향을 보였다.\n흥미로운 건 Blue가 더 적은 워커로 더 높은 쿼리 스루풋을 기록했다는 점이다. 쿼리를 빨리 처리하니까 앞단 게이트웨이가 더 많은 쿼리를 라우팅해줬고 그 결과 Green보다 워커 수가 20% 적은 상태에서도 처리량이 더 높았다.\n캐시 웜업에는 약 3시간이 걸렸다. 워커가 새로 뜨고 캐시가 충분히 찰 때까지 이 시간이 지나야 성능 차이가 드러났다.\nS3 API 비용 절감 # 캐시 적용 전후로 S3 GetObject 비용이 월 약 440만 원 줄었다. 캐시 적용 외에도 쿼리 수 변동 같은 다른 요인이 영향을 줬을 수 있지만 비용 절감 규모가 꽤 컸다.\n비용 정리 # 항목 변화 S3 API 비용 월 ~440만 원 절감 EBS 스토리지 비용 소폭 증가 (캐시 볼륨) 노드 비용 워커 수 ~20% 감소로 절감 인스턴스 스토어 검토 # EBS는 리모트 블록 스토리지다. S3 직접 접근 대비 캐시 성능 개선이 드라마틱하지 않을 수 있다. 만약 EBS 캐시로 충분한 효과가 없었다면 NVMe SSD 인스턴스 스토어가 달린 노드 타입으로 교체할 계획이었다.\n인스턴스 타입 인스턴스 스토어 r7gd.4xlarge 1 x 950GB NVMe SSD m7gd.8xlarge 1 x 1,900GB NVMe SSD 두 타입의 인스턴스 스토어 크기가 다르지만 Trino의 캐시 설정이 전체 디스크 용량 대비 퍼센트로도 지정할 수 있어서 문제가 되지 않는다. 다만 EBS 스루풋 상향만으로도 충분한 효과를 봤기 때문에 인스턴스 스토어로 교체는 진행하지 않았다.\n같이 알아두면 좋은 것: Project Hummingbird # Trino v451로 올리면서 눈여겨본 게 하나 더 있다. Project Hummingbird라는 성능 개선 프로젝트다.\nJava 22의 Vector API를 활용한 벡터화 연산을 Trino에 적용하는 작업이다. Parquet 파일 읽기에 벡터화 디코딩이 v448부터 반영됐다. 단 256비트 이상 벡터 레지스터가 필요해서 Graviton 2 인스턴스(r6g, m6g)에서는 비활성화된다. Graviton 3 이상이면 자동으로 켜진다.\nTrino가 v447부터 Java 22를 필수로 요구하게 된 것도 이 프로젝트의 일환이다.\n마치며 # Alluxio 캐시 PoC에서 배운 건 단순하다.\n캐시를 붙이는 것만으로는 안 된다. 디스크 I/O가 병목이면 캐시 적중률이 아무리 높아도 체감 성능이 안 나온다. EBS gp3 기본 스루풋 125MiB/s가 캐시 성능의 천장이었다. 1000MiB/s로 올리자마자 차이가 드러났다.\nBI 워크로드에 캐시가 잘 먹힌다. 같은 테이블을 반복 조회하는 대시보드 쿼리는 캐시 히트율이 높다.\n스팟 환경에서 캐시는 타협이 필요하다. 노드가 수시로 바뀌면 캐시 웜업 시간이 사실상 손실이다. 그래도 3시간 웜업 후에는 효과가 나타났으니 완전히 무용한 건 아니다.\n앞으로 네이티브 Alluxio 파일 시스템(Trino 460)이 안정화되면 카탈로그/클러스터 간 캐시 공유가 가능해진다. 스팟 회수 시 캐시 손실 문제도 완화될 수 있을 거다.\n참고 자료:\nA cache refresh for Trino Trino File System Cache Documentation Alluxio cache PR (v439) Cache race condition fix (v445) Cross-catalog cache sharing issue Native Alluxio file system PR (v460) Project Hummingbird Vectorized Parquet decoding PR (v448) ","date":"2026년 2월 27일","externalUrl":null,"permalink":"/posts/trino-alluxio-cache-poc/","section":"글 목록","summary":"Trino의 Alluxio 기반 파일 시스템 캐시를 프로덕션 OLAP 환경에서 PoC했다. 캐시를 붙이기만 하면 빨라질 줄 알았는데 EBS 기본 스루풋 125MiB/s가 병목이었다. 스루풋 상향 후 쿼리 성능이 눈에 띄게 개선됐고 S3 API 비용도 월 440만 원 줄었다.","title":"Trino Alluxio 캐시 PoC: EBS 스루풋이 병목이었다","type":"posts"},{"content":"","date":"2026년 2월 27일","externalUrl":null,"permalink":"/posts/","section":"글 목록","summary":"","title":"글 목록","type":"posts"},{"content":"","date":"2026년 2월 25일","externalUrl":null,"permalink":"/tags/alb/","section":"Tags","summary":"","title":"Alb","type":"tags"},{"content":"클라우드 인프라팀에서 요청이 왔다. 장애 분석할 때 ALB 로그를 테이블로 조회할 수 있게 해달라고.\nALB 로그는 S3에 CSV 형태로 쌓이고 있었다. 필요할 때마다 Athena로 직접 조회했는데 느리고 불편했다. 텍스트 포맷이니 조회 성능에도 한계가 있었다. Iceberg로 Parquet 파일로 변환해서 적재하면 실시간 대시보드까지 만들 수 있다.\n이 글은 그 시스템을 구축하면서 겪은 시행착오를 정리한 것이다.\n처음 설계: Flink filesystem connector # 가장 단순한 구조로 시작했다.\nS3 파일 → Flink (filesystem connector) → Iceberg 테이블 Flink의 filesystem connector가 S3 버킷을 감시하다가 새 파일이 들어오면 읽어서 각 라인을 레코드로 방출한다. 거기에 Iceberg sink를 붙이면 끝이다.\n문제는 메모리였다. filesystem connector는 이미 처리한 파일 목록 전체를 Flink state에 들고 있는다. ALB 로그가 하루에도 수만 개씩 쌓이니 시간이 갈수록 state가 불어나서 메모리가 터졌다. 확장의 한계에 부딪혀서 구조를 바꿔야 했다.\n현재 구조: S3 → SQS → Filebeat → Kafka → Flink → Iceberg # 파일 감시를 Flink에서 분리했다. 메시지 큐와 경량 수집기를 앞단에 두는 구조다.\nS3 버킷 → SQS (파일 이벤트) → Filebeat → Kafka → Flink → Iceberg 각 구간이 하는 일은 이렇다.\nS3 → SQS: 버킷 설정으로 ALB 로그 파일이 추가될 때마다 SQS에 해당 파일 경로가 메시지로 들어간다 SQS → Filebeat → Kafka: Filebeat가 SQS에서 메시지를 읽고 S3 파일을 직접 가져와 각 라인을 Kafka 토픽으로 보낸다 Kafka → Flink → Iceberg: Flink가 Kafka에서 레코드를 읽고 CSV 파싱 후 가공(파일 경로에서 계정번호, 서비스명, 역할 추출)하여 Iceberg 테이블에 쓴다 Flink는 Kafka만 바라보면 된다. 파일 목록을 state에 들고 있을 필요가 없어졌다.\nFilebeat에 정착하기까지 # Filebeat를 선택하기 전에 Kafka Connect Filesystem Connector를 먼저 시도했다. 결과적으로 실패했고 그 과정에서 배운 것이 있다.\nKafka Connect Filesystem Connector — 포기 # 써드파티 커넥터였는데 문제가 여러 개 있었다.\nMaven에 올라가 있지 않아서 직접 빌드해야 했다 GitHub 마지막 커밋이 4년 전이었고 Java 8 기반이었다 같은 메시지가 두 번 이상 중복 발행되는 현상이 발생했다 S3 파일 move(클린업)가 정상적으로 동작하지 않았다. FileUtil.copy()가 S3A 파일시스템에서 제대로 안 돌아가는 문제였다 커뮤니티에서 충분히 검증되지 않은 도구를 억지로 쓰는 것보다 잘 관리되는 도구를 쓰는 게 낫다고 판단했다.\nFilebeat 버킷 리스팅 모드 — 스케일링 한계 # Filebeat는 S3 input을 두 가지 모드로 지원한다. 처음에는 버킷 리스팅 모드를 썼다. 주기적으로 S3를 스캔해서 새 파일을 감지하는 방식이다.\n동작은 잘 됐는데 수평 스케일링이 안 됐다. 여러 Filebeat 인스턴스를 띄우면 같은 파일을 중복 처리한다. 각 인스턴스가 서로의 존재를 모르기 때문이다. 공식 문서에도 버킷 리스팅 모드에서는 single instance + 수직 스케일링만 하라고 명시되어 있다.\n또 다른 문제도 있었다. 처리 완료된 파일을 백업 버킷으로 옮기는 기능(backup_to_bucket_arn)이 대부분의 Filebeat 버전에서 버킷 리스팅 모드와 제대로 동작하지 않았다. GitHub Issue를 찾아보니 fix가 머지됐다가 실수로 롤백된 상태였다. 8.15.3 버전에서만 정상 동작을 확인했다.\nSQS 모드로 전환 # SQS 모드는 수평 스케일링이 가능하다. SQS가 메시지 분배를 해주기 때문에 여러 Filebeat 파드가 서로 겹치지 않고 처리할 수 있다. S3 API 호출 비용도 줄어든다.\n단점은 기존 파일을 소급 처리하지 못한다는 점이다. SQS에 이벤트가 들어온 시점 이후의 파일만 처리한다. 필요하면 기존 파일에 대해 수동으로 SQS 이벤트를 발행하면 된다. ALB 로그 상황에서는 문제가 안 됐다.\n한 가지 더. SQS 모드에서는 backup_to_bucket_arn 설정을 아예 사용할 수 없다. config 검증 단계에서 에러가 난다. 생각해 보면 SQS를 쓰면 새로 추가된 파일과 기존 파일을 구분할 필요가 없으니 백업 기능이 필요 없는 게 맞다.\n최종 Filebeat 설정은 이렇다.\nfilebeat.inputs: - type: aws-s3 queue_url: https://sqs.ap-northeast-2.amazonaws.com/xxxx/s3-elb-logs-events file_selectors: - regex: \u0026#34;.*\\\\.log\\\\.gz\u0026#34; number_of_workers: 64 decompress: true codec.line: format: message output.kafka: hosts: - kafka-cluster:9092 topic: cloudinfra.prod.streaming.alb-access-log.csv codec.format: string: \u0026#39;%{[aws.s3.object.key]} %{[message]}\u0026#39; compression: zstd 핵심은 codec.format에서 S3 파일 경로(aws.s3.object.key)를 메시지 앞에 붙여서 보내는 부분이다. Flink에서 이 경로를 파싱해 계정번호와 서비스명을 추출한다.\n오토스케일링 # Filebeat: SQS 기반 KEDA 스케일링 # SQS의 Visible Messages 수를 기준으로 KEDA ScaledObject를 구성했다.\nspec: cooldownPeriod: 300 maxReplicaCount: 128 minReplicaCount: 1 pollingInterval: 30 triggers: - type: aws-sqs-queue metadata: queueLength: \u0026#39;50\u0026#39; queueURL: https://sqs.ap-northeast-2.amazonaws.com/xxxx/s3-elb-logs-events 처음 적용했을 때 KEDA operator의 IAM Role 권한 문제로 SQS 메트릭 조회가 실패했다. ScaledObject에서 identityOwner: operator로 설정하면 KEDA operator가 자기 role로 직접 SQS를 조회한다. 이 role에 sqs:GetQueueAttributes 권한을 추가해서 해결했다.\nFlink: K8s Operator 오토스케일링 # Flink는 Kubernetes Operator의 내장 오토스케일링을 사용한다.\njob.autoscaler.target.utilization: \u0026#34;0.75\u0026#34; job.autoscaler.target.utilization.boundary: \u0026#34;0.15\u0026#34; pipeline.max-parallelism: \u0026#39;480\u0026#39; Flink 체크포인트 튜닝 # 체크포인트 간격을 1분에서 5분으로 늘렸더니 연쇄적으로 문제가 터졌다.\nHeartbeat timeout # 체크포인트가 오래 걸리면서 TaskManager의 heartbeat가 타임아웃됐다. 기본값이 너무 짧았다.\nheartbeat.interval: \u0026#39;60000\u0026#39; heartbeat.timeout: \u0026#39;300000\u0026#39; pekko.ask.timeout: 10m OOM: Java heap space # 체크포인트 간격이 길어지면서 Kafka fetch 버퍼가 힙에 쌓이는 양이 늘었다. 파드 메모리를 2G → 4G → 6G로 올려도 같은 에러가 반복됐다.\n원인은 JVM Task Heap 메모리 할당이 부족한 것이었다. 파드 전체 메모리는 여유가 있었지만 Task Heap은 2.32GB만 할당되어 꽉 찼다. taskmanager.memory.task.heap.size를 직접 지정해서 해결했다.\ntaskmanager.memory.task.heap.size: 4608m taskmanager.memory.managed.size: 512m taskmanager.memory.network.fraction: \u0026#39;0.02\u0026#39; 최종 설정 # 여러 차례 튜닝 끝에 체크포인트 간격을 10분까지 늘릴 수 있었다.\nexecution.checkpointing.interval: 10m execution.checkpointing.timeout: 5m heartbeat.interval: \u0026#39;60000\u0026#39; heartbeat.timeout: \u0026#39;300000\u0026#39; pekko.ask.timeout: 10m taskmanager.memory.task.heap.size: 4608m taskmanager.memory.managed.size: 512m taskmanager.memory.network.fraction: \u0026#39;0.02\u0026#39; 컴팩션 실패와 Upsert 제거 # 체크포인트 간격을 10분으로 바꾼 뒤에도 Iceberg 컴팩션이 계속 실패했다. 원인으로 추정되는 요소를 전부 제거하기로 했다.\n새 Iceberg 테이블을 만들었다. 기존 테이블의 메타데이터가 오염(?)된 상태일 수 있어서 깨끗한 테이블로 교체했다. Upsert 로직을 제거했다. 원래 중복 방지를 위해 UPSERT 모드로 적재하고 있었는데 이게 컴팩션 충돌의 원인이었다. Upsert를 빼면 중복 데이터가 생길 수 있다. 확인해 보니 중복이 있긴 했는데 적재 과정에서 생긴 게 아니라 원본 ALB 로그 자체에 중복이 있었다. 실질적으로 문제없다고 판단하고 append-only로 전환했다. 이후 컴팩션 작업이 빠르게 성공했다.\n운영 중 마주친 사건: ALB 로그 컬럼 수 변경 # 어느 날 새벽 4시 무렵부터 Flink 앱의 CSV 파싱이 실패하기 시작했다. 원인은 ALB 로그 컬럼이 31개에서 34개로 늘어난 것이었다. AWS에서 사전 공지 없이 변경한 거였다.\n첫 번째 시도: DLQ (Dead Letter Queue) # csv-dlq 포맷을 적용해서 파싱 에러가 난 레코드를 DLQ 토픽으로 보내도록 했다. 앱은 돌아왔지만 새로운 문제가 생겼다. 포맷 에러가 TaskManager 로그에 기록되면서 ephemeral-storage가 가득 찼다. 파드가 Evicted 상태로 죽었다 살아났다를 반복했다.\nThe node was low on resource: ephemeral-storage. log4j 설정을 수정해서 포맷 에러 로그 레벨을 ERROR로 올려 해결했다.\nlogger.format.name = com.woowahan.dataservice.format logger.format.level = ERROR 두 번째 문제: DLQ 토픽 과부하 # DLQ 토픽에 메시지가 너무 많이 들어가면서 Kafka 클러스터에 부하가 생겼다. 결국 DLQ를 롤백하고 csv.ignore-parse-error 옵션으로 파싱 에러를 무시하도록 바꿨다. 소스 테이블에 dummy 컬럼 3개를 추가해서 31개든 34개든 모두 수용할 수 있게 처리했다.\n중복 방지: UPSERT와 Primary Key # 초기에는 중복 방지를 위해 Iceberg UPSERT를 사용했다. PK(Primary Key)를 잡아야 하는데 ALB 로그에는 고유 식별자가 없다.\n46만 건의 로그를 조사해서 file_path, time, http_request, client_addr, target_addr, request_creation_time 5개 필드 조합이 거의 유니크하다는 걸 확인했다. 실제 중복은 전체에서 1건뿐이었고 그 2개 레코드는 모든 필드가 동일해서 사실상 구분 불가능한 로그였다.\nIceberg 테이블에서 PK를 지정하려면 Flink SQL의 SET IDENTIFIER FIELDS를 써야 했다. Spark SQL에서는 PRIMARY KEY 문법을 지원하지 않고 Flink SQL에서는 bucketing과 hidden partitioning을 지원하지 않아서 테이블 생성에 애를 먹었다.\n결국 앞서 설명한 대로 컴팩션 안정성을 위해 UPSERT를 제거했다.\n모니터링 # 핵심 지표 # 지표 의미 SQS Approximate Number Of Messages Visible 처리 대기 중인 파일 수 SQS Approximate Number Of Messages Not Visible 현재 Filebeat가 처리 중인 파일 수 Kafka consumer lag Flink의 처리 지연 Flink job status 앱 실행 상태 알럿 설정 # SQS: Visible Messages가 임계치 초과 시 (밀림 감지) Filebeat: CPU/메모리 사용률 과다, 파드 미실행 Flink: job이 non-running 상태 전환 시 정리 # 돌아보면 가장 큰 교훈은 세 가지다.\nFlink에 파일 감시를 맡기지 말 것. Filesystem connector는 처리한 파일 목록을 state에 들고 있어서 장기 운영하면 메모리가 터진다. 파일 감시는 SQS + Filebeat 같은 외부 도구에 맡기고 Flink는 스트림 처리에만 집중시키는 게 맞다.\nUpsert는 컴팩션과 충돌한다. Iceberg CDC 테이블의 position delete 문제다. 로그성 데이터라면 append-only가 운영 안정성 면에서 훨씬 낫다. 원본 데이터 자체의 중복은 소비자 쪽에서 처리하면 된다.\nAWS는 사전 공지 없이 포맷을 바꿀 수 있다. ALB 로그 컬럼이 갑자기 늘어나는 일이 실제로 일어났다. CSV 파싱을 하는 파이프라인이라면 ignore-parse-error 같은 방어 로직이 필수다.\n참고 자료:\nFilebeat AWS S3 Input Flink Filesystem Connector Apache Iceberg - Flink Writes KEDA AWS SQS Queue Scaler ","date":"2026년 2월 25일","externalUrl":null,"permalink":"/posts/alb-log-collection-system/","section":"글 목록","summary":"S3에 CSV로 쌓이는 ALB 로그를 Iceberg 테이블로 바꾸는 시스템을 구축했다. Flink filesystem connector의 메모리 한계를 겪고 filebeat + SQS + Kafka 구조로 재설계한 과정, 오토스케일링 적용, 체크포인트 튜닝, 그리고 운영 중 마주친 여러 삽질을 정리했다.","title":"ALB 로그를 Iceberg 테이블로 만들기까지","type":"posts"},{"content":"","date":"2026년 2월 25일","externalUrl":null,"permalink":"/tags/filebeat/","section":"Tags","summary":"","title":"Filebeat","type":"tags"},{"content":"","date":"2026년 2월 25일","externalUrl":null,"permalink":"/tags/flink/","section":"Tags","summary":"","title":"Flink","type":"tags"},{"content":"","date":"2026년 2월 25일","externalUrl":null,"permalink":"/tags/iceberg/","section":"Tags","summary":"","title":"Iceberg","type":"tags"},{"content":"","date":"2026년 2월 25일","externalUrl":null,"permalink":"/tags/kafka/","section":"Tags","summary":"","title":"Kafka","type":"tags"},{"content":"","date":"2026년 2월 25일","externalUrl":null,"permalink":"/tags/sqs/","section":"Tags","summary":"","title":"Sqs","type":"tags"},{"content":"앱 로그를 해외 트래킹 서버로 보내야 하는 상황이 생겼다. 문제는 로그 안에 회원번호, 디바이스 ID, 주문번호 같은 개인식별정보(PII)가 섞여 있다는 것. 개인정보보호법상 그대로 국외 전송하면 안 된다.\n그래서 중간에 프록시 서버를 뒀다. 앱에서 보낸 로그를 프록시가 받아서 PII를 해싱하고 해외 서버로 넘긴다. 원본 데이터는 사내 Kafka로 보내서 광고나 추천 같은 내부 데이터 프로덕트에 활용할수 있게 했다.\n이 글은 하루 평균 13억건 로그를 처리하는 프록시 서버를 Apache APISIX로 구축한 기록이다.\n왜 APISIX인가 # 처음에는 Fluent-bit을 생각했다 # 로그 수집이니까 Fluent-bit이 자연스러운 선택이었다. 근데 요구사항을 정리해보니 단순한 로그 포워딩이 아니라 API Gateway 기능이 필요했다.\nHTTP 요청을 받아서 request body를 조작해야 한다 (PII 해싱) 해외 트래킹 서버 응답(400 에러 등)을 클라이언트에 그대로 전달해야 한다 Kafka로 원본 데이터를 동시에 발행해야 한다 Fluent-bit은 이 중 어느 것도 깔끔하게 처리하지 못한다.\nKong vs APISIX # 둘 다 nginx 기반이고 Lua 스크립팅을 지원한다. Kong을 먼저 테스트했는데 Helm 차트 배포 단계에서 알려진 이슈에 걸려 실패했다.\nAPISIX로 전환한 이유는 간단하다.\n경량화 설계. Kong보다 메모리를 적게 쓰고 코어당 처리량이 높다 선언적 라우팅. Admin API로 설정을 보내면 etcd에 저장돼 영구 보관된다 커스텀 플러그인. rewrite → access → header_filter → body_filter → log 단계로 요청 처리 파이프라인이 나뉘어 있어서 원하는 단계에 로직을 끼워넣기 좋다 커스텀 플러그인 개발 # 왜 기존 플러그인으로는 안 되나 # APISIX에는 kafka-logger라는 내장 플러그인이 있다. 요청 데이터를 Kafka로 보내주는 건데 비식별화 플러그인(encrypt-pii)을 먼저 실행하면 kafka-logger가 원본이 아닌 해싱된 데이터에 접근하게 된다.\n원하는 흐름은 이렇다.\n앱 → APISIX → (1) 원본을 Kafka로 발행 (2) PII를 해싱 (3) 해싱된 데이터를 해외 서버로 전송 (4) 해외 서버의 응답을 앱에 반환 (1)과 (2)의 순서가 중요하다. 원본을 Kafka에 먼저 보내고 그다음 해싱해야 한다. 기존 플러그인 조합으로는 이 순서를 보장할수 없어서 kafka-logger 기능까지 포함한 커스텀 플러그인을 만들었다.\nLua로 비식별화 구현 # APISIX는 LuaJIT 위에서 돌아간다. lua-resty-string 모듈로 SHA-256 해싱을 구현했다.\nlocal resty_sha256 = require \u0026#34;resty.sha256\u0026#34; local str = require \u0026#34;resty.string\u0026#34; local function hash_value(value) local sha256 = resty_sha256:new() sha256:update(value) local digest = sha256:final() return str.to_hex(digest) end 비식별화 대상은 세 가지다.\n회원번호 디바이스 ID 주문번호 request body에서 JSON을 파싱하고 대상 필드를 찾아 해싱한 뒤 다시 직렬화한다.\nKafka 메시지 발행 # 같은 플러그인 안에서 lua-resty-kafka를 써서 원본 데이터를 Kafka로 보낸다.\nlocal producer = require \u0026#34;resty.kafka.producer\u0026#34; local broker_list = { { host = \u0026#34;kafka-broker-01\u0026#34;, port = 9092 }, } local p = producer:new(broker_list, { producer_type = \u0026#34;async\u0026#34; }) local ok, err = p:send(\u0026#34;app-log-topic\u0026#34;, nil, original_body) lua-resty-kafka를 쓰려면 의존 모듈이 필요하다.\nluarocks install lua-cjson luarocks install penlight 개발 중에 두 가지 이슈를 만났다.\nKafka 메시지에 timestamp가 안 남는 문제. Kafka API version을 1에서 2로 올리니 해결됐다 Kafka metadata 조회 실패. API version 2에서 발생해서 다시 1로 내렸다 결국 메시지 발행은 API version 2로, metadata 조회는 API version 1로 분리 처리했다.\n아키텍처 변천사 # 처음 설계했던 구조와 최종 구조가 꽤 다르다.\n초기 설계. 프록시 → Kafka → Flink → 해외 서버 # 앱 → APISIX → Kafka → Flink(비식별화) → 해외 트래킹 서버 프록시는 Kafka로만 보내고 비식별화는 Flink에서 처리하는 구조였다. 문제는 해외 서버가 HTTP 400 에러를 내릴 때 그걸 클라이언트에 전달할 방법이 없다는 것. Kafka로 보내는 순간 응답은 끊기니까.\n최종 설계. 프록시에서 직접 비식별화 # 앱 → APISIX → (원본 → Kafka) → (해싱 후 → 해외 트래킹 서버 → 응답 → 앱) 프록시에서 직접 비식별화를 수행하고 해외 서버로 전송한다. 장단점이 뚜렷하다.\n장점:\n해외 서버 응답(400 포함)을 클라이언트에 그대로 전달할 수 있다 Flink 애플리케이션이 빠진다 실시간 처리가 된다 단점:\n프록시 서버에 부하가 몰린다 request body 파싱 + 해싱 + Kafka 발행을 한 요청 안에서 다 처리한다 부하 집중이 걱정됐지만 APISIX 성능이 충분히 받쳐줬다. 수치는 아래에서 다룬다.\n부하 테스트 # 테스트 환경 # nGrinder로 부하를 걸었다. 프록시 서버 스펙은 Pod당 2 core, 4GiB 메모리.\n코어당 처리량 # APISIX 공식 문서에는 1 core당 10,000 QPS를 처리할 수 있다고 나와 있다. 근데 request body를 파싱하고 해싱하는 Lua 스크립트가 붙으면 그보다 낮아진다.\n실측 결과 (2 core 기준, 1분 30초씩 테스트):\nVuser Peak TPS CPU 사용률 에러 990 2,381 32% 0 1,980 4,907 48% 1 3,960 7,000 99% 0 안정적으로 운영하려면 2 core 기준 5,000 TPS 정도가 적당하다. 피크 트래픽이 약 55,000 TPS이므로 Pod 12개면 커버된다.\n튜닝 포인트 # Keepalive 설정. 적용 전에는 p95 레이턴시가 요청마다 흔들렸는데 keepalive 설정 후 p95 기준 10ms 이하로 안정화됐다. warm-up 이후에는 1ms 미만도 나왔다.\nnginx worker_connections. APISIX 기본값은 auto인데 이게 Pod 코어 수가 아니라 노드 코어 수를 기준으로 worker를 할당한다. worker가 과하게 생기면 CPU 병목이 생길 수 있어서 Pod 코어 수에 맞춰 수동 설정했다. 효과가 극적이진 않지만 CPU 사용률이 내려가면서 TPS는 올라갔다.\n스케일 아웃 전략. 트래픽이 갑자기 밀려오면 스케일 아웃되기 전에 CPU가 100%를 찍으면서 에러가 터진다. 스트리밍과 달리 백프레셔가 없기 때문이다. 두 가지로 대응했다.\nKEDA로 CPU 50% 기준 스케일 아웃 — 여유 있게 잡아야 한다 스케줄 기반 스케일링 — 피크 타임(점심, 저녁)에 맞춰 미리 Pod를 늘려놓는다 502 에러 원인 # 테스트 중 간헐적으로 502가 발생했다. upstream 서버에서 response header를 읽다가 타임아웃이 걸린 것이다. 원인이 복합적이었다.\n해외 서버 스테이징 환경이 spot 인스턴스라 응답이 불안정했다 트래픽이 급격히 몰리면 스케일 아웃 전에 CPU가 포화됐다 nGrinder agent당 vuser를 과하게 잡으면 클라이언트 쪽 네트워크 병목이 생겨서 서버 응답이 느려 보이는 현상이 있었다 운영 환경에서는 min Pod를 보수적으로 잡고 스케줄 기반 스케일링을 병행하니 502가 사라졌다.\nKubernetes 배포 # Helm 차트 구성 # APISIX를 decoupled 모드로 배포했다. control-plane과 data-plane을 분리하는 방식이다.\ncontrol-plane (apisix-control). etcd와 함께 배포하고 라우팅 설정을 관리한다 data-plane (apisix-data). 실제 트래픽을 처리한다. externalEtcd 설정으로 control-plane의 etcd에 연결한다 etcd는 PVC(gp3)로 데이터를 영구 보관한다. 표준 EKS 기본 스토리지 클래스가 gp3이므로 별도 설정 없이 PVC를 생성하면 된다.\nHPA 설정 (KEDA) # # KEDA ScaledObject (요약) triggers: - type: prometheus metadata: query: avg(rate(container_cpu_usage_seconds_total{...}[1m])) * 100 threshold: \u0026#34;50\u0026#34; - type: memory metadata: value: \u0026#34;80\u0026#34; CPU 50%나 메모리 80%를 넘으면 스케일 아웃한다. 여기에 스케줄 기반 스케일링을 더해서 피크 타임에 미리 Pod를 확보한다.\n보안 # 퍼블릭으로 노출되는 리버스 프록시 ALB에 AWS WAF를 연동했다. 정보보안팀 검토 결과 WAF만 적용하면 클라이언트 보안에 문제없다는 결론이 나왔다.\n모니터링 # Grafana 대시보드를 구성해서 아래 지표를 실시간으로 본다.\nSystem. CPU 사용률, 메모리 사용률 (Pod별) Nginx. 총 요청 수, accepted/handled connections, connection state HTTP. 상태 코드별 RPS, 서비스/라우트별 RPS Latency. APISIX 레이턴시, upstream 레이턴시, 전체 요청 레이턴시 Bandwidth. 서비스/라우트별 ingress/egress etcd. modify indexes, reachable 상태 APISIX 라우트 설정에 prometheus 플러그인을 추가해야 request 단위 메트릭이 수집된다. 이걸 빠뜨리면 시스템 메트릭만 나오고 HTTP 관련 지표가 빈다.\n알럿은 Grafana → OpsGenie → Slack 채널로 연동했다.\n운영 결과 # 약 3개월간 운영한 결과를 정리하면 이렇다.\n지표 목표 실제 비용 절감 기존 대비 20% 29.8% 절감 레이턴시 (p95) 40ms 25ms 가용성 99.99% 100% PII 비식별화 성공률 100% 100% 비용 절감이 목표보다 높았던 건 Flink 애플리케이션이 빠지면서다. 프록시에서 직접 비식별화를 처리하니 별도 스트림 프로세싱 비용이 사라졌다.\n운영 초기에 499 에러(클라이언트가 연결을 끊는 경우)와 408 에러(서버 타임아웃)가 소량 발생했다. 400 에러를 제외한 나머지는 SDK에서 재전송 처리하므로 데이터 유실은 없었다.\n마치며 # APISIX를 프록시 서버로 쓰면서 배운 것을 정리한다.\nAPI Gateway를 프록시로 쓰는 게 자연스러울 때가 있다. request body 조작과 HTTP 응답 전달이 필요하면 로그 수집기보다 API Gateway가 맞다. 커스텀 플러그인은 피할 수 없다. 기존 플러그인 조합으로 해결하려고 붙잡지 말고 빨리 커스텀 플러그인을 만드는 게 낫다. APISIX 플러그인 구조가 잘 되어 있어서 개발 자체는 어렵지 않다. 스케일 아웃보다 미리 확보하는 게 낫다. 트래픽이 급격히 몰리면 리액티브 스케일링은 늦다. 스케줄 기반으로 피크 타임에 미리 Pod를 올려놓는 게 안정적이다. nginx worker 수를 확인하라. APISIX auto 설정이 Pod가 아닌 노드 기준으로 worker를 만든다. 컨테이너 환경에서는 수동으로 맞춰야 한다. 참고 자료:\nApache APISIX 공식 문서 lua-resty-kafka (GitHub) APISIX Custom Plugin Development Apache APISIX Grafana Dashboard ","date":"2026년 2월 24일","externalUrl":null,"permalink":"/posts/apisix-proxy-server-guide/","section":"글 목록","summary":"해외 트래킹 서버로 앱 로그를 전송할 때 개인정보를 비식별화해야 했다. Fluent-bit에서 시작해 Kong을 거쳐 APISIX에 정착한 과정, 커스텀 Lua 플러그인 개발, 5.5만 TPS 부하 테스트, Kubernetes 배포까지 실전 경험을 정리했다.","title":"Apache APISIX로 프록시 서버 구축하기. 일 13억 건 로그 비식별화 처리","type":"posts"},{"content":"","date":"2026년 2월 24일","externalUrl":null,"permalink":"/tags/apisix/","section":"Tags","summary":"","title":"Apisix","type":"tags"},{"content":"","date":"2026년 2월 24일","externalUrl":null,"permalink":"/tags/cdc/","section":"Tags","summary":"","title":"Cdc","type":"tags"},{"content":"","date":"2026년 2월 24일","externalUrl":null,"permalink":"/tags/compaction/","section":"Tags","summary":"","title":"Compaction","type":"tags"},{"content":"","date":"2026년 2월 24일","externalUrl":null,"permalink":"/tags/deletion-vector/","section":"Tags","summary":"","title":"Deletion-Vector","type":"tags"},{"content":"Iceberg CDC 테이블에 컴팩션을 돌리면 이런 에러가 뜬다.\norg.apache.iceberg.exceptions.ValidationException: Cannot commit, found new position delete for replaced data file append-only 테이블에서는 안 나는 에러다. CDC에서만 난다. 왜 그런지 이해하려면 Iceberg v2의 delete 메커니즘부터 알아야 한다.\nIceberg v2의 row-level delete # 데이터를 지우는 두 가지 방법. COW vs MOR # Iceberg에서 행을 삭제하거나 업데이트하는 방법은 두 가지다.\nCopy-on-Write (COW). 변경이 생기면 데이터 파일을 통째로 다시 쓴다. 삭제할 행을 빼고 나머지를 새 파일에 복사하는 식이다. 읽기 성능은 좋지만 쓰기 비용이 크다. 배치성 대량 갱신에 적합하다.\nMerge-on-Read (MOR). 데이터 파일은 건드리지 않는다. 대신 \u0026ldquo;이 행은 삭제되었다\u0026quot;는 정보를 별도 delete file에 기록한다. 쓰기가 빠른 대신 읽을 때 원본과 delete file을 병합해야 하므로 읽기 비용이 올라간다. CDC/Upsert 테이블에 적합하다.\nCDC 파이프라인은 업데이트가 쉴 새 없이 들어오니까 MOR이 맞다. 문제는 이 MOR 경로에서 생기는 delete file이 컴팩션과 충돌한다는 점이다.\nDelete file의 두 종류 # MOR에서 사용하는 delete file에는 두 가지가 있다.\nEquality delete. 삭제할 행의 키값만 기록한다. \u0026ldquo;이 PK를 가진 행을 지워라\u0026quot;는 뜻이다. 여러 데이터 파일에 걸쳐 있어도 delete file 하나로 표현할 수 있다. 대신 읽기 시 키 매칭 비용이 든다.\nPosition delete. 특정 데이터 파일의 특정 위치(행 번호)를 기록한다. \u0026ldquo;A.parquet 파일의 42번째 행을 지워라\u0026quot;는 식이다. 읽을 때 정확히 그 위치만 건너뛰면 되니까 equality delete보다 읽기 성능이 좋다.\n유형 기록 내용 읽기 비용 적합한 경우 Equality delete 키 값 높음 (키 매칭) PK 기반 대량 삭제 Position delete 파일 경로 + 행 번호 낮음 (위치 점프) 스트림 내 빈번한 업데이트 엔진마다 지원 범위가 다르다 # Iceberg 스펙에는 두 종류 모두 정의되어 있지만 모든 엔진이 전부 구현한 건 아니다.\n엔진 Equality delete 읽기 Position delete 읽기 Equality delete 쓰기 Position delete 쓰기 Spark O O X O Flink O O O (UPSERT 모드) 상황에 따라 Trino O O X O Athena O O X O Hive/Impala O O X O Spark은 equality delete를 읽을 수는 있지만 쓰지는 못한다. Trino와 Athena도 마찬가지. 행 삭제 시 position delete만 기록한다. UPSERT 모드에서 equality delete 쓰기를 지원하는 건 Flink뿐이다.\n이 차이가 컴팩션 전략에 영향을 준다.\nDelta Writer. 같은 커밋 안에서 delete 전략이 갈린다 # CDC 싱크에서 iceberg-core의 BaseTaskWriter가 레코드를 처리하는 로직이 흥미롭다.\npublic void deleteKey(T key) throws IOException { if (!internalPosDelete(asStructLikeKey(key))) { eqDeleteWriter.write(key); } } 한 커밋을 만드는 과정에서 삭제 요청이 들어오면 먼저 이번 스트림(커밋)에 포함된 데이터인지 확인한다.\n이번 스트림에 있는 레코드 → position delete로 기록 이번 스트림에 없는 레코드 → equality delete로 기록 왜 전부 equality delete로 통일하지 않을까? 읽기 성능 때문이다. position delete가 MOR 읽기에서 훨씬 효율적이라 가능한 한 position delete를 쓰려고 한다. iceberg-core 쓰기 로직에 읽기 성능 최적화가 녹아있는 셈이다.\n이 설계가 컴팩션에서 문제를 일으킨다.\n스냅샷 타입과 커밋 충돌 # Iceberg의 네 가지 스냅샷 operation # Iceberg 스냅샷에는 operation 필드가 있다. 어떤 종류의 변경이 일어났는지를 나타낸다.\nOperation 의미 대표 작업 append 데이터 파일 추가 배치 적재, INSERT replace 데이터/삭제 파일 교체 컴팩션 overwrite 논리적 덮어쓰기 업서트, UPDATE, DELETE delete 데이터 파일 제거 또는 삭제 파일 추가 DROP PARTITION 등 컴팩션은 replace다. 작은 파일 여러 개를 큰 파일로 합치고 기존 걸 교체한다. CDC 싱크는 overwrite다. 업서트 과정에서 delete file을 만든다.\n낙관적 동시성 제어 # Iceberg는 낙관적 동시성(optimistic concurrency)으로 커밋 충돌을 처리한다. Git이랑 비슷하다.\n현재 스냅샷을 기준으로 새 메타데이터 트리를 만든다 원자적 커밋(atomic swap)을 시도한다 그 사이에 다른 커밋이 끼어들었으면 검증(validation) 을 수행한다 검증 통과하면 커밋 성공. 실패하면 재시도 핵심은 3번의 검증 규칙이다. 어떤 스냅샷 타입끼리 충돌하고 어떤 조합은 자동으로 병합되는가.\nAppend-only vs CDC. 왜 차이가 나는가 # Append-only 테이블은 충돌이 거의 없다 # Append-only 테이블은 데이터를 추가만 한다. delete file이 없다. 컴팩션(replace)이 돌아가는 동안 새 데이터가 들어와도(append) 서로 다른 파일을 건드리니까 자동 병합된다. Git에서 서로 다른 파일을 수정한 두 브랜치가 충돌 없이 머지되는 것과 같다.\nCDC 테이블은 position delete가 문제다 # CDC 테이블은 다르다. 업서트가 일어나면 delete file이 생긴다. 컴팩션이 데이터 파일 A를 새 파일 B로 교체하려는 순간 CDC 싱크가 파일 A에 대한 position delete를 만들어 버리면 어떻게 될까?\n시간 순서: 1. 컴팩션 시작: 파일 A를 읽어서 새 파일 B를 만드는 중 2. CDC 싱크: 파일 A의 42번째 행을 삭제 (position delete 생성) 3. 컴팩션 완료: 파일 A → 파일 B 교체 커밋 시도 4. 검증 실패: \u0026#34;파일 A에 대한 새 position delete가 생겼는데 파일 A를 교체하면 그 delete가 유실된다\u0026#34; ValidationException: Cannot commit, found new position delete for replaced data file 컴팩션 입장에서는 파일 A를 이미 읽어서 새 파일을 만들었는데 그 사이에 파일 A에 대한 삭제가 추가된 거다. 이 삭제를 반영하지 않고 교체하면 데이터 정합성이 깨지니까 Iceberg가 커밋을 거부한다.\nEquality delete는 왜 덜 부딪히나 # Equality delete는 \u0026ldquo;이 키를 가진 행을 지워라\u0026quot;라는 논리적 선언이다. 특정 파일에 바인딩되지 않는다. 컴팩션이 파일을 교체해도 키 기반 삭제는 새 파일에도 그대로 적용할 수 있다.\n실제로 Iceberg에는 컴팩션 시 시작 시점의 sequence-number를 유지하는 메커니즘이 있다(PR #3480). 이걸로 equality delete와의 충돌을 자동 우회한다. 기본 옵션으로 활성화되어 있다.\nposition delete는 그게 안 된다. 특정 파일의 특정 위치를 가리키기 때문에 파일이 바뀌면 위치도 의미를 잃는다.\n커밋 인터벌 딜레마 # \u0026ldquo;그럼 싱크 커밋 인터벌을 조정하면 되지 않나?\u0026rdquo; 싶을 수 있다. 쉽지 않다.\n인터벌을 길게 잡으면 한 커밋에 포함되는 레코드가 많아진다. 같은 레코드가 INSERT 후 UPDATE되거나 DELETE되는 확률이 올라간다. delta writer가 이번 스트림 내 레코드를 position delete로 처리하니까 position delete 발생이 늘어난다.\n인터벌을 짧게 잡으면 position delete 발생은 줄어들지만 커밋이 자주 일어난다. 컴팩션이 완료되기 전에 새 커밋이 끼어들 확률이 높아진다. position delete가 한 건만 있어도 충돌이 발생한다.\n어느 쪽이든 충돌 확률을 0으로 만들 수는 없다.\nv2에서의 개선 시도 — 전부 실패했다 # 이 문제를 해결하려는 PR이 여러 개 올라왔지만 전부 머지되지 못하고 닫혔다.\nPR 접근 방식 결과 #4703 컴팩션 검증 시 position delete를 선택적 무시 리뷰어들이 \u0026ldquo;위험하다\u0026rdquo; 판단, 닫힘 #4748 Flink upsert에서 position delete와 데이터 파일의 sequence number가 같다는 점을 이용 닫힘 #5760 manifest entry에 min-data-sequence-number 필드를 추가해 비충돌 delete를 필터링 stale bot이 닫음 #7249 position-deletes-within-commit-only 스냅샷 프로퍼티로 같은 커밋 내 position delete 선언 stale bot이 닫음 결국 v2 안에서는 깔끔한 해법이 안 나왔다. 커뮤니티 방향은 v3에서 구조적으로 해결하는 쪽으로 수렴했다.\nIceberg v3. Deletion Vector가 바꾸는 것 # v3 스펙은 2025년 초 확정되었고 Iceberg 1.8.0(2025년 2월)부터 구현이 들어가기 시작했다. 핵심 변경은 Deletion Vector(DV) 도입이다.\nPosition delete file → Deletion Vector # v3에서 position delete file은 새로 만들 수 없다. DV가 그 자리를 대신한다.\nPosition delete files must not be added to v3 tables, but existing position delete files are valid.\nDV는 Puffin 파일에 저장되는 Roaring bitmap이다. 데이터 파일 하나당 \u0026ldquo;몇 번째 행이 삭제되었는지\u0026quot;를 비트맵으로 표현한다.\n항목 v2 Position delete v3 Deletion Vector 저장 형식 Parquet (파일 경로 + 행 번호 컬럼) Puffin (Roaring bitmap) 데이터 파일당 수 무제한 (N개 누적 가능) 최대 1개 새 삭제 발생 시 별도 delete file 추가 기존 DV를 읽어서 병합 후 교체 왜 컴팩션 충돌이 줄어드는가 # v2에서 충돌이 나는 이유는 position delete file이 데이터 파일과 독립적으로 존재하기 때문이었다. 컴팩션이 데이터 파일을 교체하는 동안 CDC 싱크가 같은 파일에 대한 새 position delete file을 만들면 교체 후에 그 delete가 가리키는 파일이 사라진다.\nDV는 구조가 다르다.\n데이터 파일에 종속된다. DV는 데이터 파일의 sidecar다. 컴팩션이 데이터 파일을 새로 쓰면 DV 삭제분도 함께 반영되고 기존 DV는 제거된다. 독립적으로 누적되지 않는다. 데이터 파일 하나에 DV는 최대 하나다. 새 삭제가 들어오면 기존 DV를 읽어서 병합한 뒤 교체한다. v2처럼 delete file이 쌓이면서 \u0026ldquo;파일 A에 대한 새 position delete\u0026rdquo; 문제가 생길 여지가 줄어든다. 컴팩션 빈도 자체가 줄어든다. DV는 compact한 비트맵이라 v2 position delete file처럼 소파일 문제가 없다. 컴팩션을 덜 돌려도 되니까 충돌 윈도우도 줄어든다. Row Lineage와 행 수준 충돌 검출 # v3는 DV 외에 Row Lineage도 도입한다. 모든 행에 고유 _row_id와 _last_updated_sequence_number가 부여된다. DV + Row Lineage를 결합하면 행 수준(row-level) 충돌 검출이 가능해진다(Issue #14613).\nv2에서는 같은 데이터 파일을 건드리면 무조건 충돌이었다. v3에서는 같은 파일이라도 서로 다른 행을 수정했으면 자동 병합할 수 있다. CDC 싱크가 42번째 행을 삭제하고 컴팩션이 다른 행을 정리하는 상황이라면 충돌 없이 커밋이 가능해진다.\n아직 완벽하지는 않다 # OCC(낙관적 동시성)는 여전히 적용된다. 두 writer가 같은 데이터 파일의 DV를 동시에 갱신하면 한쪽은 재시도해야 한다. 그래도 v2와는 다른 점이 있다.\n재시도 비용이 낮다. 비트맵 병합만 다시 하면 된다. 데이터를 처음부터 스캔할 필요가 없다. 충돌 범위가 좁다. 파일 단위가 아니라 DV 단위다. Row lineage 기반 행 수준 충돌 검출이 엔진에 구현되면 같은 파일 내 다른 행 수정은 충돌에서 제외된다. 엔진 지원 현황 (2025년 기준) # 엔진 v3 DV 지원 Spark (Iceberg 1.8.0+) 지원 AWS EMR / Athena / Glue 2025년 11월 발표, 지원 Databricks 지원 (row-level concurrency 포함) Trino (Starburst) 지원 추가 중 Flink 구현 진행 중 v3 마이그레이션은 기존 v2 테이블에서 ALTER TABLE ... SET TBLPROPERTIES ('format-version' = '3')로 전환할 수 있다. 기존 position delete file은 유효하게 유지되며 새 delete부터 DV로 기록된다.\n현재 시점의 운영 우회책. CDC를 잠시 멈추고 컴팩션하기 # 현실적으로 가장 안정적인 방법은 컴팩션 윈도우 동안 CDC 싱크를 일시 중단하는 것이다.\n컴팩션 파이프라인: 1. 새벽 저부하 시간대에 CDC 싱크 커넥터를 pause 2. 컴팩션 실행 (rewrite_data_files) 3. 컴팩션 완료 후 CDC 싱크 재개 카카오 테크 블로그에서도 비슷한 운영을 시사하고 있다. 12시간 간격으로 실시간 CDC 싱크를 중단하고 컴팩션을 돌리는 구조다.\n주의사항 # 컴팩션 시간이 예상보다 길 수 있다. 하루치 CDC 데이터가 쌓인 테이블을 컴팩션하면 생각보다 오래 걸린다. 윈도우 길이를 실측으로 결정해야 한다. 파티션별 분할 실행을 고려하라. 전체 테이블을 한 번에 컴팩션하지 말고 파티션 단위로 나눠서 실행하면 시간을 줄일 수 있다. delete file 정리도 별도로 해야 한다. rewrite_position_delete_files로 delete 소파일을 정리하는 minor compaction도 주기적으로 돌려야 한다. 단 버전별 버그가 보고되어 있으니 호환성을 확인하라. 운영 체크리스트 # 런타임 버전 확인. 사용 중인 EMR/Spark/Flink/Trino 버전에서 rewrite_data_files 검증 규칙과 rewrite_position_delete_files 지원 여부를 확인한다 충돌률 모니터링. CDC 커밋 주기 대비 컴팩션 수행 시간을 실측하고 충돌 빈도를 추적한다 메타데이터 대시보드. 스냅샷/매니페스트 테이블에서 파일 수, 평균 크기, delete file 누적량을 시각화한다 컴팩션 윈도우 확보. 야간 CDC pause 또는 파티션별 분할 컴팩션 전략을 수립한다 커뮤니티 패치 추적. PR #4703, #7249 같은 개선안 반영 여부를 버전별로 점검한다 마치며 # 정리하면 이렇다.\nIceberg v2 MOR 경로에서 position delete는 읽기 성능을 위한 최적화다 그런데 position delete는 특정 파일에 바인딩되어 있어서 컴팩션(replace)과 충돌한다 Equality delete는 sequence-number 메커니즘으로 자동 우회되지만 position delete는 안 된다 v2 안에서 이 문제를 해결하려는 PR은 전부 머지되지 못했다 v3 Deletion Vector가 구조적 해결책이다. Position delete file 대신 데이터 파일당 하나의 비트맵으로 삭제를 관리하고 Row Lineage로 행 수준 충돌 검출까지 가능해진다 v3 전환 전까지는 컴팩션 윈도우 동안 CDC를 잠시 멈추는 게 현실적인 답이다 v3 스펙은 확정되었고 엔진 지원도 빠르게 확대되고 있다. v3로 전환하면 이 글에서 다룬 운영 부담 대부분이 사라진다. 아직 v2를 쓰고 있다면 v3 마이그레이션 계획을 세우는 게 장기적으로 맞다.\n참고 자료:\nRow-Level Changes on the Lakehouse: COW vs MOR in Apache Iceberg (Dremio) Apache Iceberg Spec - Row-level Deletes Apache Iceberg - Reliability (Concurrency) PR #3480: Core: support rewrite data files with starting sequence number PR #4703: API: Optionally ignore position deletes in rewrite validation PR #7249: Avoid conflicts between rewrite datafiles and flink CDC writes 로그 유형별 Iceberg 테이블 적재 및 운영 전략 (Kakao Tech) Improve Position Deletes in V3 (Issue #11122) Row Lineage for V3 (Issue #11129) Row-level concurrency (Issue #14613) What\u0026rsquo;s New in Apache Iceberg v3 (Google Open Source Blog) Iceberg V3 Deletion Vectors on Amazon EMR (AWS Blog) ","date":"2026년 2월 24일","externalUrl":null,"permalink":"/posts/iceberg-cdc-compaction-challenge/","section":"글 목록","summary":"Iceberg v2의 row-level delete 구현, position delete와 equality delete의 차이, 실시간 CDC 싱크와 컴팩션 간 커밋 충돌 원인을 코드 레벨에서 분석했다. v3 Deletion Vector가 이 문제를 어떻게 바꾸는지, 그리고 v2 환경에서의 운영 우회책까지 함께 정리한다.","title":"Iceberg - 왜 CDC 테이블의 컴팩션이 까다로운가","type":"posts"},{"content":"","date":"2026년 2월 24일","externalUrl":null,"permalink":"/tags/iceberg-v3/","section":"Tags","summary":"","title":"Iceberg-V3","type":"tags"},{"content":"","date":"2026년 2월 24일","externalUrl":null,"permalink":"/tags/kafka-connect/","section":"Tags","summary":"","title":"Kafka-Connect","type":"tags"},{"content":"","date":"2026년 2월 24일","externalUrl":null,"permalink":"/tags/lakehouse/","section":"Tags","summary":"","title":"Lakehouse","type":"tags"},{"content":"","date":"2026년 2월 24일","externalUrl":null,"permalink":"/tags/lua/","section":"Tags","summary":"","title":"Lua","type":"tags"},{"content":"","date":"2026년 2월 24일","externalUrl":null,"permalink":"/tags/privacy/","section":"Tags","summary":"","title":"Privacy","type":"tags"},{"content":"","date":"2026년 2월 24일","externalUrl":null,"permalink":"/tags/proxy/","section":"Tags","summary":"","title":"Proxy","type":"tags"},{"content":"Joe Reis가 데이터 실무자 1,101명을 대상으로 서베이를 돌리고 2026년 데이터 엔지니어링 트렌드를 발표했다. 대규모 플랫폼 데이터 엔지니어링 팀을 이끄는 입장에서 이 트렌드를 우리 팀 아키텍처와 대조하며 잘하고 있는것과 앞으로 해야 할것을 정리해본다.\n우리 아키텍처 한 줄 요약 # S3를 중심 데이터 레이크로 두고 Apache Iceberg 테이블 포맷 위에 Trino(배치/애드혹 분석)와 StarRocks(실시간 OLAP)를 얹은 하이브리드 구조다. 수집은 Kafka + Debezium CDC와 Flink 스트리밍으로 처리하고 오케스트레이션은 Airflow를 깊이 커스터마이징해서 운영한다.\n[Services] → Kafka + Debezium CDC → Flink → S3 (Iceberg) ↓ ┌─────┴─────┐ │ │ Trino StarRocks (배치/애드혹) (실시간 OLAP) │ │ └─────┬─────┘ ↓ Dashboard 1. AI 활용 — 이미 하고 있는것과 넘어야 할 벽 # 트렌드 요약 # 서베이 응답자 82%가 AI를 매일 쓰지만 64%는 아직 실험 단계나 단순 작업에만 머물러있다. Joe Reis는 2026년 말이면 \u0026ldquo;AI-assisted\u0026quot;라는 수식어가 직무 기술에서 사라질 거라 예측한다.\n우리가 하고 있는 것 # AI 코딩 도구로 파이프라인을 개발하는 건 이미 일상이다. SQL 최적화나 코드 리뷰, 트러블슈팅에 LLM을 쓰고 있고 데이터 카탈로그와 연계한 자연어 기반 데이터 탐색도 시도하고있다.\n해야 할 것 # 개인 단위로 AI를 쓰는 수준을 넘어 팀 워크플로우 전체에 AI를 심는 게 과제다.\n파이프라인 이상 감지 자동화 스키마 변경에 자동 대응 데이터 품질 룰 자동 생성 Joe Reis가 말한 \u0026ldquo;10%의 AI-mature 팀\u0026quot;에 들려면 AI를 단순 보조 도구가 아닌 플랫폼 자체를 구성하는 요소로 녹여야 한다.\n2. 데이터 모델링 위기와 시맨틱 레이어 — 가장 큰 숙제 # 트렌드 요약 # 응답자 89%가 데이터 모델링에서 고통을 호소하고 시맨틱 모델을 쓰는 팀은 고작 5%다. Joe Reis는 시맨틱 레이어가 먼저 주류가 된 뒤 LLM이 스키마를 즉석에서 해석하는 방향으로 갈 거라 본다.\n우리가 하고 있는 것 # 데이터 카탈로그로 리니지와 메타데이터를 관리하고 있고 테이블 레이어 체계(L1/L2/L3)를 정의해 품질을 계층적으로 관리하려 한다. Airflow 커스텀 오퍼레이터를 통해 데이터 검증을 자동화하는 것도 운영 중이다.\n해야 할 것 # dbt 도입을 검토했으나 차세대 데이터 플랫폼 전환과 맞물려 중단된 상태다. 기존 파이프라인을 dbt로 이관하기보다 새 플랫폼으로 바로 이관하는 쪽을 검토하고 있는데 그 사이 데이터 변환을 표준화하고 모듈화하는 작업이 공백으로 남아있다. Joe Reis가 말한 \u0026ldquo;89%의 고통\u0026quot;과 정확히 겹친다.\n시맨틱 레이어도 손을 못 대고 있다. 비즈니스 메트릭 정의가 팀마다 다르고 같은 지표인데 SQL이 제각각인 문제가 있다. 서베이에서 시맨틱 모델 교육 수요가 19%로 높게 나온 것처럼 조직 전체가 데이터를 읽는 수준을 끌어올리는 일이 시급하다.\nAI 에이전트가 데이터를 자율적으로 활용하는 미래를 대비하면 잘 정의된 시맨틱 레이어는 선택이 아니라 필수다. 플랫폼 전환이 밀리더라도 모델링 표준과 시맨틱 정의는 따로 진행할 수 있고 진행해야 한다.\n3. 오케스트레이션 통합 — Airflow의 미래 # 트렌드 요약 # Airflow가 아직 지배적이지만 Dagster가 소규모 기업에서 12% 점유율을 보이며 바텀업으로 성장하고 있다. 오케스트레이션이 아예 없는 팀이 기업 규모와 상관없이 20%라는 점도 놀랍다.\n우리가 하고 있는 것 # Airflow를 깊이 커스터마이징해서 쓰고 있다. 자체 Provider 패키지를 만들었고 데이터 검증 자동화 오퍼레이터, 커스텀 전송 오퍼레이터 등 플랫폼에 맞는 기능을 직접 구현했다. 지금은 Airflow 3.x 메이저 버전 업그레이드를 진행하면서 Python 버전 업그레이드와 Breaking Change 대응을 계획하고 있다.\n해야 할 것 # Airflow에 깊이 투자한 건 강점이면서 동시에 기술 부채이기도 하다.\n커스텀 Provider 유지보수 부담 버전 업그레이드 때마다 호환성 이슈 여기에 AI 에이전트 오케스트레이션이라는 새 패러다임까지 대비해야 한다. Joe Reis가 예측한 대로 오케스트레이션이 플랫폼에 흡수되는 흐름도 지켜봐야 하고. 차세대 데이터 플랫폼과 맞물리는걸 고려하면 오케스트레이션 중장기 로드맵을 세우는 일이 시급하다.\n4. Lakehouse vs. Warehouse — 이미 답을 낸 영역 # 트렌드 요약 # 서베이에서 44%가 Warehouse, 27%가 Lakehouse, 12%가 Hybrid를 쓴다. Snowflake과 Databricks 기능이 수렴하면서 이 논쟁 자체가 의미를 잃어가고 있다. Joe Reis는 2026년 말이면 \u0026ldquo;warehouse vs. lakehouse\u0026rdquo; 논쟁이 구식으로 느껴질 거라 예측한다.\n우리가 하고 있는 것 # 여기서 우리 팀은 이미 정답에 가깝다. S3 위에 Iceberg 오픈 테이블 포맷을 표준으로 채택하고 용도에 따라 Trino와 StarRocks를 골라 쓰는 구조는 Warehouse도 Lakehouse도 아닌 양쪽 장점을 취한 아키텍처다. CDC 파이프라인으로 실시간 데이터를 Iceberg 테이블에 적재하고 배치와 실시간 분석을 같은 데이터 위에서 돌릴 수 있다.\n해야 할 것 # Iceberg v3의 Deletion Vector, Row Lineage 같은 새 기능을 쓰려면 쿼리 엔진 전반에서 호환성을 확보해야 한다. 지금 Trino와 StarRocks의 Iceberg v3 지원이 제한적이라 엔진 업그레이드 로드맵과 Iceberg 버전 전략을 연계해야 한다. 오픈 테이블 포맷 기반 아키텍처 거버넌스—카탈로그 통합, 접근 제어, 품질 보장—도 더 강화할 필요가 있다.\n5. 리더십이 병목이 되는 문제 — 가장 어렵고 가장 중요한 과제 # 트렌드 요약 # 데이터 엔지니어 22%가 \u0026ldquo;리더십 방향 부재\u0026quot;를 주요 이슈로 꼽았다. 레거시 기술 부채(26%)에 버금가는 수치다. Joe Reis는 2026년에 더 많은 데이터 팀이 해체되거나 엔지니어링 조직에 합병될 거라 경고한다.\n우리가 하고 있는 것 # 데이터 플랫폼 팀이 독립 조직으로 존재하며 인프라부터 수집, 변환, 분석 환경까지 End-to-End로 책임진다. 비즈니스 팀과 직접 소통하며 데이터 요건을 수렴하고 있다.\n해야 할 것 # 기술력만으로는 팀이 존재하는 이유를 증명할 수 없다. Joe Reis가 강조한 대로 \u0026ldquo;비즈니스 가치를 증명한 팀만 살아남는다.\u0026rdquo;\n데이터 플랫폼 ROI를 숫자로 측정하고 소통하는 체계 수립 AI 시대에 데이터 플랫폼이 맡을 역할에 대한 비전 수립 데이터 옵저버빌리티를 도입해 다운타임 줄이기 파이프라인 개발 생산성을 지표화해서 비즈니스 임팩트 보여주기 정리. 잘 하고 있는 것 vs. 해야 할 것 # 영역 잘 하고 있는 것 해야 할 것 AI 활용 개인 단위 AI 코딩 도구 적극 활용 팀 워크플로우에 AI 임베드, 운영 자동화 데이터 모델링 카탈로그 기반 메타데이터 관리, 레이어 체계 정의 시맨틱 레이어 도입, 데이터 변환 표준화 오케스트레이션 Airflow 깊은 커스터마이징, 3.x 업그레이드 진행 장기 오케스트레이션 전략, AI 에이전트 대응 Lakehouse/Warehouse Iceberg 기반 하이브리드 아키텍처 구축 완료 Iceberg v3 호환성, 거버넌스 체계 강화 리더십 End-to-End 플랫폼 팀 운영 비즈니스 임팩트 정량화, 데이터 옵저버빌리티 마치며 # Joe Reis 서베이에서 가장 인상적이었던 문장이 있다.\n\u0026ldquo;2026년 데이터 엔지니어링은 올바른 도구를 고르는 것보다 그 도구를 잘 활용할 조직적 근육을 키우는 게 더 중요하다.\u0026rdquo;\n우리 팀은 기술 스택 면에서 트렌드 앞쪽에 서 있다. Iceberg 기반 오픈 데이터 레이크, 실시간과 배치를 아우르는 하이브리드 아키텍처, 깊이 있는 Airflow 커스터마이징. 아직 여기까지 못 온 조직이 많다.\n하지만 기술적 우위만으로는 부족하다. 데이터 변환 표준화, 시맨틱 레이어, 데이터 옵저버빌리티, AI 네이티브 워크플로우. 그리고 무엇보다 비즈니스 가치를 증명하는 리더십. 2026년에 우리가 집중해야 할 방향이다.\n과거의 빚은 이자를 물고 있고 페이데이가 다가오고 있다.\n원문 참고: Where Data Engineering Is Heading in 2026 — Joe Reis\n","date":"2026년 2월 23일","externalUrl":null,"permalink":"/posts/2026-data-engineering-trends/","section":"글 목록","summary":"Joe Reis의 1,101명 서베이를 기반으로 한 2026년 데이터 엔지니어링 트렌드를 대규모 플랫폼 데이터 엔지니어링 팀의 현재 아키텍처와 대조하며 정리했습니다. 이미 잘 하고 있는 것과 앞으로 해야 할 것을 솔직하게 돌아봅니다.","title":"2026 데이터 엔지니어링 트렌드와 대규모 플랫폼의 현주소","type":"posts"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/ai/","section":"Tags","summary":"","title":"Ai","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/airflow/","section":"Tags","summary":"","title":"Airflow","type":"tags"},{"content":"Airflow 2.x End of Life가 2026년 4월 22일로 다가오고 있다. 우리 팀은 수백 개 DAG을 운영하는 프로덕션 환경에서 Airflow 3.x 마이그레이션을 진행했다. 그 과정에서 마주친 Breaking Changes와 단계적 업그레이드 전략, 대규모 DAG 환경에서 얻은 실전 교훈을 정리한 기록이다.\n왜 지금 마이그레이션해야 하는가 # Airflow 3.x에서 바뀐 것 # Airflow 3.x는 단순한 메이저 버전 업데이트가 아니다. 아키텍처 수준에서 큰 변화가 있었다.\nDAG 버전 관리. dag_id에 버전 서픽스를 붙이거나 스케줄 변경 시 스케줄링이 꼬이던 문제에서 해방된다. 네이티브 백필. CLI나 커스텀 플러그인에 의존하던 백필을 웹 UI에서 바로 실행할 수 있다. 이벤트/애셋 기반 트리거. 단순 cron 표현식을 넘어서 여러 스케줄링 방식을 쓸 수 있게 됐다. React 기반 웹 UI. Flask App Builder 기반에서 React로 전면 개편됐고 사용성이 많이 좋아졌다. 아키텍처 변화. API Server 등장 # 3.x에서 가장 큰 아키텍처 변화는 API Server가 메타 DB에 접근하는 유일한 관문이 됐다는 점이다.\nAirflow 2.x: Webserver ─── MetaDB Worker ────── MetaDB Scheduler ─── MetaDB DAG Code ──── MetaDB (직접 접근 가능) Airflow 3.x: API Server ── MetaDB (유일한 접근 경로) Webserver ─── API Server Worker ────── API Server Scheduler ─── API Server DAG Code ──── API Server (직접 접근 불가) 이 변화 때문에 DAG 최상위 코드에서 메타 DB에 직접 접근하던 패턴이 전부 깨진다. 마이그레이션에서 가장 영향이 큰 변경사항이다.\n사실 이 패턴은 2.x에서도 안티패턴이었다. DAG 최상위에서 Variable.get()이나 Connection.get_connection_from_secrets()를 호출하면 스케줄러가 DAG을 파싱할 때마다 DB 쿼리가 발생한다. DAG이 수백 개면 파싱 루프 한 바퀴에 DB 호출이 수천 번 일어날 수도 있다. 2.x에서는 모든 컴포넌트가 메타 DB에 직접 연결되어 있어서 동작은 했고 deprecation 경고만 뜨다보니 고칠 동기가 약했다. 3.x는 아키텍처 수준에서 이 안티패턴을 강제로 차단한 셈이다.\n# ❌ 안티패턴: DAG 파싱 시점에 DB를 찌르는 코드 my_var = Variable.get(\u0026#34;some_config\u0026#34;) # ✅ 올바른 방식: Jinja 템플릿으로 태스크 실행 시점에 접근 task = PythonOperator( task_id=\u0026#34;my_task\u0026#34;, python_callable=my_func, op_kwargs={\u0026#34;config\u0026#34;: \u0026#34;{{ var.value.some_config }}\u0026#34;}, ) 단계적 업그레이드 전략 # 한 번에 최신 버전으로 올리는 건 위험하다. 우리는 네 단계로 나눠서 접근했다.\n1단계. 2.x 최신 버전(2.11)으로 업데이트 (선택) # 3.x로 직접 올리다가 이슈가 생길 경우를 대비한 안전장치다. 2.11에서는 3.x에서 제거될 기능에 대한 deprecation 경고가 표시되므로 수정 대상 코드를 미리 파악할 수 있다.\n2단계. 3.0.x로 업데이트 # Python 3.9 환경에서는 최신 3.1.x가 아닌 3.0.x까지만 지원된다. Python 버전을 올리기 전에 Airflow 메이저 버전을 먼저 올린다.\n3단계. Python 버전 업그레이드 (3.9 → 3.12+) # Airflow 3.1.x는 Python 3.9를 지원하지 않는다. Python 3.12 이상을 목표로 하되 의존성 호환 이슈가 있으면 3.10이나 3.11로 타협한다.\n4단계. 3.1.x로 업데이트 # 최종적으로 최신 stable 릴리스로 올린다.\n환경별 순차 적용 # DEV → BETA \u0026amp; 개인환경 → STAGE → PROD 각 환경에서 충분히 검증한 후 다음 환경으로 넘어간다. DEV 환경에서 약 2주, BETA에서 1주간 검증했다.\nBreaking Changes와 대응 방법 # 1. schedule_interval → schedule # 가장 흔하게 마주치는 변경사항이다. 기존 schedule_interval에 전달하던 cron 표현식을 그대로 schedule에 넘기면 된다.\n# Before (Airflow 2.x) DAG( dag_id=\u0026#34;my_dag\u0026#34;, schedule_interval=\u0026#34;5 2 * * *\u0026#34;, ) # After (Airflow 3.x) DAG( dag_id=\u0026#34;my_dag\u0026#34;, schedule=\u0026#34;5 2 * * *\u0026#34;, ) 단순 치환이지만 DAG 수가 수백 개라면 누락 없이 전부 바꿔야 한다. CI에서 자동으로 검증하는 방법은 뒤에서 다룬다.\n2. 존재하지 않는 오퍼레이터 인자 전달 불가 # Airflow 3.x에서는 개별 태스크가 메타 DB상에 시리얼라이즈된 DAG을 받아 실행하는 구조로 바뀌었다. allow_illegal_arguments 설정이 제거되면서 오퍼레이터에 정의되지 않은 인자를 전달하면 DAG 임포트 자체가 실패한다.\n# 이런 코드가 2.x에서는 경고 없이 동작했지만, 3.x에서는 에러가 발생한다 MyOperator( task_id=\u0026#34;my_task\u0026#34;, num_partition=10, # 실제 인자명은 num_partitions (복수형) ) TypeError: Invalid arguments were passed to MyOperator (task_id: my_task). Invalid arguments were: **kwargs: {\u0026#39;num_partition\u0026#39;: 10} 이 변경은 오히려 잠재적 버그를 발견하는 계기가 된다. 오랫동안 오타가 있는 인자가 무시되고 있었다면 이번에 바로잡을 수 있다.\n3. Deprecated 컨텍스트/템플릿 변수 제거 # 2.x에서 deprecated 경고만 뜨던 변수가 3.x에서는 완전히 제거됐다. 가장 영향이 큰 건 execution_date다.\nDeprecated 변수 대체 변수 {{ execution_date }} {{ logical_date }} 또는 {{ data_interval_start }} {{ next_execution_date }} {{ data_interval_end }} {{ prev_execution_date_success }} {{ prev_data_interval_start_success }} Jinja 템플릿과 Python 코드 양쪽 모두 수정해야 한다.\n# Jinja 템플릿 # Before \u0026#34;SELECT * FROM table WHERE dt = \u0026#39;{{ execution_date }}\u0026#39;\u0026#34; # After \u0026#34;SELECT * FROM table WHERE dt = \u0026#39;{{ logical_date }}\u0026#39;\u0026#34; # Python context # Before execution_date = context[\u0026#34;execution_date\u0026#34;] # After logical_date = context[\u0026#34;logical_date\u0026#34;] 4. DB별 Operator 통합 → SQLExecuteQueryOperator # MySQL, PostgreSQL, Trino 등 DB별로 따로 있던 Operator가 SQLExecuteQueryOperator 하나로 합쳐졌다. 내부적으로 커넥션 타입에 따라 적절한 Hook을 알아서 골라 쓴다.\n# Before (Airflow 2.x) from airflow.providers.mysql.operators.mysql import MySqlOperator MySqlOperator( task_id=\u0026#34;task\u0026#34;, mysql_conn_id=\u0026#34;my_conn\u0026#34;, sql=\u0026#34;SELECT 1\u0026#34; ) # After (Airflow 3.x) from airflow.providers.common.sql.operators.sql import SQLExecuteQueryOperator SQLExecuteQueryOperator( task_id=\u0026#34;task\u0026#34;, conn_id=\u0026#34;my_conn\u0026#34;, # DB별 conn_id → 통합 conn_id sql=\u0026#34;SELECT 1\u0026#34; ) 5. DummyOperator → EmptyOperator # 2.x와 3.x 양쪽에서 모두 동작하는 임포트 경로를 써야 한다.\n# v2에서만 동작 (3.x에서 에러) from airflow.operators.dummy import DummyOperator # v3에서만 동작 from airflow.providers.standard.operators.empty import EmptyOperator # v2 \u0026amp; v3 모두 호환 (권장) from airflow.operators.empty import EmptyOperator 6. SimpleHttpOperator → HttpOperator # # Before from airflow.providers.http.operators.http import SimpleHttpOperator # After from airflow.providers.http.operators.http import HttpOperator 7. Connection getter 메서드 → 속성 직접 참조 # Connection 클래스 인터페이스가 좀 더 Pythonic하게 바뀌었다.\n# Before conn = BaseHook.get_connection(\u0026#34;my_conn\u0026#34;) password = conn.get_password() host = conn.get_host() # After conn = BaseHook.get_connection(\u0026#34;my_conn\u0026#34;) password = conn.password host = conn.host 8. 기타 패키지 경로 변경 # # cached_property # Before: from airflow.compat.functools import cached_property # After: from functools import cached_property (Python 내장) # KubernetesPodOperator # Before: from airflow.providers.cncf.kubernetes.operators.kubernetes_pod import ... # After: from airflow.providers.cncf.kubernetes.operators.pod import ... 9. provide_context=True 제거 # Airflow 2.0부터 PythonOperator에서 context가 자동 주입된다. provide_context=True는 아무 역할도 하지 않는데 남아 있는 코드가 꽤 많다.\n# Before PythonOperator( task_id=\u0026#34;my_task\u0026#34;, python_callable=my_func, provide_context=True, ) # After PythonOperator( task_id=\u0026#34;my_task\u0026#34;, python_callable=my_func, ) 10. from airflow.models import DAG → from airflow import DAG # airflow.models.DAG은 v3에서 deprecated다. from airflow import DAG으로 바꾸면 v2/v3 양쪽 다 동작한다.\n# Before from airflow.models import DAG # After from airflow import DAG from airflow import models 후 models.DAG()으로 쓰는 패턴은 바꿀 필요 없다.\n11. @apply_defaults 데코레이터 제거 # Airflow 2.0부터 BaseOperator가 자동 처리한다. 커스텀 Operator에 남아 있으면 제거하면 된다.\n# Before from airflow.utils.decorators import apply_defaults class CustomOperator(BaseOperator): @apply_defaults def __init__(self, **kwargs): super().__init__(**kwargs) # After class CustomOperator(BaseOperator): def __init__(self, **kwargs): super().__init__(**kwargs) 12. concurrency → max_active_tasks # DAG 파라미터 concurrency가 v3에서 제거된다. 의미는 동일하지만 이름이 더 명확해졌다.\n# Before with DAG(dag_id=\u0026#34;my_dag\u0026#34;, concurrency=5) as dag: # After with DAG(dag_id=\u0026#34;my_dag\u0026#34;, max_active_tasks=5) as dag: 13. TaskInstance 직접 생성 제거 # kwargs[\u0026quot;ti\u0026quot;]가 이미 TaskInstance 객체다. 별도로 생성할 이유가 없다. ti.execution_date 접근과 TaskInstance(task, execution_date) 생성자는 v3에서 deprecated다.\n# Before def my_callable(**kwargs): ti = TaskInstance(kwargs[\u0026#34;ti\u0026#34;].task, kwargs[\u0026#34;ti\u0026#34;].execution_date) ti.xcom_push(key=\u0026#34;my_key\u0026#34;, value=result) # After def my_callable(**kwargs): ti = kwargs[\u0026#34;ti\u0026#34;] ti.xcom_push(key=\u0026#34;my_key\u0026#34;, value=result) 대규모 DAG 환경에서 마이그레이션하기 # ruff로 비호환 항목 자동 검출 # 수백 개 DAG을 눈으로 훑는 건 불가능하다. ruff의 Airflow 전용 규칙을 쓰면 비호환 코드를 자동으로 잡아준다.\n# 특정 파일 검사 ruff check --preview --select AIR dags/my_dag.py # 팀 디렉터리 전체 검사 ruff check --preview --select AIR dags/my_team/ Rule 대상 AIR301 deprecated 데코레이터 (@apply_defaults 등) AIR302 deprecated 파라미터, import 경로, 템플릿 변수 CI 파이프라인에 v3 호환성 검증 추가 # MR(Merge Request) 단계에서 v3 호환성을 자동 검증하는 CI 잡을 추가했다.\n# .gitlab-ci.yml 예시 airflow-v3-compat-check: stage: test image: apache/airflow:3.0.6-python3.12 script: - pip install -r requirements.txt - ruff check --preview --select AIR dags/ - python -m py_compile dags/**/*.py - airflow dags list --output table allow_failure: true # 초기에는 경고만, 이후 필수로 전환 처음에는 allow_failure: true로 시작해서 현황을 파악하고 마이그레이션 기한이 다가오면 필수 검증으로 전환한다.\n실전 수정 이력: 3라운드에 걸친 일괄 수정 # 우리는 전체 DAG 레포지토리에 대해 3차에 걸쳐 비호환 항목을 수정했다.\n차수 변경 파일 수 주요 수정 항목 1차 252개 schedule_interval→schedule, DummyOperator→EmptyOperator 2차 35개 1차 누락분 보완, provide_context 제거, 파라미터 오입력 수정 3차 21개 DAG import 경로, Jinja 템플릿 변수, concurrency→max_active_tasks, TaskInstance 직접 생성 제거 1차에서 252개 파일을 한꺼번에 수정했는데, 그래도 누락이 생겼다. ruff가 잡아주지 못하는 패턴(파라미터 오입력, 사내 커스텀 오퍼레이터의 불필요 인자 등)은 수작업으로 찾아야 했다. 한 번에 끝낼 수 있을 거라고 기대하지 않는 게 좋다.\n이관 허들을 의도적으로 높여라 # 우리가 얻은 가장 큰 교훈이다.\n모든 DAG 코드에 일괄로 호환성 패치를 적용할 수도 있었다. 하지만 의도적으로 이관 난이도를 유지하기로 했다. 이유는 분명하다.\n관성적으로 운영되고 있지만 실제로는 쓰지 않는 DAG이 상당수 존재한다.\n마이그레이션을 계기로 DAG 소유자가 \u0026ldquo;이 DAG이 정말 필요한가?\u0026ldquo;를 스스로 검토하도록 유도한 것이다. 결과적으로 상당수의 불필요한 DAG이 정리됐고 운영 부담도 줄었다.\n구체적으로는 이렇게 진행했다.\n비활성 DAG 목록을 취합해 공유 시트에 정리 DAG 소유자와 소속 부서에 유지 여부를 기한 내 확인하도록 안내 기한 내 응답이 없으면 비활성화 v3 호환성 패치는 소유자가 직접 수행 커스텀 Provider 패키지 선제 대응 # 사내 커스텀 오퍼레이터나 유틸리티를 Provider 패키지로 제공하고 있다면 Airflow 코어의 Breaking Changes를 흡수하는 호환 레이어를 먼저 준비해야 한다.\n커스텀 Provider 패키지를 네 차례에 걸쳐 점진적으로 업데이트했다.\nv3.0.0. 기본 호환성 확보 v3.0.1. 오퍼레이터 인자 검증 대응 v3.0.2. deprecated 컨텍스트 변수 호환 레이어 추가 v3.0.3. 문서 및 마이너 버그 수정 사용자 코드 변경은 최소화하되 Provider 패키지 내부에서 v2/v3 분기 처리를 하는 식으로 접근했다.\nHelm Chart 업데이트 # Kubernetes 환경에서 Airflow를 운영한다면 Helm Chart도 같이 업데이트해야 한다. 3.x에서 도입된 DAG Processor 컴포넌트와 API Server 분리를 반영해야 하기 때문이다.\n기존 차트 버전에서 호환성을 먼저 확인하고 안정화되면 최신 stable 버전으로 올리는 2단계 접근이 안전하다.\nFAB Auth Manager 이슈 # 3.x에서 React 기반으로 웹이 전면 개편되면서 기존 Flask App Builder(FAB) 기반 Auth Manager가 기본 패키지에서 빠졌다. 커스텀 Security Manager를 쓰고 있다면 별도 설치와 코드 수정이 필요하다.\nFailed to import WoowaSecurityManager, using default security manager 이런 에러가 나오면 FAB Auth Manager 패키지를 명시적으로 설치하고 임포트 경로를 업데이트해야 한다.\n마치며 # Airflow 3.x 마이그레이션은 단순한 버전 업그레이드가 아니다. 아키텍처가 바뀌었고 코드 호환성이 깨졌으며 인프라도 같이 손봐야 한다.\n배운 것을 정리하면 이렇다.\n단계적으로 올려라. 한 번에 최신 버전으로 뛰지 말고 2.11 → 3.0.x → Python 업그레이드 → 3.1.x 순서로 진행하라. CI에서 자동 검증하라. 수백 개 DAG 호환성을 사람이 확인하는 건 불가능하다. 마이그레이션을 정리 기회로 삼아라. 이관 허들을 유지해서 불필요한 DAG을 자연스럽게 걸러내라. 커스텀 Provider를 선제 업데이트하라. 사용자 코드 변경을 최소화하는 호환 레이어를 먼저 만들어라. Airflow 2.x EOL까지 아직 시간이 있다고 안심하지 말자. 대규모 환경에서 마이그레이션은 예상보다 오래 걸린다. 지금 시작해도 늦지 않다.\n참고 자료\nUpgrading to Airflow 3 - Apache Airflow Documentation Apache Airflow 3 is Generally Available! Airflow 3.x Release Notes ","date":"2026년 2월 23일","externalUrl":null,"permalink":"/posts/airflow-3-migration-guide/","section":"글 목록","summary":"Airflow 2.x EOL을 앞두고 3.x로 마이그레이션한 실전 경험을 공유한다. Breaking Changes, 단계적 업그레이드 전략, DAG 호환성 확보 방법, 수백 개 DAG을 운영하는 환경에서 배운 교훈을 정리했다.","title":"Airflow 3.0 마이그레이션 가이드: 대규모 DAG 환경에서의 실전 경험","type":"posts"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/bali/","section":"Tags","summary":"","title":"Bali","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/compression/","section":"Tags","summary":"","title":"Compression","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/data-engineering/","section":"Tags","summary":"","title":"Data-Engineering","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/data-pipeline/","section":"Tags","summary":"","title":"Data-Pipeline","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/digital-nomad/","section":"Tags","summary":"","title":"Digital-Nomad","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/family/","section":"Tags","summary":"","title":"Family","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/gpu/","section":"Tags","summary":"","title":"Gpu","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/infrastructure/","section":"Tags","summary":"","title":"Infrastructure","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/categories/life/","section":"Categories","summary":"","title":"Life","type":"categories"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/mig/","section":"Tags","summary":"","title":"Mig","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/migration/","section":"Tags","summary":"","title":"Migration","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/nvidia/","section":"Tags","summary":"","title":"Nvidia","type":"tags"},{"content":"GPU가 비싸다. A100 한 장이 수천만 원인데 대부분의 워크로드는 80GB 메모리를 다 쓰지 않는다. Jupyter 노트북에서 간단한 실험 돌리는 데 GPU 한 장을 통째로 할당하면 나머지 70GB는 그냥 놀게 된다.\nNVIDIA MIG(Multi-Instance GPU)는 이 문제를 풀어준다. 물리 GPU 하나를 최대 7개 독립 인스턴스로 쪼개서 여러 워크로드가 동시에 돌아간다. 이 글은 A100 GPU 4장 환경에서 MIG를 설정하고 Kubernetes까지 연동한 과정을 기록한 것이다.\nMIG란 무엇인가 # MIG는 하나의 물리 GPU를 여러 독립 GPU 인스턴스로 분할하는 기술이다. 각 인스턴스가 자체 메모리와 컴퓨트 유닛을 갖고있어서 서로 간섭하지 않는다. 한 인스턴스에서 OOM이 나도 다른 인스턴스에는 영향이 없다.\nA100 80GB 기준 분할 옵션은 이렇다.\n프로필 메모리 SM 수 GPU당 최대 인스턴스 1g.10gb ~10GB 14 7 2g.20gb ~20GB 28 3 3g.40gb ~40GB 42 2 7g.80gb ~80GB 98 1 7분할(1g.10gb)을 하면 GPU 4장에서 인스턴스 28개가 나온다. 단순 계산으로 GPU 활용률이 4배 이상 올라간다.\n지원 GPU 확인 # MIG는 A100, H100 등 특정 GPU에서만 쓸 수 있다. A40이나 V100은 MIG를 지원하지 않는다. 우리도 처음에 A40 서버에서 시도했다가 안 되는 걸 확인하고 A100 서버로 전환했다.\nnvidia-smi 출력에서 MIG M. 컬럼을 확인하면 된다.\n# MIG 미지원 GPU (A40) | MIG M. | | N/A | ← 지원하지 않음 # MIG 지원 GPU (A100) | MIG M. | | Disabled | ← 지원하지만 비활성화 상태 | Enabled | ← 활성화됨 지원 GPU 목록은 NVIDIA 공식 문서에서 확인할 수 있다.\nMIG 설정하기 # 사전 준비. nvidia-mig-manager 비활성화 # MIG를 켜기 전에 nvidia-mig-manager.service를 반드시 비활성화해야 한다. 이 데몬이 부팅할 때마다 MIG를 disabled로 되돌린다.\nsudo systemctl disable nvidia-mig-manager.service mig-parted 설치 # nvidia-mig-parted는 NVIDIA에서 제공하는 MIG 설정 도구다. 선언적으로 config 파일을 작성하면 원하는 분할 구성을 한번에 적용해준다.\n# deb 패키지 설치 (Ubuntu/Debian) curl -LO https://github.com/NVIDIA/mig-parted/releases/download/v0.5.2/nvidia-mig-manager_0.5.2-1_amd64.deb sudo dpkg -i nvidia-mig-manager_0.5.2-1_amd64.deb MIG 모드 활성화 # sudo nvidia-smi -mig 1 이 명령을 실행하면 MIG 모드가 pending 상태가 된다. 적용하려면 리부트가 필요하다.\nsudo reboot VM 환경 주의사항. GPU passthrough로 사용하는 가상머신에서는 nvidia-smi --gpu-reset을 지원하지 않는다. 리부트 없이 MIG를 활성화할 수 없으므로 베어메탈 서버를 쓰는 게 좋다. 우리도 이 문제 때문에 VM에서 베어메탈로 옮겼다.\nconfig.yaml 작성 # mig-parted는 YAML 파일로 분할 구성을 선언한다. 한 파일에 여러 프리셋을 정의해놓고 필요할 때 골라 쓸 수 있다.\nversion: v1 mig-configs: # MIG 비활성화 all-disabled: - devices: all mig-enabled: false # 전체 GPU를 7분할 (1g.10gb × 7) all-1g.10gb: - devices: all mig-enabled: true mig-devices: \u0026#34;1g.10gb\u0026#34;: 7 # 전체 GPU를 3분할 (2g.20gb × 3) all-2g.20gb: - devices: all mig-enabled: true mig-devices: \u0026#34;2g.20gb\u0026#34;: 3 # 전체 GPU를 2분할 (3g.40gb × 2) all-3g.40gb: - devices: all mig-enabled: true mig-devices: \u0026#34;3g.40gb\u0026#34;: 2 # GPU를 통째로 사용 (7g.80gb × 1) all-7g.80gb: - devices: all mig-enabled: true mig-devices: \u0026#34;7g.80gb\u0026#34;: 1 # GPU별로 다른 분할 구성 custom-config: - devices: [0] mig-enabled: true mig-devices: \u0026#34;3g.40gb\u0026#34;: 2 - devices: [1] mig-enabled: true mig-devices: \u0026#34;2g.20gb\u0026#34;: 3 \u0026#34;1g.10gb\u0026#34;: 1 - devices: [2] mig-enabled: true mig-devices: \u0026#34;2g.20gb\u0026#34;: 3 \u0026#34;1g.10gb\u0026#34;: 1 - devices: [3] mig-enabled: true mig-devices: \u0026#34;1g.10gb\u0026#34;: 7 마지막 custom-config가 포인트다. GPU마다 다른 프로필을 섞어서 구성할 수 있다. 왜 이렇게 해야하는지는 뒤에서 설명한다.\n설정 적용 # # 균일한 7분할 적용 sudo nvidia-mig-parted apply -f ./config.yaml -c all-1g.10gb # 또는 커스텀 구성 적용 sudo nvidia-mig-parted apply -f ./config.yaml -c custom-config -d 플래그를 추가하면 디버그 로그를 볼 수 있다. 적용이 끝나면 nvidia-smi -L로 인스턴스 목록을 확인한다.\nGPU 0: NVIDIA A100-SXM4-80GB (UUID: GPU-xxxx) MIG 3g.40gb Device 0: (UUID: MIG-xxxx) MIG 3g.40gb Device 1: (UUID: MIG-xxxx) GPU 1: NVIDIA A100-SXM4-80GB (UUID: GPU-xxxx) MIG 2g.20gb Device 0: (UUID: MIG-xxxx) MIG 2g.20gb Device 1: (UUID: MIG-xxxx) MIG 2g.20gb Device 2: (UUID: MIG-xxxx) MIG 1g.10gb Device 3: (UUID: MIG-xxxx) ... 재부팅 시 자동 적용 # MIG 설정은 재부팅하면 날아간다. systemd 서비스로 등록해서 부팅할 때 자동으로 적용되게 만든다.\n# /etc/systemd/system/nvidia-mig-config.service [Unit] Description=Apply NVIDIA MIG Configuration After=nvidia-persistenced.service [Service] Type=oneshot ExecStart=/usr/bin/nvidia-mig-parted apply -f /home/user/config.yaml -c custom-config RemainAfterExit=yes [Install] WantedBy=multi-user.target sudo systemctl daemon-reload sudo systemctl enable nvidia-mig-config.service 실전에서 배운 것. 균일 분할로는 부족하다 # 처음에는 단순하게 생각했다. GPU 4장을 전부 1g.10gb × 7로 쪼개면 인스턴스 28개가 나온다. 가장 많은 사용자가 동시에 쓸 수 있으니 좋지 않을까?\n큰 모델은 MIG에서 안 돌아간다 # 현실은 달랐다. 추천 모델 학습하는 팀에서 문제가 터졌다. 모델이 GPU 메모리를 30GB 넘게 쓰는데 MIG 인스턴스 하나는 10GB밖에 없으니 CUDA OOM으로 로드 자체가 안 됐다.\nLLM도 마찬가지였다. Llama 2 7B 모델은 4bit 양자화를 해도 MIG 디바이스에서 로드가 안 됐다. 13B은 말할것도 없다.\n결론은 명확하다. 워크로드에 따라 분할 전략을 다르게 가져가야 한다.\nGPU별 커스텀 분할 # 팀 내 워크로드를 분석해보니 이런 구성이 됐다.\nGPU 프로필 용도 GPU 0 3g.40gb × 2 중형 모델 학습 (메모리 40GB급) GPU 1 2g.20gb × 3 + 1g.10gb × 1 중소형 실험 GPU 2 2g.20gb × 3 + 1g.10gb × 1 중소형 실험 GPU 3 1g.10gb × 7 Jupyter 노트북, 가벼운 배치 작업 대형 모델 학습이 필요하면 MIG를 꺼둔 GPU를 별도로 남겨두는 방법도 있다. 우리는 LLM 실험 수요가 늘면서 일부 GPU의 MIG를 끄기도 했다.\n주의. MIG 슬라이스를 섞어 구성할 때 물리적 제약이 있다. GPU 내부 메모리 슬라이스는 왼쪽에서 오른쪽으로 할당되며 수직으로 공유할 수 없다. NVIDIA 공식 문서에서 지원하는 조합을 꼭 확인해야 한다.\nKubernetes 연동 # MIG 인스턴스를 Kubernetes에서 쓰려면 NVIDIA device plugin 설정을 바꿔야 한다.\nMIG Strategy 이해하기 # device plugin에는 세 가지 MIG 전략이 있다.\n전략 리소스 이름 설명 none nvidia.com/gpu MIG를 인식하지 않음. 물리 GPU 단위 할당 single nvidia.com/gpu MIG 인스턴스를 자동 할당. 기존 워크로드 호환 mixed nvidia.com/mig-{profile} MIG 프로필별로 별도 리소스 노출 single 전략은 기존 워크로드가 nvidia.com/gpu: 1로 요청하던 걸 수정 없이 MIG 인스턴스로 연결해준다. 편하긴 한데 어떤 크기의 인스턴스를 받을지 제어할 수가 없다.\nmixed 전략은 nvidia.com/mig-3g.40gb: 1처럼 프로필을 명시해서 요청한다. GPU별로 다른 분할을 쓴다면 mixed가 맞다.\ndevice plugin 설정 변경 # # values.yaml migStrategy: mixed helm upgrade -i nvdp nvdp/nvidia-device-plugin \\ --namespace nvidia-device-plugin \\ --create-namespace \\ --version 0.12.3 \\ -f ./values.yaml 적용 후 nvidia-device-plugin Pod를 재시작해야 노드 리소스에 반영된다. kubectl describe node로 MIG 리소스가 보이는지 확인한다.\nAllocatable: nvidia.com/mig-1g.10gb: 9 nvidia.com/mig-2g.20gb: 6 nvidia.com/mig-3g.40gb: 2 JupyterHub에서 MIG 사용 # JupyterHub 프로필에서 리소스 요청을 MIG 타입으로 바꾼다.\n# 변경 전 (물리 GPU 할당) extra_resource_limits: nvidia.com/gpu: \u0026#34;1\u0026#34; # 변경 후 (MIG 인스턴스 할당) extra_resource_limits: nvidia.com/mig-1g.10gb: \u0026#34;1\u0026#34; mixed 전략에서 nvidia.com/gpu: 1을 요청하면 물리 GPU 전체가 할당되니까 주의해야 한다. MIG 인스턴스를 쓰려면 반드시 프로필 이름을 명시해야 한다.\nAirflow KubernetesPodOperator에서 MIG 사용 # Airflow에서 GPU 작업 실행할 때도 리소스 요청을 MIG 타입으로 바꾼다.\nresources = { \u0026#34;cpu\u0026#34;: \u0026#34;4\u0026#34;, \u0026#34;memory\u0026#34;: \u0026#34;16Gi\u0026#34;, \u0026#34;nvidia.com/mig-2g.20gb\u0026#34;: \u0026#34;1\u0026#34;, } KubernetesPodOperator( ... container_resources=k8s.V1ResourceRequirements( requests=resources, limits=resources, ), ... ) 운영 팁 # MIG 설정 변경 타이밍 # MIG 구성을 바꾸려면 그 GPU의 모든 프로세스를 종료해야 한다. 운영 환경에서는 배치 작업이 없는 시간대를 골라서 작업한다. 우리는 배치 스케줄이 새벽 4시 이후에 몰려 있어서 밤 9시 이후에 MIG 재설정을 진행했다.\n서버 전체 GPU에 MIG를 걸어야 한다 # 한 서버에서 일부 GPU만 MIG를 켜고 나머지는 끄는 구성은 동작하지 않는다. 서버 안의 모든 GPU가 MIG enabled이거나 전부 disabled여야 한다. 대형 모델 학습용으로 MIG 없는 GPU가 필요하면 별도 서버를 쓰거나 MIG config에서 7g.80gb: 1로 설정해서 GPU 전체를 하나의 인스턴스로 노출하면 된다.\nGPU Capacity 변화 # MIG 적용 전후로 Kubernetes 클러스터의 GPU capacity가 크게 달라진다. 우리 환경에서는 GPU 4장(capacity 4)이 MIG 적용 후 인스턴스 기준으로 20개 이상이 됐다. 모니터링이랑 알럿 기준을 같이 조정해야 한다.\n마치며 # MIG는 GPU 활용률을 높이는 괜찮은 방법이다. 만능은 아니다. 실전에서 배운걸 정리하면 이렇다.\n지원 GPU를 먼저 확인하라. A100, H100 같은 특정 모델만 MIG를 지원한다. A40이나 V100은 안 된다. VM 환경은 피하라. GPU passthrough에서는 GPU reset이 안 돼서 MIG 활성화가 까다롭다. 베어메탈이 편하다. 균일 분할로 시작하되 커스텀 분할로 넘어가라. 워크로드를 분석해서 GPU별로 프로필을 섞는 게 실용적이다. 대형 모델은 MIG로 안 된다. LLM이나 대규모 추천 모델은 GPU 전체 메모리가 필요하다. MIG 없는 GPU를 따로 확보해야 한다. GPU는 비싸지만 잘 쪼개면 기존 인프라에서 더 많은걸 해낼 수 있다.\n참고 자료.\nNVIDIA MIG User Guide nvidia-mig-parted (GitHub) NVIDIA Device Plugin for Kubernetes Getting the Most Out of the A100 GPU with MIG ","date":"2026년 2월 23일","externalUrl":null,"permalink":"/posts/nvidia-mig-setup-guide/","section":"글 목록","summary":"A100 GPU 4장으로 최대 28개의 독립 GPU 인스턴스를 만들 수 있다. MIG 개념부터 mig-parted 설치, 슬라이스 구성, Kubernetes 연동까지 실전 경험을 정리했다.","title":"NVIDIA MIG 설정 가이드. A100 GPU 하나를 여러 개로 쪼개 쓰기","type":"posts"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/olap/","section":"Tags","summary":"","title":"Olap","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/open-source/","section":"Tags","summary":"","title":"Open-Source","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/optimization/","section":"Tags","summary":"","title":"Optimization","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/orchestration/","section":"Tags","summary":"","title":"Orchestration","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/performance-tuning/","section":"Tags","summary":"","title":"Performance-Tuning","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/python/","section":"Tags","summary":"","title":"Python","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/real-time/","section":"Tags","summary":"","title":"Real-Time","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/remote-work/","section":"Tags","summary":"","title":"Remote-Work","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/ruff/","section":"Tags","summary":"","title":"Ruff","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/starburst/","section":"Tags","summary":"","title":"Starburst","type":"tags"},{"content":"Trino를 프로덕션 쿼리 엔진으로 운영하는 팀이라면 2025년 한 해 동안 느꼈을 거다. 릴리스가 뜸해졌다. 감각이 아니라 숫자로 드러나는 변화다. 2024년 30개였던 Trino 오픈소스 릴리스가 2025년에는 11개로 줄었다. 63% 감소.\n이 글에서는 Starburst가 왜, 어떻게 AI 중심 플랫폼 기업으로 전환했는지 살펴보고 Trino 오픈소스를 쓰는 입장에서 이 변화를 어떻게 바라봐야 하는지 정리한다.\nTrino 릴리스, 무슨 일이 일어났나 # 릴리스 빈도가 급격히 줄었다 # Trino 오픈소스 릴리스 패턴을 분기별로 보면 감소 추세가 뚜렷하다.\n기간 릴리스 수 평균 주기 비고 2024 Q4 9개 주 1회 안정적 패턴 2025 Q1 6개 2주 1회 감소 시작 2025 Q2 2개 월 1회 급격한 감소 2025 Q3 1개 분기 1회 최저점 2025 Q4 2개 1.5개월 1회 여전히 저조 2024년 Q4까지만 해도 매주 새 릴리스가 나왔다. 그런데 2025년 Q2부터 월 1회 수준으로 떨어졌고 Q3에는 분기 통틀어 릴리스가 단 1개였다. Starburst Enterprise 릴리스도 마찬가지로 극소수에 그쳤다.\n숫자만 놓고 보면 심각해 보이지만 Trino가 \u0026ldquo;쇠퇴\u0026quot;한다는 뜻은 아니다. Starburst가 내린 전략적 선택이다.\n왜 줄었는가 # Trino 오픈소스에 Starburst가 얼마나 기여했는지 보면 답이 나온다. 2024년 기준 Starburst 팀이 Trino 전체 커밋의 84% 를 차지했다. 기여자 138명에 커밋 2,822개, 참여 기업 50곳 이상이었지만 실질적인 개발 동력은 Starburst였다. 그 Starburst가 엔지니어링 리소스를 다른 곳에 쏟기 시작한 거다.\n그 \u0026ldquo;다른 곳\u0026quot;이 바로 AI다.\nStarburst의 AI 피벗 # 포지셔닝이 바뀌었다 # Starburst 공식 메시징 변화를 추적해보면 전환이 얼마나 의도적이었는지 알 수 있다.\n시기 포지셔닝 핵심 메시지 ~2023 Open Data Lakehouse Company Trino 기반 분산 쿼리 엔진 2024 Data Lake Analytics Platform 페더레이션 쿼리 + Iceberg 2025 Data Platform for Apps and AI AI Agent + Agentic Workforce \u0026ldquo;Open Data Lakehouse\u0026quot;에서 \u0026ldquo;Data Platform for Apps and AI\u0026quot;로. 단순한 마케팅 변화가 아니라 제품 로드맵 전체가 이 방향으로 정렬됐다.\n2025년 주요 발표 타임라인 # 2025년 5월 — Launch Point\nStarburst는 AI Agent와 AI Workflows를 공식 발표했다.\nAI Agent. 자연어로 데이터를 쿼리하는 인터페이스다. \u0026ldquo;What were our sales in Europe last quarter?\u0026rdquo; 같은 질문이 자동으로 SQL로 변환된다. Air-gapped 환경(금융, 의료, 정부)을 명시적으로 지원하며 Google Agent2Agent 프로토콜과 Anthropic Model Context Protocol(MCP)도 지원한다. AI Workflows. Vector embeddings를 Iceberg 테이블에 저장하고 구조화/반구조화/비구조화 데이터를 AI 학습에 활용하는 파이프라인이다. RAG(Retrieval-Augmented Generation)를 네이티브로 지원한다. 기타. Starburst Data Catalog(Hive Metastore 대체), Automated Table Maintenance(파일 정리 및 컴팩션 자동화), Native ODBC Driver, Role-based Query Routing 2025년 10월 — AI \u0026amp; Datanova 2025\n여기서 Starburst는 Agentic Workforce 플랫폼과 Lakeside AI Architecture를 발표하며 한 단계 더 나아갔다.\n핵심은 Model-to-Data 아키텍처다. 기존에는 데이터를 중앙 웨어하우스로 모은 뒤 AI 모델을 돌렸다. Starburst는 반대로 AI 모델을 데이터가 있는 곳으로 보낸다.\n기존 접근: Data → Centralized Warehouse → AI Model Starburst: AI Model → Federated Data (where it lives) 데이터를 이동시키지 않으므로 데이터 주권(GDPR, Schrems II)을 유지하면서도 통합 분석이 가능하다는 논리다. Citi, HSBC 같은 글로벌 금융기관이 165개국에 흩어진 데이터를 이 방식으로 통합하고 있다고 한다.\n기술 스택이 달라졌다 # Starburst 기술 스택을 레이어로 표현하면 2025년에 뭐가 추가됐는지 보인다.\n┌─────────────────────────────────────┐ │ AI Agent \u0026amp; Agent2Agent Protocol │ ← 2025 NEW ├─────────────────────────────────────┤ │ AI Workflows (Vector Store) │ ← 2025 NEW ├─────────────────────────────────────┤ │ Starburst Data Catalog │ ← 2025 NEW ├─────────────────────────────────────┤ │ Lakehouse (Trino + Iceberg) │ ├─────────────────────────────────────┤ │ Federated Data Sources (50+) │ └─────────────────────────────────────┘ Trino는 여전히 기반 레이어에 있지만 새 기능은 전부 위에서 만들어지고 있다. Trino 오픈소스 릴리스가 줄어든 이유가 여기 있다. 엔지니어링 리소스가 상위 레이어로 이동한 거다.\nVector Store on Iceberg. 주목할 만한 기술적 시도 # 2025년 Starburst 발표 중 기술적으로 가장 흥미로운 건 Apache Iceberg 테이블에 직접 vector embeddings를 저장하는 접근이다.\n왜 의미가 있는가.\n별도 벡터 DB가 필요 없다. Pinecone, Weaviate, Milvus 같은 전용 벡터 데이터베이스를 운영 안 해도 된다. 기존 데이터 엔지니어링 스킬을 그대로 쓴다. Iceberg 테이블을 다루던 방식 그대로 벡터 데이터를 관리할 수 있다. Iceberg가 제공하는 기능이 벡터 데이터에도 먹힌다. Time travel, ACID 트랜잭션, 스키마 진화, 파티셔닝 전부 벡터 데이터에서도 쓸 수 있다. 거버넌스 정책을 일관되게 적용 가능하다. 구조화 데이터와 벡터 데이터에 동일한 접근 제어, 감사 로그, 데이터 마스킹 정책을 걸 수 있다. 오픈 포맷이므로 vendor lock-in이 없다. AI 워크로드가 데이터 플랫폼에서 빠질 수 없는 요소가 되는 미래를 가정하면 꽤 실용적인 접근이다. 전용 벡터 DB 대비 검색 성능에는 트레이드오프가 있겠지만 운영 복잡도를 줄이고 거버넌스를 통합할 수 있다는 점은 엔터프라이즈 환경에서 매력적이다.\n비즈니스 성과. 시장에서 통하고 있는가 # AI 피벗이 단순한 마케팅이 아니라는 건 비즈니스 지표가 보여준다.\nFY25 실적 (2025년 2월 발표)\n지표 성과 신규 고객 전년 대비 20% 증가 Galaxy(SaaS) 고객 전년 대비 76% 증가 Galaxy 사용량 전년 대비 94% 증가 최대 계약 글로벌 금융기관과 8자리(억 단위) 다년 계약 파트너십 Dell Data Lakehouse의 쿼리 엔진으로 선정 Galaxy(SaaS) 고객이 76% 늘었다는 건 눈여겨볼 만하다. 클라우드 매니지드 서비스 전환이 빨라지고 있다는 뜻이고 오픈소스 Trino를 직접 운영하는 팀 입장에서는 대안이 되기도 한다.\n고객사 면면도 인상적이다.\nHSBC. 165개국 데이터 통합 Citi. 글로벌 데이터 주권을 유지하며 통합 분석 Vectra AI. 120개국 위협 탐지 플랫폼 ZoomInfo. 멀티클라우드 데이터 통합 경쟁 환경에서 어디에 서 있는가 # 데이터 플랫폼 시장에서 Starburst를 경쟁사와 비교하면 차별화 지점이 드러난다.\n기능 Databricks Snowflake Dremio Starburst AI Agent O O X O Federated Query 제한적 제한적 O 핵심 강점 Data Sovereignty 제한적 제한적 제한적 핵심 강점 오픈소스 기반 Spark X Arrow Trino Vector Store O O X O (Iceberg) On-prem + Cloud O 제한적 O 핵심 강점 Starburst가 내세우는 차별화는 두 축이다.\n하나는 페더레이션과 데이터 주권. 50개 이상 데이터 소스에 실시간 쿼리를 지원하면서 데이터를 이동시키지 않는다. 165개국 규제를 준수하면서 통합 분석을 제공하는 건 GDPR, Schrems II 환경에서 결정적이다.\n다른 하나는 하이브리드 배포. On-premise와 멀티 클라우드를 동시에 지원한다. 규제 산업에서 클라우드 전환이 더딘 기업에게 강하게 어필한다.\nDatabricks는 Spark + Delta Lake 중심 AI/ML Lakehouse로 Unity Catalog를 통해 거버넌스를 강화하고 있다. Snowflake는 2024년 Iceberg 지원을 추가하고 Snowpark으로 AI/ML을 밀고 있지만 여전히 데이터 중앙화가 전제다. Dremio는 Arrow Flight 기반 성능과 시맨틱 레이어를 내세우지만 엔터프라이즈 기능에서는 아직 격차가 있다.\n흥미로운 건 Starburst CEO Justin Borgman이 한 말이다. \u0026ldquo;What they\u0026rsquo;ve done for Spark is what we aim to do for Presto(Trino).\u0026rdquo; Databricks가 Spark 오픈소스 위에 강력한 상용 플랫폼을 구축한 것처럼 Starburst도 Trino 위에 같은 구조를 만들겠다는 거다.\nTrino 오픈소스, 괜찮을 것인가 # 오픈소스와 상용 기능이 갈라지고 있다 # 지금 Trino 오픈소스에 남아있는 것과 Starburst 전용으로 넘어간 것을 정리하면 이렇다.\nTrino 오픈소스:\n핵심 쿼리 엔진 기본 커넥터 Fault-tolerant execution SQL MERGE 기본 보안 기능 Starburst 전용:\nWarp Speed (최대 7배 성능 향상) AI Agent \u0026amp; AI Workflows Starburst Data Catalog 고급 거버넌스 (RBAC, 데이터 마스킹, 감사 로그) Automated Table Maintenance Smart Indexing Materialized Views (일부) 가장 눈에 띄는 건 Warp Speed다. 최대 7배 성능을 끌어올리는 독점 인덱싱/캐싱 레이어가 상용 전용이라는 건 대규모 워크로드에서 오픈소스와 상용 제품 사이 성능 차이가 점점 벌어질 수 있다는 뜻이다.\n낙관적으로 볼 수 있는 근거 # Trino 코어 엔진은 이미 성숙 단계다. 분산 SQL 쿼리 엔진으로서 필요한 기능은 대부분 갖추고 있다. 릴리스 빈도가 줄었다고 품질이 떨어지는 건 아니다. 커뮤니티는 여전히 활발하다. Trino Summit 2024에는 Netflix, LinkedIn, Wise 등이 참여했고 Trino Community Broadcast도 계속 운영되고 있다. 50곳 이상 기업이 기여하고 있다. Starburst 기여가 줄더라도 다른 기업이 메울 여지는 있다. 우려할 점 # 커밋의 84%를 담당하던 회사가 다른 곳에 집중하기 시작했다. 나머지 기업이 이 공백을 메울 동기가 충분한지는 불확실하다. 성능 최적화 핵심이 상용 전용이다. Warp Speed 없이 대규모 워크로드를 운영하는 팀은 갈수록 불리해질 수 있다. AI 관련 새 기능이 전부 상용 제품에 몰려 있다. 데이터 플랫폼에 AI가 필수가 되는 미래에서 오픈소스만으로는 경쟁력 확보가 어려워질 수 있다. Trino 운영 팀이 고려해야 할 것 # Trino를 프로덕션에서 운영하는 팀 입장에서 이 상황을 시간 축 두 개로 나눠 생각해볼 수 있다.\n단기 (1~2년). 큰 문제 없다 # Trino 오픈소스는 여전히 안정적이고 프로덕션에서 검증된 기술이다. 핵심 기능은 충분히 성숙했고 기본 쿼리 성능과 커넥터 생태계는 탄탄하다. 당장 대안으로 갈아타야 할 이유는 없다.\n중장기 (3~5년). 전략적 대비가 필요하다 # 오픈소스와 상용 제품 사이 기능 격차가 벌어질 가능성을 감안해야 한다. 특히 다음 영역에서 대비가 필요하다.\n성능 최적화. Warp Speed 없이 대규모 워크로드 성능을 어떻게 확보할 건지. 자체 캐싱 레이어나 인덱싱 전략을 검토하고 StarRocks 같은 보완 엔진 도입도 따져봐야 한다. AI 통합. 데이터 플랫폼에 AI를 통합하는 게 조직 요구사항이 될 때 오픈소스 Trino만으로 충분한지 평가해야 한다. Vector Store on Iceberg 같은 접근을 직접 구현할 수 있는지, 다른 도구와 조합이 필요한지 따져봐야 한다. 거버넌스. 조직이 커지고 규제가 강화될수록 고급 거버넌스 기능(RBAC, 데이터 마스킹, 감사 로그)이 더 절실해진다. 오픈소스만으로 충족할 수 있는지 따져봐야 한다. 대안 평가. Starburst Galaxy 도입이나 다른 쿼리 엔진으로 전환, 하이브리드 접근(배치는 Trino, 실시간은 StarRocks) 등을 주기적으로 비교 평가해야 한다. 마치며 # Starburst의 AI 피벗은 단순한 마케팅이 아니다. Galaxy 고객 76% 증가, 역대 최대 계약 등 비즈니스 지표가 이 전략이 시장에서 먹히고 있음을 보여준다. 쿼리 엔진 회사에서 AI 플랫폼 기업으로 전환하는 흐름은 되돌리기 어렵다.\nTrino 오픈소스는 당장 죽지 않는다. 하지만 \u0026ldquo;충분히 성숙한\u0026rdquo; 상태로 유지보수 모드에 가까워지고 있고 새 기능 개발의 무게 중심은 분명히 상용 제품으로 옮겨갔다. Databricks가 Spark에 대해 했던 것과 같은 패턴이다.\nTrino를 프로덕션에서 운영하는 팀이라면 지금 당장은 안심해도 되지만 3년 뒤를 위한 대비는 지금 시작해야 한다. 오픈소스가 주는 안정성에 기대면서도 성능 격차와 AI 통합이라는 두 축에서 선택지를 확보해두는 게 현명하다.\n기술 부채는 늘 조용히 쌓인다. 이자는 언제나 우리가 생각했던 것보다 비싸다.\n참고 자료:\nTrino Release Notes Starburst Enterprise Release Notes TechTarget: Addition of new AI capabilities shows Starburst\u0026rsquo;s growth BigDataWire: Starburst\u0026rsquo;s New Platform Aims to Close AI\u0026rsquo;s Biggest Gap ","date":"2026년 2월 23일","externalUrl":null,"permalink":"/posts/starburst-trino-ai-pivot/","section":"글 목록","summary":"Starburst가 쿼리 엔진 회사에서 AI 플랫폼 기업으로 전환하면서 Trino 오픈소스 릴리스가 63% 감소했다. Trino를 프로덕션에서 운영하는 팀의 관점에서, 이 변화가 의미하는 것과 앞으로의 전략을 정리한다.","title":"Starburst의 AI 피벗: Trino 오픈소스는 괜찮을까?","type":"posts"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/starrocks/","section":"Tags","summary":"","title":"Starrocks","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/categories/starrocks/","section":"Categories","summary":"","title":"StarRocks","type":"categories"},{"content":" 도입 배경 # 데이터 파이프라인을 운영하다보면 한 가지 고민에 반드시 부딪힌다. 실시간 대시보드를 어떻게 만들 것인가?\n우리 팀도 똑같았다. 기존 파이프라인 구조는 이랬다.\nService → Kafka → Iceberg → S3 → Trino → Airflow(5분) → Dashboard 겉보기엔 잘 돌아갔지만 실무에서 체감하는 문제는 분명했다.\n최소 5분 지연. Airflow 스케줄 주기가 병목이었다 파이프라인 복잡도. Kafka → Flink → Redis → API → Dashboard까지 컴포넌트 5개 이상을 관리해야 했다 반복되는 I/O. Trino가 매 쿼리마다 S3를 풀스캔했다 높은 개발 비용. 실시간 대시보드 하나 새로 만드는 데 약 2주 걸렸다 StarRocks를 도입한 뒤 아키텍처가 이렇게 바뀌었다.\nService → Kafka → StarRocks → Dashboard (서브초 레이턴시) 중간 컴포넌트가 빠지면서 파이프라인이 크게 단순해졌다. Kafka에서 StarRocks로 바로 넣으니 실시간성도 갖출 수 있었다.\n도입 효과 # 약 3개월간 PoC를 거치고 6개월에 걸쳐 단계적으로 도입한 결과다.\n항목 Before After 개선폭 대시보드 지연 5분 \u0026lt; 1초 ~300배 대시보드 개발 기간 ~2주 ~1주 50% 단축 파이프라인 컴포넌트 5개 이상 2개 60% 감소 쿼리 응답 시간 30~50초 5~10초 5~10배 하드웨어 비용 128GB × 18노드 64GB × 3노드 ~75% 절감 Trino는 절대적인 쿼리 시간에서는 빠르지만 Airflow 스케줄 지연까지 포함한 end-to-end 레이턴시와 하드웨어 비용 면에서 StarRocks가 실시간 워크로드에 더 맞았다.\n테이블 모델 선택 가이드 # StarRocks를 처음 도입할 때 가장 신경 써야 할 결정이 테이블 모델이다. 잘못 고르면 나중에 테이블을 다시 만들어야 한다.\n의사결정 흐름 # ┌─────────────────────────────┐ │ 어떤 데이터를 저장하는가? │ └──────────────┬──────────────┘ │ ┌───────▼────────┐ │ UPDATE 필요? │ └───────┬────────┘ │ ┌────────┴────────┐ │ │ [아니오] [예] │ │ ┌─────▼─────┐ ┌─────▼──────┐ │ 집계 필요? │ │ Primary Key │ └─────┬─────┘ │ (빈번한 │ │ │ UPDATE) │ [아니오] [예] └────────────┘ │ │ ┌─────▼───┐ ┌▼──────────┐ │Duplicate│ │Aggregate │ │(원본 저장)│ │(자동 집계) ★│ └─────────┘ └────────────┘ 모델 비교 # 모델 중복 허용 UPDATE 자동 집계 적합한 용도 Duplicate Key O X X 로그, 원본 이벤트 Aggregate Key X 자동 O 실시간 통계 ★ Primary Key X O (고속) X 빈번한 UPDATE Duplicate Key. 원본 데이터 저장 # 클릭 로그나 API 이벤트, 센서 데이터처럼 원본을 그대로 보관해야 할 때 쓴다.\nCREATE TABLE order_events ( event_id BIGINT, event_time DATETIME, order_id VARCHAR(50), user_id BIGINT, event_type VARCHAR(20), amount DECIMAL(10, 2) ) DUPLICATE KEY(event_id, event_time) PARTITION BY date_trunc(\u0026#39;day\u0026#39;, event_time) DISTRIBUTED BY HASH(event_id) BUCKETS 10; Aggregate Key. 실시간 통계 ★ # 데이터가 수집되는 시점에 자동으로 집계가 일어난다. StarRocks 도입에서 가장 값어치있었던 모델이다.\nCREATE TABLE order_stats ( stat_time DATETIME NOT NULL COMMENT \u0026#39;5분 간격\u0026#39;, region VARCHAR(20) NOT NULL, delivery_type VARCHAR(20) NOT NULL, -- 집계 컬럼: 수집 시 자동으로 집계 함수 적용 order_count BIGINT SUM DEFAULT \u0026#34;0\u0026#34;, total_amount DECIMAL(15, 2) SUM DEFAULT \u0026#34;0\u0026#34;, user_bitmap BITMAP BITMAP_UNION, max_amount DECIMAL(10, 2) MAX ) AGGREGATE KEY(stat_time, region, delivery_type) PARTITION BY date_trunc(\u0026#39;day\u0026#39;, stat_time) DISTRIBUTED BY HASH(stat_time) BUCKETS 10; 사용 가능한 집계 함수.\n함수 용도 예시 SUM 합계 주문 건수, 매출 합계 MAX / MIN 최대/최소값 최고가, 최저가 REPLACE 최신 값 덮어쓰기 최종 상태 BITMAP_UNION 정확한 유니크 카운트 순 이용자 수 HLL_UNION 근사 유니크 카운트 대규모 카디널리티 BITMAP_UNION은 HyperLogLog와 달리 정확한 유니크 카운트를 제공한다. 비즈니스 KPI 대시보드처럼 정확도가 중요하면 반드시 이걸 쓰자.\nPrimary Key. 빈번한 UPDATE # 주문 상태를 추적하거나 재고를 관리하는 것처럼 같은 키 데이터가 자주 갱신되는 경우에 맞다.\nCREATE TABLE orders ( order_id VARCHAR(50) NOT NULL, status VARCHAR(20), amount DECIMAL(10, 2), updated_at DATETIME ) PRIMARY KEY(order_id) DISTRIBUTED BY HASH(order_id) BUCKETS 10 PROPERTIES ( \u0026#34;enable_persistent_index\u0026#34; = \u0026#34;true\u0026#34; ); enable_persistent_index를 켜면 UPDATE 성능이 크게 좋아진다.\n데이터 수집 # Routine Load. Kafka 실시간 연동 # Kafka 토픽에서 데이터를 연속으로 가져오는 방식이다. 실시간 파이프라인 대부분이 이걸 쓴다.\nCREATE ROUTINE LOAD order_load ON orders COLUMNS( order_id, user_id, timestamp_ms, amount, order_date = FROM_UNIXTIME(timestamp_ms / 1000) ) PROPERTIES ( \u0026#34;format\u0026#34; = \u0026#34;json\u0026#34;, \u0026#34;jsonpaths\u0026#34; = \u0026#34;[\\\u0026#34;$.orderId\\\u0026#34;,\\\u0026#34;$.userId\\\u0026#34;,\\\u0026#34;$.timestamp\\\u0026#34;,\\\u0026#34;$.amount\\\u0026#34;]\u0026#34; ) FROM KAFKA ( \u0026#34;kafka_broker_list\u0026#34; = \u0026#34;kafka-broker:9092\u0026#34;, \u0026#34;kafka_topic\u0026#34; = \u0026#34;orders\u0026#34; ); Aggregate Key 테이블과 결합하면 수집 시점에 변환과 집계를 한번에 처리할 수 있다.\nCREATE ROUTINE LOAD order_stats_load ON order_stats COLUMNS( timestamp_ms, region, amount, user_id, -- 5분 간격으로 라운딩 stat_time = FROM_UNIXTIME(FLOOR(timestamp_ms / 1000 / 300) * 300), order_count = 1, total_amount = amount, user_bitmap = BITMAP_HASH(user_id) ) WHERE amount \u0026gt; 0 PROPERTIES (\u0026#34;format\u0026#34; = \u0026#34;json\u0026#34;) FROM KAFKA ( \u0026#34;kafka_broker_list\u0026#34; = \u0026#34;kafka-broker:9092\u0026#34;, \u0026#34;kafka_topic\u0026#34; = \u0026#34;orders\u0026#34; ); 이 패턴 하나로 기존에 Flink로 처리하던 집계 로직을 SQL만으로 대체했다.\nStream Load. 벌크 데이터 로딩 # 파일이나 API로 한번에 대량 로딩할 때 쓴다.\n# CSV 파일 로딩 curl --location-trusted \\ -u user:password \\ -H \u0026#34;label:load_$(date +%Y%m%d%H%M%S)\u0026#34; \\ -H \u0026#34;column_separator:,\u0026#34; \\ -T data.csv \\ http://starrocks-fe:8030/api/mydb/mytable/_stream_load 성능 튜닝 실전 팁 # Thread Pool 설정 # 동시 접속이 500 RPS 이상인 고부하 환경에서는 기본 Thread Pool 크기가 부족하다.\n# be.conf pipeline_scan_thread_pool_thread_num = 32 # 기본값: 24 pipeline_exec_thread_pool_thread_num = 32 # 기본값: 24 Bucket Count 가이드라인 # 데이터 크기 권장 Bucket 수 \u0026lt; 10 GB 10 10~50 GB 20 50~100 GB 30 \u0026gt; 100 GB 50+ 산정 공식. buckets = max(1, 데이터_크기_GB / 10)\n파티셔닝 전략 # 파티션 컬럼에 함수를 쓰면 파티션 프루닝이 안 된다. 생각보다 자주 실수하는 부분이다.\n-- ✅ 올바른 사용: 파티션 프루닝 동작 WHERE event_time \u0026gt;= NOW() - INTERVAL 3 DAY -- ❌ 잘못된 사용: 파티션 프루닝 불가 WHERE DATE(event_time) \u0026gt;= CURRENT_DATE - 3 TTL 설정 # 오래된 파티션을 자동 삭제하려면 TTL을 건다.\nPROPERTIES ( \u0026#34;partition_live_number\u0026#34; = \u0026#34;3\u0026#34; -- 최근 3개 파티션만 유지 ) 운영 노하우 # Materialized View 관리 # ASYNC 리프레시가 예고 없이 멈출 때가 있다. 정기적으로 상태를 확인하고 문제가 생기면 수동으로 복구해야 한다.\n-- 상태 확인 SHOW MATERIALIZED VIEWS; -- 강제 동기 리프레시 REFRESH MATERIALIZED VIEW db.mv_name WITH SYNC MODE; -- 비활성화된 MV 재활성화 ALTER MATERIALIZED VIEW db.mv_name ACTIVE; Routine Load 모니터링 # 상태가 PAUSED로 바뀌는 경우가 잦다. Kafka offset이 꼬이거나 비정상 메시지가 들어올 때 그렇다.\n-- 상태 확인 SHOW ROUTINE LOAD FOR db.load_job; -- 재개 RESUME ROUTINE LOAD FOR db.load_job; Scale-in 주의사항 # 노드를 축소할 때는 반드시 Decommission을 먼저 해야 한다. 이 절차를 빼먹고 노드를 줄이면 데이터가 유실된다.\n-- 1. 현재 노드 확인 SHOW PROC \u0026#39;/backends\u0026#39;; -- 2. 디커미션 시작 ALTER SYSTEM DECOMMISSION BACKEND \u0026#34;\u0026lt;BE_IP\u0026gt;:\u0026lt;HEARTBEAT_PORT\u0026gt;\u0026#34;; -- 3. TabletNum이 0이 될 때까지 대기 후 제거 ALTER SYSTEM DROP BACKEND \u0026#34;\u0026lt;BE_IP\u0026gt;:\u0026lt;HEARTBEAT_PORT\u0026gt;\u0026#34;; 도입 시 알아둘 점 # 알려진 제약 사항 # 이슈 설명 대안 Routine Load 비정상 메시지 처리 한계 Kafka 단에서 사전 검증 datetime 파티션 Iceberg datetime 파티션 호환 이슈 대체 파티션 전략 사용 버전 업그레이드 4.x 대에서 버그 경험 스테이징 환경 필수 테스트 버전 업그레이드는 반드시 스테이징에서 충분히 검증하고 프로덕션에 적용하자. 실제로 여러 차례 업그레이드와 다운그레이드를 반복한 적이 있다. 롤백 계획은 항상 준비해두자.\n도입 체크리스트 # 배포 전\n유스케이스와 요구사항 정의 데이터 볼륨 및 증가량 추정 테이블 모델 선택 파티션 전략 설계 배포 후\nRoutine Load 작업 생성 및 검증 사용자 권한 설정 데이터 보관 정책(TTL) 설정 Scale-in/out 절차 문서화 모니터링 대시보드 구성 마치며 # StarRocks를 도입하면서 배운 것을 정리한다.\nAggregate Key 모델이 제일 쓸모있다. 수집 시점에 자동 집계되니까 스토리지와 쿼리 성능을 동시에 잡을 수 있다. BITMAP_UNION으로 정확한 유니크 카운트를 확보하자. 비즈니스 KPI에는 근사치가 아니라 정확한 수치가 필요하다. Routine Load + Aggregate Key 조합이 Flink를 대체한다. SQL만으로 실시간 집계 파이프라인을 구축할 수 있다. 운영 자동화에 투자하자. Materialized View와 Routine Load 모니터링은 빠뜨리면 안 된다. 실시간 분석 워크로드에서 StarRocks는 파이프라인 복잡도를 크게 낮춰준다. 다만 버전 업그레이드나 운영 안정성 쪽은 아직 무르익는 단계라서 충분히 PoC하고 스테이징에서 검증한 뒤 도입하길 권한다.\n참고 자료: StarRocks 공식 문서\n","date":"2026년 2월 23일","externalUrl":null,"permalink":"/posts/starrocks-adoption-guide/","section":"글 목록","summary":"기존 Trino + Airflow 파이프라인의 5분 지연을 서브초 레이턴시로 개선한 StarRocks 도입 과정을 정리했습니다. 테이블 모델 선택, 데이터 수집, 성능 튜닝, 운영 노하우까지 실무에서 얻은 교훈을 공유합니다.","title":"StarRocks 도입기: 실시간 OLAP으로 데이터 파이프라인을 뜯어고친 이야기","type":"posts"},{"content":" 왜 압축 설정을 신경 써야 하나 # StarRocks를 운영하다 보면 데이터가 수십 TB 규모로 불어나는 시점이 꼭 온다. 이때 압축 설정 하나로 스토리지 비용이 30~50%씩 벌어지는 걸 여러 번 겪었다. 저장 공간만의 문제가 아니다. 압축률이 높으면 디스크 I/O가 줄어들어 스캔 성능이 올라가고 반대로 압축/해제에 CPU를 많이 잡아먹으면 지연 시간이 늘어난다. 워크로드 특성에 맞춰 압축 알고리즘을 고르는 게 StarRocks 튜닝에서 빠질 수 없는 부분이다.\n지원되는 압축 알고리즘 비교 # StarRocks는 여러 압축 알고리즘을 지원한다. 실무에서 주로 쓰는 네 가지를 비교해 본다.\n알고리즘 압축률 압축 속도 해제 속도 적합한 워크로드 LZ4 보통 (2~3x) 매우 빠름 매우 빠름 실시간 분석, 저지연 쿼리 ZSTD 높음 (4~6x) 보통 빠름 배치 분석, 콜드 데이터 Snappy 낮음 (1.5~2x) 빠름 빠름 범용, 레거시 호환 ZLIB 높음 (4~5x) 느림 보통 아카이빙, 저빈도 접근 데이터 개인적으로 가장 많이 쓰는 조합은 핫 데이터에 LZ4, 콜드 데이터에 ZSTD다. Snappy는 Hadoop 에코시스템에서 넘어온 데이터 다룰 때 간혹 쓰는데 신규 테이블엔 굳이 권하지 않는다.\n테이블 생성 시 압축 설정 # 테이블 만들 때 PROPERTIES에서 compression 속성을 지정하면 된다. 따로 안 잡으면 기본값인 LZ4가 적용된다.\n실시간 분석용 테이블 (LZ4) # CREATE TABLE analytics.realtime_events ( event_id BIGINT, user_id BIGINT, event_type VARCHAR(64), event_time DATETIME, properties JSON ) ENGINE = OLAP DUPLICATE KEY(event_id) DISTRIBUTED BY HASH(user_id) BUCKETS 32 PROPERTIES ( \u0026#34;replication_num\u0026#34; = \u0026#34;3\u0026#34;, \u0026#34;compression\u0026#34; = \u0026#34;LZ4\u0026#34; ); LZ4는 해제 속도가 압도적으로 빨라서 대시보드 쿼리처럼 수백 밀리초 안에 응답해야 하는 테이블에 잘 맞는다.\n배치 분석용 테이블 (ZSTD) # CREATE TABLE warehouse.order_history ( order_id BIGINT, customer_id BIGINT, order_date DATE, total_amount DECIMAL(18, 2), status VARCHAR(32), items ARRAY\u0026lt;STRUCT\u0026lt;sku STRING, qty INT, price DECIMAL(10,2)\u0026gt;\u0026gt; ) ENGINE = OLAP DUPLICATE KEY(order_id) PARTITION BY RANGE(order_date) ( PARTITION p2025 VALUES LESS THAN (\u0026#39;2026-01-01\u0026#39;), PARTITION p2026 VALUES LESS THAN (\u0026#39;2027-01-01\u0026#39;) ) DISTRIBUTED BY HASH(customer_id) BUCKETS 16 PROPERTIES ( \u0026#34;replication_num\u0026#34; = \u0026#34;2\u0026#34;, \u0026#34;compression\u0026#34; = \u0026#34;ZSTD\u0026#34; ); ZSTD는 압축률이 LZ4보다 1.5~2배 높다. 파티션 단위로 수억 건 이상 쌓이는 히스토리 테이블에서 스토리지 절감 효과가 확실히 드러난다.\n기존 테이블 압축 변경 # 이미 돌아가는 테이블의 압축 알고리즘을 바꾸려면 ALTER TABLE을 쓰면 된다. 다만 바꾼 뒤 새로 적재되는 데이터부터 적용되고 기존 세그먼트는 Compaction이 끝나야 반영된다.\nALTER TABLE warehouse.order_history SET (\u0026#34;compression\u0026#34; = \u0026#34;ZSTD\u0026#34;); 워크로드별 권장 압축 설정 # 실무에서 여러 차례 검증한 결과를 바탕으로 정리하면 이렇다.\n실시간 대시보드 / Ad-hoc 쿼리. LZ4를 권한다. CPU 오버헤드가 거의 없어서 P99 지연 시간에 미치는 영향이 작다. 야간 배치 리포트 / ETL 결과 테이블. ZSTD를 권한다. 쿼리 빈도가 낮고 데이터양이 많으면 스토리지를 아낀만큼 비용에 바로 드러난다. 로그성 대용량 적재. ZSTD를 쓰되 zstd_compression_level을 3 이하로 낮추면 압축 속도와 압축률 사이 균형을 잡을 수 있다. 압축률과 성능 트레이드오프 실측 # 약 50억 건(원본 약 800GB) 이벤트 로그 테이블을 대상으로 압축 알고리즘별 벤치마크를 돌려봤다.\n지표 LZ4 ZSTD (level 3) ZSTD (level 9) 압축 후 크기 320 GB 195 GB 170 GB 압축률 2.5x 4.1x 4.7x 단순 스캔 쿼리 (Avg) 1.2초 1.5초 1.8초 집계 쿼리 (Avg) 3.4초 3.8초 4.5초 데이터 적재 속도 120 MB/s 95 MB/s 60 MB/s LZ4랑 비교하면 ZSTD level 3은 스토리지를 약 39% 줄이면서 쿼리 지연은 10~15%만 늘었다. 반면 ZSTD level 9는 추가로 줄어드는 용량 대비 적재 속도 저하가 커서 대부분 환경에서 level 3이 나은 선택이었다.\n운영 팁과 모니터링 # 마지막으로 압축 관련해서 운영할 때 놓치기 쉬운 부분을 짚어 본다.\nCompaction 모니터링은 꼭 해야 한다. 압축 알고리즘을 바꾼 뒤 Compaction이 안 끝난 상태에서 혼합 세그먼트가 남아 있으면 쿼리 성능이 일시적으로 흔들릴 수 있다. BE의 compaction_score 메트릭을 보면서 Compaction이 밀리고 있지 않은지 확인해야 한다.\n테이블 단위로 압축 전략을 나눠라. 클러스터 안에서 모든 테이블에 같은 압축을 거는 건 비효율적이다. 접근 빈도, 데이터 크기, SLA를 따져서 테이블마다 다르게 잡는 편이 낫다.\n디스크 사용량 추이를 추적하라. 압축을 바꾸고 나서 SHOW DATA 명령으로 테이블별 실제 디스크 사용량을 주기적으로 확인하자. 기대한 압축률이 안 나오면 데이터 특성(카디널리티, NULL 비율 등)을 다시 살펴봐야 한다.\nSHOW DATA FROM warehouse.order_history; 압축 설정은 한 번 정해놓고 끝낼 게 아니다. 데이터 특성과 워크로드가 바뀌면 거기에 맞춰 꾸준히 재검토해야 한다. 이 글이 StarRocks 압축 전략 세우는 데 참고가 됐으면 좋겠다.\n","date":"2026년 2월 23일","externalUrl":null,"permalink":"/posts/starrocks-compression-guide/","section":"글 목록","summary":"StarRocks에서 압축 설정을 최적화해 스토리지 비용을 절감하고 쿼리 성능을 올리는 방법을 실무 경험 바탕으로 정리했다.","title":"StarRocks 압축 설정 가이드: 성능과 스토리지 최적화","type":"posts"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/trends/","section":"Tags","summary":"","title":"Trends","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/vector-store/","section":"Tags","summary":"","title":"Vector-Store","type":"tags"},{"content":"","date":"2026년 2월 23일","externalUrl":null,"permalink":"/tags/workation/","section":"Tags","summary":"","title":"Workation","type":"tags"},{"content":"발리하면 떠오르는 이미지가 있다. 서핑, 열대 자연, 코워킹 스페이스에서 노트북을 펼친 디지털 노마드. 워케이션(workation)의 성지라고 불리는 곳이다.\n나도 그 이미지에 이끌렸다. 아이에게는 해외 유치원이라는 새 경험을 주고 가족에게는 일상에서 벗어난 해방감을 줄 수 있을 거라 기대했다. 2023년 초, 회사의 해외 리모트 근무 제도를 활용해 발리에서 약 한 달간 일하고 생활했다.\n결론부터 말하면, 아이가 있는 가정에게 발리 리모트 근무는 생각보다 별로였다. 이 글은 그 솔직한 기록이다. 발리 리모트 근무를 고민하는 분들, 특히 어린 아이가 있는 가정이라면 판단하는 데 도움이 됐으면 한다.\n출발 전: 준비해야 할것들 # 승인과 세무 이슈 # 해외 리모트 근무는 비행기표 사기 전에 회사 승인부터 받아야 한다. 승인 과정에서 일정이 바뀔 수 있기 때문이다.\n처음에 3개월 체류를 신청했는데 세무 검토 과정에서 세법상 2개월 이하만 가능하다는 회신을 받았다. 해외 체류 기간에 따라 세금 처리가 달라져서다. 비행기표를 이미 끊어놨다면 변경 수수료를 물어야 할 뻔했다. 반드시 승인 확정 후에 항공권을 구매하자.\n항공권은 대한항공 마일리지를 썼는데 비용 대비 차감되는 마일리지가 적어서 가성비가 좋았다.\n숙소. 빌라의 함정 # 발리 숙소는 크게 두 가지 선택지가 있다. 호텔이나 리조트를 전전하거나, 월 단위로 빌라를 빌리거나.\n호텔에서 3일 정도 지내본 뒤 수영장이 딸린 발리스러운 빌라를 월 단위로 계약했다. 사진으로 보면 정말 근사하다. 야자수 아래 프라이빗 풀, 넓은 거실, 열대 정원. 실제로 살아보면 다르다. 결국 빌라를 취소하고 다시 호텔로 돌아왔다.\n빌라의 현실.\n벌레가 많다. 개미와 모기는 기본이고 이름 모를 벌레가 출몰한다. 호텔이나 리조트는 방역을 하지만 빌라는 그렇지 않다. 침구류와 청소 상태가 들쭉날쭉하다. 관리 수준이 숙소마다 천차만별이다. 상수도 문제. 뒤에서 다시 다루겠지만 이게 가장 큰 문제다. 교통이 불편하다. 빌라가 저렴한 이유가 있다. 대부분 도심에서 떨어져 있고 발리에서 걸어다니는 건 사실상 불가능하다. 한 달 이상 체류한다면 빌라가 합리적으로 보이지만 특히 아이가 있다면 호텔이나 서비스드 레지던스가 낫다. 관리와 위생, 편의성 모든 면에서.\n위생. 발리의 가장 큰 리스크 # 인도네시아 여행 커뮤니티에서 가장 자주 나오는 토픽이 있다. \u0026ldquo;병원 어디 가야 해요?\u0026rdquo;, \u0026ldquo;약 좀 주세요\u0026rdquo;, \u0026ldquo;샤워기 필터 구합니다.\u0026rdquo;\n과장이 아니다.\n물 문제 # 발리는 지하수를 끌어다 쓰는 곳이 많다. 오염된 경우가 적지 않아서 비누로 빡빡 씻어도 몸이 계속 미끈미끈한 느낌이 가시지 않는다. 유럽의 석회수와는 또 다른 종류의 불쾌함이다.\n수영장은 발리 곳곳에 널려 있지만 소독약 냄새가 안 나는 곳이 많다. 소독약 냄새가 안 난다는 건 소독을 안 한다는 뜻이다. 세균과 박테리아가 번식하기 좋은 열대 기후에서.\n비치도 안심할 수 없다. 서핑 중 육지에서 흘러들어온 오염된 바닷물을 삼키고 아픈 사람이 많다. 카페에서 나오는 차가운 음료의 얼음이 정수된 물로 만든건지도 확신할 수 없다.\n아이의 입원 # 출국 전 나름 준비를 했다. 장티푸스 예방접종을 맞고 출국 전날 종합병원에서 피검사로 염증 수치와 백혈구 수치를 확인했다. 유산균도 2주 전부터 복용시켰다.\n도착 3일 만에 아이에게 고열이 찾아왔다.\n평소 38도 위로 올라간 적이 없던 아이가 39.5도까지 치솟았다. 응급실을 세 번 갔다. 세 번째 응급실에서는 귀가하겠다고 하니 \u0026ldquo;책임지지 않겠다\u0026quot;는 서명을 하고 가라고 했다. 결국 병동에 입원. 4일간 입원했다.\n이때 경험은 지금 돌이켜봐도 힘들다.\n기본적으로 낙후된 인도네시아 의료 시설에 대한 불신. 말이 잘 통하지도 않는다. 아이가 응급실에 있는데 비가 쏟아지면서 천장이 무너져 내렸다. 굉음과 함께 천장 조명이 떨어지고 놀라서 아이를 안고 뛰쳐나온 직후 천장이 내려앉았다. 그 지역에서 제일 좋다는 병원에서 벌어진 일이다. 응급실 한 번 방문에 검사비 포함 약 50만 원. 총 의료비 300만 원 이상. 여행자 보험 가입은 꼭 해야 한다. 보장 내용을 꼼꼼히 확인하고 의료비 보장 한도가 넉넉한 상품으로 들어야 한다. 솔직히 이 경험 이후 \u0026ldquo;뭘 위해 여기 있어야 하나\u0026ldquo;라는 생각이 머리에서 떠나지 않았다.\n아이와의 일상. 기대와 현실 # 할것이 없다 # 한국에서 아이와 하는 일상을 떠올려 보자. 책 읽어주기, 산책, 놀이터, 키즈카페, 장난감 놀이, 주말 캠핑. 발리에서는 이것 중 거의 아무것도 할 수 없다.\n책이 없다. 한글 동화책을 한 보따리 가져가지 않는 한 읽어줄 책이 없다. 산책이 안 된다. 발리에는 인도(보도)가 거의 없다. \u0026ldquo;3발자국 이상 걸으려면 오토바이를 불러야 한다\u0026quot;는 말이 과장이 아니다. 강렬한 햇빛 아래 매연을 맞으며 걷다보면 오토바이에 발이 깔릴것 같은 공포를 느낀다. 아이와 산책은 상상도 못 한다. 놀이터가 거의 없다. 한국처럼 아파트 단지마다 놀이터가 있는 환경이 아니다. 법적으로도 의무 시설이 아닌 듯하다. 아주 가끔 하나씩 보이는데 시설 수준이 한국에 비해 많이 떨어진다. 실내 놀이 환경이 없다. 집에는 익숙한 장난감이 있지만 여기에는 없다. 결국 한국에서는 안 보여줬던 유튜브를 보여주게 된다. 이게 현실이다.\n기대했던 유치원 # 발리에 호주 교민이 많다 보니 영어 기반 유치원이 잘 되어 있다. 아이에게 영어 환경을 경험시켜줄 수 있을 거라는 기대가 컸다.\n근데 아이 성향을 간과했다. 우리 아이는 소극적이고 먼저 다가가는 성격이 아니다. 원생 대부분이 영어를 쓰는 환경에서 2주 동안 혼자 노는 아이를 지켜봐야 했다. 결국 유치원을 그만 보내기로 했다. 기대가 컸던만큼 실망도 컸다.\n아이 성향에 따라 경험이 완전히 달라진다. 사교적이고 적응이 빠른 아이라면 좋은 경험이 될 수도 있겠지만 모든 아이가 그렇지는 않다. 아이 성격을 냉정하게 따져봐야 한다.\n나의 일상. Vacation이 아니라 Workation이다 # 없던 시간이 생겨나지 않는다 # 한국에서의 일상을 돌아보자. 부지런한 성격은 아니다. 아침에 일어나서 아이 밥 먹이고 유치원 보내고 일하다가 퇴근하면 아이와 놀아주고 아이가 잠들면 짧으면 한 시간 길면 두 시간의 자유 시간. 유튜브 보거나 밀린 일 하거나 운동하거나.\n발리라고 해서 없던 시간이 생기지 않는다. 하루에 내 시간이 한 시간인 사람이 장소를 옮겼다고 갑자기 세 시간이 되지 않는다. 오히려 출퇴근 시간이 늘었다.\n인터넷. VPN의 벽 # 집에서 일하는 건 사실상 불가능했다. 인터넷 속도가 느리고 정전이 잦고 수시로 끊긴다.\n코워킹 스페이스는 다르다. 괜찮은 코워킹 스페이스는 UPS와 자체 발전기를 갖추고 있고 여러 ISP와 계약해서 한쪽이 끊겨도 다른 회선으로 유지된다. 회사에서 제시한 최저 인터넷 속도를 대부분 만족한다.\n문제는 VPN이다. 회사 보안 정책상 VPN을 켜고 일해야 하는데 VPN을 켜는 순간 인터넷 속도가 원래의 10~20% 수준으로 떨어진다. VPN을 켜도 원활하게 일할 수 있는 코워킹 스페이스는 발리 전체에 몇 개 안 된다. 그런 곳은 하루 이용료가 2만 원 정도로 비싸고 숙소에서 가깝지도 않다.\n저녁 시간의 현실 # 퇴근 후 밤 시간. 서핑이나 야외 액티비티는 불가능한 시간이다. 유럽처럼 거리에서 뮤지션이 공연하는 문화도 아니다. 현실적으로 할 수 있는 건 괜찮은 음식점이나 바에서 맛있는 걸 먹고 술 한 잔 하는 정도.\n근데 이것도 녹록지 않다.\n술 문화가 발달하지 않았다. 이슬람 국가라는 배경 때문인지 크래프트 비어는 로컬 브루어리 2~3곳이 전부이고 해외 크래프트 비어는 아예 없다. 증류주는 비싸고 와인은 수입산이라 종류가 한정적이고 가격이 높다. 괜찮은 곳은 한국만큼 비싸다. 음료를 따로 시키고 세금이 15~20% 붙는다. 매일 괜찮은 곳에서 먹기엔 통장 잔고가 부담스럽다. 저렴한 곳에서 먹다보면 남의 나라까지 와서 왜 이 고생을 하고 있나 싶다. 도착 2주 만에 통장 잔고가 급격히 줄어드는 걸 목격했다.\n그래도 좋았던것 # 부정적인 이야기만 한 것 같아서 좋았던것도 솔직하게 적는다.\n코워킹 스페이스 # 발리의 코워킹 스페이스 문화는 확실히 눈에 띄었다. PC방 같기도 하고 도서관 같기도 하고 카페 같기도 한 공간. 여기는 이런 분위기구나, 저기는 이런 메뉴가 맛있네 하면서 코워킹 스페이스를 구경하는 것 자체가 재미있었다. 전 세계에서 온 디지털 노마드와 같은 공간에서 일하는 느낌도 나쁘지 않았다.\n비치클럽 # 뒤에는 수영장, 앞에는 바다. 음악과 맛있는 음식. 발리의 비치클럽은 확실히 특별한 경험이다. 젊은 사람이 즐기는 모습을 구경하는 것만으로도 활력이 됐다.\n주말 # 주말에는 비로소 내가 발리에 놀러 온 것 같았다. 투어도 하고 비치클럽도 가고 서핑도 한다. 평일에는 느낄 수 없었던 발리의 매력이 주말에 몰아서 찾아온다. 역설적이지만 이게 \u0026ldquo;워케이션\u0026quot;이라는 단어의 정확한 뜻이었다. work과 vacation이 동시에 오는 게 아니라 번갈아 오는 것이다.\n정리. 발리 리모트 근무, 누구에게 맞는가 # 한 달간의 경험을 정리하면 발리 리모트 근무의 만족도는 생활 방식에 따라 크게 갈린다.\n조건 만족도 이유 미혼 or 커플 (아이 없음) 높음 액티비티, 자유 시간, 유연한 일정 아이가 있는 가정 낮음 위생 리스크, 할것 없음, 시간 부족 VPN 불필요한 업무 높음 코워킹 스페이스 활용이 자유로움 VPN 필수 업무 보통 코워킹 스페이스 선택지 제한 넉넉한 예산 높음 좋은 숙소 + 좋은 음식 = 좋은 경험 빠듯한 예산 낮음 저렴한 곳 전전하다 지침 가기 전에 체크할것 # 아이가 있는 가정이 그래도 가겠다면.\n여행자 보험. 의료비 보장 한도를 반드시 확인. 응급실 한 번에 50만 원이 나올 수 있다. 장티푸스 예방접종. 출국 최소 2주 전에 접종. 숙소. 빌라보다 호텔이나 서비스드 레지던스. 위생과 관리가 다르다. VPN 테스트. 회사 VPN을 켠 상태에서 일할 수 있는 코워킹 스페이스를 미리 조사. 아이 준비물. 한글 책, 장난감, 태블릿에 오프라인 콘텐츠 다운로드. 유치원. 아이 성향을 냉정하게 판단. 소극적인 아이에게 영어 유치원은 스트레스가 될 수 있다. 예산. 한국 생활비 + 30~50% 여유를 잡아야 한다. 발리가 저렴하다는 건 로컬 음식과 로컬 숙소 기준이다. 한국인이 만족할 수준으로 생활하려면 한국과 비슷하거나 더 들 수 있다. 마치며 # 돌아와서 생각해보면 발리 리모트 근무에서 가장 크게 느낀 건 하나다.\n장소를 바꾼다고 삶이 바뀌지 않는다. 하루에 자유 시간이 한 시간인 사람은 발리에서도 한 시간이다. 아이를 돌봐야 하는 부모는 발리에서도 아이를 돌봐야 한다. 거기에 위생 리스크와 의료 불안, 인프라 불편까지 얹어진다.\n그럼에도 이 경험을 후회하지는 않는다. 해보지 않았으면 계속 궁금했을 것이고 발리에 대한 막연한 환상을 품고 살았을 것이다. 환상을 현실로 확인한 것 자체가 가치 있었다.\n다만 같은 조건으로 다시 해외 리모트 근무를 한다면 발리는 아닐 것이다. 의료 인프라가 탄탄하고 아이와 산책할 수 있는 도시. 보도가 있고 놀이터가 있고 수돗물을 믿을 수 있는 곳. 일상의 기본이 갖춰진 도시에서의 워케이션이 진짜 워케이션이다.\n","date":"2026년 2월 23일","externalUrl":null,"permalink":"/posts/bali-remote-work-with-family/","section":"글 목록","summary":"서핑, 자연, 디지털 노마드의 성지 발리. 아이를 데리고 한 달간 리모트 근무를 했다. 기대했던것과 실제 경험 사이의 간극을 솔직하게 기록한다.","title":"발리 리모트 근무 후기: 아이와 함께한 한 달, 솔직한 기록","type":"posts"},{"content":" 운영자 정보 # 본 블로그는 nanta가 운영하며, 사이트 주소는 https://nanta-data.dev/ 입니다.\n수집하는 정보 # Google Analytics # 본 사이트는 방문자의 이용 현황을 파악하기 위해 Google Analytics 4(GA4)를 사용합니다. GA4는 다음 정보를 수집합니다:\n방문한 페이지 및 체류 시간 대략적인 위치 정보 (국가/도시 수준) 기기 유형, 브라우저, 운영체제 유입 경로 (사이트를 어떻게 찾았는지) Google Analytics는 쿠키를 사용하여 고유 방문자를 구분합니다. 개인을 식별할 수 있는 정보는 의도적으로 수집하지 않습니다.\n자세한 내용은 Google 개인정보처리방침을 참고하세요.\nGoogle AdSense # 본 사이트는 Google AdSense를 통해 광고를 게재할 수 있습니다. AdSense는 쿠키와 웹 비콘을 사용하여 이전 방문 기록을 기반으로 광고를 제공합니다.\nGoogle은 DART 쿠키를 사용하여 브라우징 기록에 기반한 광고를 제공합니다 Google 광고 설정에서 맞춤 광고를 비활성화할 수 있습니다 자세한 내용은 Google AdSense 개인정보처리방침을 참고하세요.\n댓글 # 본 사이트는 현재 댓글 기능을 제공하지 않습니다. 향후 댓글 기능이 추가되면 본 방침을 업데이트하겠습니다.\n쿠키 # 쿠키는 사용자의 기기에 저장되는 작은 텍스트 파일입니다. 본 사이트는 다음 목적으로 쿠키를 사용합니다:\n분석: 사이트 트래픽 측정 (Google Analytics) 광고: 관련 광고 제공 (Google AdSense) 환경설정: 테마 설정 기억 (다크/라이트 모드) 브라우저 설정을 통해 쿠키를 제어할 수 있습니다. 쿠키를 비활성화하면 사이트 기능에 영향을 줄 수 있습니다.\n외부 링크 # 블로그 게시물에는 외부 웹사이트로의 링크가 포함될 수 있습니다. 외부 사이트의 개인정보 보호 관행에 대해서는 책임지지 않습니다.\n이용자의 권리 # 이용자는 다음 권리를 가집니다:\n수집되는 데이터에 대해 알 권리 추적 비활성화 (브라우저 설정 또는 Google 광고 설정) 본인 데이터에 대한 정보 요청 방침 변경 # 본 개인정보처리방침은 수시로 업데이트될 수 있습니다. 변경 사항은 이 페이지에 게시됩니다.\n문의 # 본 개인정보처리방침에 대해 궁금한 점이 있으시면 소개 페이지의 연락처로 문의해 주세요.\n최종 수정일: 2026년 2월 23일\n","externalUrl":null,"permalink":"/privacy-policy/","section":"nanta - 데이터 엔지니어링","summary":"개인정보처리방침","title":"개인정보처리방침","type":"page"},{"content":" 안녕하세요, nanta입니다 # 저는 안정적이고 확장 가능한 데이터 인프라와 파이프라인을 구축하는 데이터 엔지니어입니다. 대규모 데이터의 수집, 변환, 서빙 과정에서 발생하는 다양한 문제를 해결하는 일에 보람을 느끼고 있습니다.\n블로그 소개 # 이 블로그는 실무에서 얻은 데이터 엔지니어링 지식을 공유하는 공간입니다. 실제 프로젝트에서 배운 교훈, 튜토리얼, 아키텍처 관련 의사결정, 그리고 데이터 분야에서 일하는 엔지니어분들께 도움이 될 만한 팁들을 다루고 있습니다.\n기술 스택 # 현재 주로 사용하고 있는 기술들입니다:\n스트림 처리: Apache Kafka 워크플로 오케스트레이션: Apache Airflow 쿼리 엔진: Trino, StarRocks 컨테이너 오케스트레이션: Kubernetes 언어: Python, SQL 인프라: Docker 연락처 # 이메일: nanta0032@naver.com 궁금한 점이나 제안 사항이 있으시면 편하게 연락 주세요!\n","externalUrl":null,"permalink":"/about/","section":"nanta - 데이터 엔지니어링","summary":"블로그 소개","title":"소개","type":"page"}]